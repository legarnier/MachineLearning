{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VR5HjXwNuvX"
      },
      "source": [
        "## <center> École Polytechnique de Montréal <br> Département Génie Informatique et Génie Logiciel <br>  INF8460 – Traitement automatique de la langue naturelle <br> </center>\n",
        "## <center> TP4 INF8460 <br>  Automne 2022 </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XucTbTqIN3H2"
      },
      "source": [
        "## 1. DESCRIPTION\n",
        "Dans ce TP, l’idée est d'utiliser un système de traduction automatique pour générer des requêtes de base de connaissances en SPARQL à partir de questions en langage naturel.\n",
        "\n",
        "Les bases de connaissances sont une source de données structurées, selon les standards, modèles et langages du Web sémantique, qui permettent un accès efficace à une grande quantité d'information dans des domaines très variés. Cependant, leur accès est limité par la complexité des requêtes qui ne permet pas au public de s'en servir. Un système de traduction automatique pourrait permettre de générer automatiquement une requête étant donnée une question formulée par un usager en langage naturel.\n",
        "\n",
        "Dans notre cas, la langue d’entrée sera l’anglais et le langage de requête sera SPARQL (https://www.w3.org/TR/sparql11-query/). Afin de faciliter le travail du modèle, nous vous fournissons une version modifiée des questions dans laquelle certains mots sont remplacés par leur équivalent que l’on retrouve dans la requête.\n",
        "\n",
        "Voici un exemple : <br>\n",
        "\n",
        "__Question originale :__ _In how many other states do people live, whose languages are spoken in apocalypto?_\n",
        "\n",
        "__Entrée : Question taggée :__ _In how many other dbp:region do people live, whose dbo:language are spoken in dbr:Apocalypto?_\n",
        "\n",
        "__Sortie attendue : Requête:__ _select distinct count ( ?uri ) where { dbr:Apocalypto dbo:language ?x . ?x dbp:region ?uri }_\n",
        "\n",
        "(Cette demande revoie à la partie suivant de la base de connaissance DBPedia:\n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPQAAACKCAYAAACdB2dPAAAAAXNSR0IArs4c6QAAAAlwSFlzAAALEwAACxMBAJqcGAAAOgBJREFUeAHtnQl81dWZ98+9N7nZyULYt0QJsgkiilQFUVzrvrburXU6M3aZmc47n75v2+lQp87M68xr27Ez3WzL1Far1n3fsSiiuKIgAkJkhwTIfpPc3Hvf3/eQg1ckkJCb3CSc88nJ/3///7M+5/md5znPWf4B0/sucO/lJjjl8imhSM5JGc3xtlB23eb8vJLS0mBmxtBQIlAQyAiMMKHcMcHM3LLMzIyxiURwqAkGikw8kRtPJMIBk8gwJhCwRQ+YuK5txgSbjUk0BRKmJpGIbWuLtnyciLVUxuORTW1tsW0JE6jLiDZXVe3avfPIYdMao7Ufx7fvXtf22NY3YwsW2DR6nxI+R0+BFFNgDyhSnGhycgJvuOKqi3Jz8kpyY23hYQWFOWODgdDwQNag8Znh3EmJQGhIRmZuXigjV9ec0qysnKCeKYkMEwqFTSAEdoOCr55ZDLtrUi4JYdr6hEmAbd0nYlETkzcmpvtW09oSibbFmqtjrU3VsbbmBvUBW2ItdR/EWiOV0WjLxpaG5spEKFJfV72m8ak7XmtasIiEvPMU6F8USDmg//MbJuvk0y8YPGjQyJKMcMFR4ay8imBm3vRQVt6kjIy8kTl5RUOy8gqNCWUbkykfDBtJXuFOoIwDTAjIP/mE/dF+755z3Z9rr4q9uHuu7T6o26D+Wa/7WIswLaEebzGNu6qjLa112xKxyPZ4S+M7ba11KyKRxjWxRMO6lpr1u26+8Pnq++gZvPMU6OMUaOf87pXyxQUmv/CYC8cOHjphSkZ2wdTsnOKZgcz8KeFwwai80mGZUp/3ANgqx8KFBS4/kkHbvTJ0ObaV9gI415CkfgaSX2WKRYxpaTQNu3c0tUbrNplo5L2WyI4l0caG5Q1bV1Y+v/jpjd+83ag38M5ToO9R4JABfe+3TeH0edeelFc09qS84rEnZA0afGQgc9DY7PyioAllqaYCCFI3JgAjaVGJ+4OTeo+Kb0EegjwqvzT0SKSuOd5auyFSW7W6oW7DK027Vr9y3388vEyqucS8d54CfYMCXQb0a3+cNaF0+Kxz80uPPKOweOzkQHbRqHBuoQa8Up1RSgEwEniP7tw3atmdUgBu1HSkeFAdUzRiWiJ1kURT9abd1Rveq6lafu+GjY8+e/aNdbu6k42P6ymQCgp0GtDvPTB3Ut6QmVcNHnH0JTklY8dmhgvyTYYkcVxJOCk8UEDcIWVVVwtuAVx1TWgM3haprq6tWreqturDR6rXLL579l8s39RhdP/CU6CHKXBAQEtTDqx85IIjc4dU3FQ8dPIlBaXjhwfDg7IsbjFkWaOVroelA9ztAE/ETLy5JrJ7+wfr66o/WFizbfnCY69YXC2yHK7EOSw5oi9UukNAL7n3rJJhwydfXzJs4tcKh08q1/g4aMfEhzWIO2gyDGvtPta8o616y8p36qo++lEkuvrh6Wc909hBLP/YUyDlFPgMoGWxzig97ppZpaOmfq9oxNRzsovGaNyocXF/MWqlnERdTDCoefOMhGnc8VG0rmrlPdtXL/nHGVc+VdnFVHxwT4FDosCnAK1FIKFZX7/pS4Ujjvlu0ZgZ5SauMbIWZXjXVQqIrGGMhHVm57pXnq2qfPufJp1/96tdTcWH9xToKgX2AnrBPJNx/T/ddOmQ8XN/ljdscrFplaU67hdLdZWgnwofypR1vNnUfPz2O9Ublv5dxRkLF33qvf/hKZBiClhAo2aXnfGNvxhRNu+WrCFHFZsWSWWvYqeG1Kjg4aCp3fDW5u3rnv/qUWfe+URqEvapeAp8lgLMv5jhc748q3Do9O9nDa3wYP4sjbr3BC2nJWYKRx89qnjEsf/87u/nje5egj62p0DHFAhue/ravMLBR36reMz04aY5zcYvFm9kItFQVW1f03HJWaqZrXEqnvBufpj4vOtLTtNaJho0RaNmHFNUNvNrfaloviwDiwIZTaHQiUOKxp9rEjKAJdJoABMIN368zWzctFULzRJm2NASUzGxTBsoNJZnqow5X2Z17X3QrFu70Xy0fhMPTElJoSkpHqQhf9xEmlu01yNhpk2bsCcs7UU8BhfMnafLCdSZWYXBwmGTL1v2h+N/dfzVy9alqyg+34FLgWAge8jXcwtHZptYGg1gmsNtk/+ocpN54pmXzUtL3jQvvfKWqa5vsqtJ2wTQ6p21piXaZmIa29dFmk31rlrzu7se01A/YTZv3mF2764zQUn1tes2mRdeWmYiWn5ao/i76xpNTUOTvY/RGaTZ5ZeMHlo0dOa8NBfDZz9AKZCRGc6eH8zIT5/0kqrcEo2aN19bbl5Y9JqVsNOnVphFL78lCbzRnHLyTFNaWmyefuYVM/6IMeb4YyebV19fbuafeoIZPWqYGTKkWMusQ2bTlh2mameNng011dW7zEvPv2peeulNU1CQK208YFqao+a6ay8w5WUjNZ3EWvM0ODSEzIKczLyiiWnI3Wd5GFAgGAhk6PSAPWuT01JfqdqVG7eZt9/5wHzp6vPMhCPHmiZJ4MkTy815nz/F3LHwQfPKq2+bG6690Lzz3mqzU5L49LNOlgYdMI2NjWbd+s2mtr7RtEnd3i2pHRNYMzSODgvkgHna0RXmqAnlZtjwElNfW5+WKu7NFLVfHRgHN3jnKdATFAjGYpFNdrO/HWT2RBYHSZMlk1KFq6p2S13eaLbv2G2aW6MWlLn5eeaIslGmtrbBbNlebYZIUmeqA6ht1NyungHq88+ZY+acOttEZU2ONLeaeoG8WpI6IzPT5OXlmKxwlhlUWCAQZZh6qd6JdKrdaPxtLbFoc13tQajiX3sKHBIFgm2R2lsjDdtlVZZ1OB1O4C0fN8qcftoJZvWaDVKZh5iTTjjG5Gil1ccffWz+7m+vMxeee6p5860VZp7U7xHDh5j1K9eapqaImSQpvr16tzV4DSkuNKWDC01eTo5Vuxlbj5FKHlYHEBSIi7Q5DNU7ni51G9oyvKjdWtNYs+LpdJDa5znwKRDY/tyVw4IjZz9VOv7UY4zGmXtMwr1ccTE6wqtOIA1nhkxOZtg0tOhQEIEyPz9X2xRjksoRU5CbYwjZot86KFAGs4DJ1GghU51RS1ubtW4HNXzQKWJGhwXuOYJMV04aQzCH9C7MCKOXq7cnO5U4GE9sX/30A5uXfe/K4/7SQGzvPAVSSgHL9+tf+ptrhx455zd5pRNCpjVNU1eo3gK27VAwHrlpKg5LcO/s0UW8aw/Hc8KCVsJbqOreqvH7o5PeET4dTkOA2s1vV21d9dxFk877/ZJ0FMHnOfApYGGzY+Pqh3ZvfftniciONpORJoMNoOSgBFRie6+rPflEjeDeccXxHGC6sPaZfic/t/ftaey9b49vE+mtf+poMrNM8671LTs3vfVvE8/9vd+k0VukPwzzsUuq7nhgbcsXTg2/lRHKLM0pHjFd52FLPxQYvOseBZg9CGeYaN2Gph2VS26rXHv//yufUZPGCf/uVcfH7vsU2LtG8o771zdeOHv3q7nh/PHh3PwjQpwTlpB0cVKx79elb5UQI2NmwDTv/LBq25qXb9v8+r//37k31fgDBftWKw240uwFNDX77cPbmi6atfrlYKBA0z7h8eG8wnx7gicqq3edo0BQJJVRz8SbTP2OD9dvW/38d9/47//+r7N/ZNJknOhcsX2ogUEBLEn7de8+8oXZQ8fM+OuC0iMuzxtWkWNikjhReDId49D9FrFvPUS9Bsim0dRtW72jsXrdnbu3LP/tlAvuX9G3CupLM5Ap0CGgqfSffzNjyNgJ887ILR77V4NKyudkDS7Twggxbluaprf6Yks4IAdaTP3WNZrWr3y4bmflr1Yu+9OSC79dnealaX2RYL5MPUmBAwLaZfzGo+ePHVwyfn5O/shrBmnCOqdk3J7vxbGh43A1nqFaM06O1Zv6nesbGnZteL61dtP/bNix/OW5VyyucrTzV0+B3qRApwBNgRILTHDVtPnFWSWTTgsXDPlCXmHZKYNKxhTroP1QgLO5bSCNtQekEU31o4pIY3uNJ9r0zbu6XRu2R3avv7exadsD9VUb3jvuiufqFMqPSSwz+H/poEA7EruW9YsL5mUMPaZwQm7RuPNyi0efkVMwenpu0fD8QDg/J8iRO3A9bA24rSf9/sLnKrsFLdd2Ly0knojqy7Q1kfqarTXNdZtfa6rd9HT99q3PHPPFhzYomLca0sTepZ0CsG633Is6XLD47845Om9Q2SkFxeWn5Q6SBS1vcGkia9CgjGA4HNDmiD0Al3QD3FjMHdDTDvIk0LL6zAKY8sV12Gmz1n23Ngei9bUNu7dsjtRvfb+pbvPLO6vefemEL76+ultE85E9BXqIAt0GdHK55unwn39cOH7cqFFzZ2bnDjs6t2DIlNyC0nH6lGxpIFxQEghk5oWztWgFa3ACAAFyFcEB3YKdFNulOc/3uuT7vQ/3c9NeJXtx1dMVsLIubh/gqofRmV/N2pMdaQskok2x5rqqaEv9zua6nWu1aeWDxobtyyvXPfj6uV9r3LafzPwjT4E+RQHH8T1SqEcXmNySEeNHFJd/7qicrNKKrPyScZnZxeOzs/OKgpk5xYFw7pCAlqXJuqTtyxlZmTl56hLaVXZtw7CSHdDjAL51urrb9icO/7Yj4JOwOIx1dAisVue+TR99j0SkIMQicZnpA/HW+nhLU1U82lzb0ly7JVK/6yM92tZQv2Hl5g8Xra28a9e2v3zTb6DYQ0z/v79QYF9o9Hi5fzHTZBZfbnLHV5xWVFA0frDG3LmxRKgwJzt/eCgrf3hGRkAAD+SbQFZhRjhcHAhlFgnweYlAIEd7qNhcFUpoS1WkqSVX2yHj2TnhSEJnC/HpOFWmNZCI8xX3+li0tSbe1rI7ZNpq29piDW36entbW+P21kj9NoWpb0vIML1rzc6qN16tu/BWTR5bUd3j1fcZeAr0KAV6HdAHqs0CjcfHlZmMkkkmM2/4xHBJ0ZisnPCocCJkMrWlMtQWCwQD8pF4W/Anv3n9+PzccNPXv3Tce6zBSoQS8VAwGIu3tsZaY5FoQ2NNS0v0/ZatazZEt71mooufNG33aZLpQPn7d54CngLpo8Bpyvr49GXvc/YU6HsUaB+g9r2CHaREaBYMtvHeeQp4CrRToF8C+sUXXwwVFhYmSkpKZPfCXO6dp4CnABTolxJuzpw5n3/wwQc/n52dHWmvw2LfnJ4CngL9lAKSyk/IO/ejfloNX2xPgZRToL+qq8kHBSTfp5xAPkFPgf5EgX6pcm/atCn+2muvGY2joyeffHJnl5D1p3bxZfUUOCQK9EtAv/nmm4kdO3aYJUuWmJaWFg/oQ2p6H2kgUqBfqtwBrcvme1YyiukjdTpo3ztPAU8BS4F+KaHfeustpqvMrl27AosXL9bHob3zFPAU6LcUEJAf/vDDDxPr169PrFq16tZ+WxFfcE+BFFOgX0ro4uLi9Tk5OR9K7W7NzMzUh7m88xTwFIAC/RHQoUsvvfSB1tbWFRpLR8Ph8LuqB0tBvXGMFvXOU6CfUYCzxG+Rf1/+Tfm/ku9Tu8ZUHu88BTwFukCBzyksh4Svkh/XhXg+qKfAgKYA0q4/us0q9CD5RfJPyXvnKeApIAqkS1UNzps3z/ra2trQ2rVr84YPH14iQ1dpLBbLy83NHaT7Eq0EK9X94IyMjAKVNU9GMD5NEYrH46G6uroS/W7Lz8+v1Viac4eiitui6ayIrrX19fU7GxoaqhobG3dHIpFaGc8aampqdlVXV+86/vjj2dQRX7FiRey+++4jrh9/iwgDwAUuv/zy4JQpUxBUwWXLluWUlpaWFBUVlUSj0XzxVGFeXl5xQUFBqfimNBgMFoq3csQ/nGSZCV/p6jCR0HsOxBA7xVp13yi7Tb34aZd4r0o8taupqalOPNio++pt27btGj9+fKN4NrZo0aI4XnHxvepc4Xsy08xzzjkn55hjjskSUYeJkGNlyBomIleo8pNE0CEicr6IPETvhgjAIYFPR4tlsHAkkJWVpXP9ggF+62o9C0vwOOaj8SK6zgvTaWF8+D0eT2gFmWlubk7wW1cjoreoAappDF0bFH6Lpr9WamHKxwq/QR3LBuVXr1VoTc888wzrw/3pJpbCffZf6Mwzz8yeOXNmrtq3QLw0VvwxVjMg47StdrKANlK8lD9o0CB4qlRgzmIhUkd8pfCWp/blK3iqI74SPxvxUgzBIQGC8NAxV21V4qUPJDzWqAPYrncbmImR8Gh+5JFH4Cs+O9NjricAHVYvWaLeSpgtmiCQAtzpAuwUEXekiD188ODBRkS2HsDiHOEcQLni3G93bx/u559rCF4lA557OgKc6xBIE5CrMazXMtIWgXurfm9XQ7ytBnlfwF8jv/7999+vefLJJ3cpuge4pWLa/oUkGEqmTp1aJD4ql4evporHZoiXhomvRgwdOjTL8RXgpe0dX1Fq7vfHV7xzz7nf1zne2pev3G/HV8RDkDi+2rlzJ4uftomPtgjY74u3luu6RtfV0kprpB3CV9iCUuZSBei8G264YfSkSZMmi8hTRNjjJXWnCrijR40aFRaoLXgptZOkjtAHImTKarmfhGgM1yvTa7tGU09r1ABm8+bNjSL8RvW6y7dv3/6KVPXlH3zwwYa77rprk5JLaSPsp3j+0R4KhK+66ir4aqxU52nDhg07SXw1TVJ4zMiRI/MEaiNBYUPCR2hjXOGxdPKVAzhXeAwHyAVm+KpVQN8kvnpfgmSZhMcK8dXK3/zmN/AVh1V2y3UH0BnXXntthYg9ZcyYMSeK4LOGDBlyDIQWwe06a0dkR+B0EbmzFALUrjFQ+3FS1c2WLVuMiL9D6vm7uiz9+OOPl2p8turxxx9f19m0fbjOU+Dcc889QnaOiePGjZst4TBb/DRd16HiLSPV2SaEuptuodDZGjlJDrid8EBDZB+CeKuxqqrqHQmM1zdu3LhE4F5x5513rlHa+nBc112XAf25z31u/BlnnHGOVJ8zjjjiiKkC8WhJ4kyn4rSPYS2xu16cvhcDgNMINAYMRC+rhmiSEWTDRx999K62cf7p9ttvf14l97tEutd8xd/4xjfmn3DCCZcdeeSR02UkZTyci3ZHGyAUHG91L5u+EdsJDngLQQfAJbmjAvemdevWaaT3/rNyT7766qtru1LiTgN6/vz5E+S/OGvWrEsF5HKNWQqk/lhV1RG6r0vgrhBmf2Gdmp4MbgF7OyrT22+//ej999//R91v3V9c/2z/FJCGN0Ir/744Y8aM8xmyCcgYTveC2Gl3+489MJ46zdCBW+o4Y+96AXv966+/fv/zzz//R/nVnantQQF90UUXlanX/CtZEy+VVB6tXjPbMXSykaEzmQ2kMK4R6GllzaR3bdQusLXyC5977rnfqWfF4OFdBxSQpldy+umnX3fsscd+SWCu0JAtV7Mf/UaN7qBa3X6czFd0ZtIGmyWtN2n25X5pgz9/6KGHKg+USYeAFrELdRjfNQLy14877rjxAnIGEvhwBnFHhHSNwHuMHm+88Ybo/+Zt2g32uCyZzHl7104BzYDklJeXnyu++pb4aiZGU155vvosizi+4ipgt4mv1oqvfqotw7+X0Kj9bAwt0tjPw4ybbrpp5llnnfXjs88++29knBiinjN4OKg++6FFpx/R2eE1jRKaOHHiGNlwLtSU3FhpM29pqyffjT7s3YUXXjhGc8f/Lv9Pc+fOLZOVOuT56sBs4YSojIHBioqKUhkGz5ZwnaqOcK0MszsU+1OLV/YFdOj73//+NRor/6fAPFvjmQDqJIl61zkKOEkjy39GWVnZDHWGk0aMGLFaxN/SuRQGZigJieMlJG674IILLpcNJsNZqQdmbVNfKwdsCYqAgH2UAH6a6Fjz5z//+T3lthegyYAOLViw4GIB+b908N5IBuiA2btDowCGQoyGUi/HawrsOPWsH2hc/fGhpda/Y/393//9XA3h/kuSeQ5zxyy+8O7QKIBGw2IszQSUyHg4d/To0Wu1zPRDpWZB7QCd8YMf/OBG9Z4/kopdApCJ6F33KOCIf9RRR41Qj3q6mPkDGTa6NA3RvRKkP/Y3v/nNs2VY/a20vqMwpiKZveseBZwWKA0wRwu55ktY1AjUnAsQtwccfOtb3zpOluzvT5s2bTDzYUTwLjUUQFLjNN03RlNcN2sq4r3HHnuM3WIHdFKxWEExXJ5Od69KdcBIPf8SIyo9/TYZag5q7JOAGHnSSSfdTN3p3Bwter6YAz8HMApWwaxWMn5fGH73tttuW5rx1a9+NVfTUX8rwo+E6D0FZnpnpniw2NFLH2xcTnjKc6jO5dcXJAKMzBBGQ5mZWmX21wL09zpRr+mi0R2iV7bCJs9GHKi3JRyeDqAnOgHSZoPBjfJL5Q/oVN+/Fl/NpC2SwezahsgH4jm3Wo+4biEG9wfjnQMWap+X8CPlIU3Hb+TlytzVvEiPtk51Ofcptv0JVikzQ+StW7f+rbB8Q4YWs8/WhP4FLGoH8al2VBCnw/HtGmnGTxrMG8ZSFMi9J4wjHlf1Okar0OyzfcO43y588m/u8aqg0XI6o610JP2ZdOxD/SNscjlcmu59qq40sOoT1Lzr5bNnz75j6dKllQdJO1tlq1CDhWVQw3puWHCg6Z4Oo7EGXQtbjHa22XFWhwG79wLDCp3Mvm5PQ7d3JKpjmeaXr6DO1N05mJ2ltLQNtNYCJSMDogUAbeEc7zT/ap/LCGRYY0+csrIyu/zTCR4Xh/DccwWQuH3bNTks7/lN2bTij482WH7judYUGGlThnyZGydN51w+yb/dPenRRqSnYdbe5c/7i+PKQlyXPs+Swybfu3AunotD+cEuGF6+fPnsoMzfXysvL8/pSUlG5pWVlUYZGn050oLbGdy4sl6azoTehl4Z8P/iF7+wz2gcCk0YwvKbskI4VzneOanPInjCs05W4wp7T7o0LvFdWoTXwnjz7rvv2nzpaEjHpekaKdVXGTOGazx5SmfSVZmjlPGPf/yj0Uo0c++99xptGNlrVOIddMCxJFXLBo0WHlhmBAC8o+68A+zUD8dz3vPb0Y4rYQnnOnbC8RvaJL3raBBcrKQvka+QD1JH6qr7vc4xLGDhIwnU6b333ttbH9qGvF1+8MEvf/lLW174Z/XqPYulXFuTHnXjN+1L2/NMawGMtivae5cefEMdXd1coehg4IE//OEPNj4AXrhwoeVTeNHRhzzgn2Q+Ij9+Jzt+v/TSSzYtx2vwP/EdbxKecpA2YZI9YQlHXtTF8SX0x9EmpMU75/gNhsFyhiyxZzpp6QKk6kqmFE6GIEtgNbCVNJoYt5WWOmZkdrfP6KnVy5gJEyYYLciwwH7nnXeMxvZG+5NtYyKltI7crFy50kpwwmuFkSE9LeS3vSwMQo914oknGpYQaiLeMiPSXovfbdquBxcBjCzPNq8NGzZYySH1xZZh34ZKBU1oLEmCHFkpZyu95+U7+tBB4pVXXhkq+gWRUjAoGxO0/M/ceuutRltTDbR76qmnbONeeeWVlkbUuUwSTMsGzcMPP2xpf9555xntELOSEBpDP6n8VtohRWAqSVNLB+oOY9MGGvdaupI3+cmaarSYwTBtIloOUdnHyH/CVcaU6Pf18lPlvyMjIJsqsqgzznXMABmwwbDwA+1Du5AnkpGOWHkYTfXZsiKVKb+MtUbpWenHM4pAG9EpsB137Nixlqe0As3yBxoa+wvQbmB4aUa27clDY3ubFvEBLVoPoNZwyOYPaJDOaImPPvqo5THyoHMjLOXH0syVcsuCb0FJXZnZgM50NAgvrmiJWotg7+FTaS72HeUCe6RNHPJDW0EQUVct7DJgAN6kXaGJFpfYel188cVWe6AOeNIBy0H1UBou7BlDWMqn8B+AlhHISpVLLrnEFoSGhHGoOMAkbxiKhqBRqBQ9+OTJky1D0TNBYJgVgmm9tL1qTtNot5PtLCAQ4ERCae7crFmzxvaA9LYQAYKgBsGUMAP50SvSQACDToD4pEPv2lOO8ouxgypnufKYJz+/Az/v5z//+bEvv/xy8Pzzz7dlhA50Xlr3bEGAFIExaUxAAj3YSkgegJR6Q3toh1SfN2+epStaEg7akB70AECEgflIA8kIUwmUtiPRDjP7m85VjBy655570Pvnybvyn6b7E+TZ3D5O/jKlNxbpR3lw3NM5oBloX7NtJ6QPnQUg0RDEdrwMF7ToxKqs8A9goYx00jA5dYN3KJM6PQN9tK3SpgvIACWgIE1ARKfOb8CFAOA5be/K5UAF6AA/9IEPoDd5kS8dJKAjT9JEPSc+AgYa0wZOSFBXyu0kLL+Jj0SGfgw34EfCw+9OOpMmtIEnASd1Zvjk2olwtInsXRYzaGcuT8oCjsByUBJ0C4R1LylAKh0EgxBUhALjyBwmgiD0ooCQnhJprsXolhkBtPsN41FhmBQCkx4Ecj0hjUg69O70wMSDIDApjQlxISL3pAXBkHgwAISBkenRceTTU46GVrmj6qUXKY/fy/+2A3/nd7/73YdV/jY6J+oL7QAF9S9Tbw0T0UlBQ5gWRoAm1J9O0YGH5wAToEIHGATVFRrAxDAtkoY40JErcQANzE16dLZ0DHh1hm0aDj2sct+ZVPaFur9PnpNY+fDBTaLzKwofp844rpSZutBh0zYwKW1A2eAByka7wB/wJIxKuyLVqANpUB7aknajndHmqD+dOeVzdKD9qRvhiA+/ARD4zPE66ZEHYQFKpdR6ykT+xOM5HtrTaVA2JCQ2IOjEc2hOPq6edASUgfgAmXfUhXpSTsJTF9qOd0cffbSlBZ0oeVE/+Ji2gl60P+lo9aHVNKAbZSU9yo6jPuQhemwJqUdsLisrOx8VhsKk0lFJGosKAmikIMSlQejxpPfbykAsCkplIIRM8bb3okKAjYYiPoREopIeTIGkJw16TcpP48P09OTkyz1SmYZXHa2np4YQNA758A7GJk3KQPqApicc5VFZd0rLuEUg2nKgPH76059WqNGuFsNy1pWVGjQiHQ/1ppwAkXrzG9XMSTA6OsLCxDwjX4BP50obU2fAA0MRBjDQ0eEJi+SAWckXoAGaU0891QJc6URF83tuueWWj/cpP8yzTP5R+Ua1b7M65UtF53zSgea0CcwK89JxQnfy5j1tQRtQBviAdqdu8AN15jltBh8QHp6ByQEp9SVtwEo9aWsYHLDQsZE36VcKsAAFddrxCgCmI6M8CBGGIZSR96RLXGgE7wJ0wEg4QAaNoQ/58dwBi/JTDn5TbtIiLFccoKYdiENbwG+0BYAnT/KhruRNPXhGPbT23XYEdMa0kXPUmzaSpvZ/AlqSN1zjqmekvh1NZBJJpaNSFJ4CUyEKSyWoIIDnHWFwruEJwzs8jYxqzVgFlYVnlBMPASgvjUQcPM+5OscYiwZDJYWJf/azn1mVj/RICyaHIKThiEw5Uu3Ii/Rl2HroK1/5yheU/gGX4alepyvMs5SPuAANBzM4xqDM1CnZQQ/CJzv3jPxRzxkL06GedtpptrfnuaOZC/vCCy9Y1R6mg1Za5WXLT1jleYbyeC45j/3ch3/961/fc8UVV1xE2qRLOwMg2gia46kP5SUf7l1Y0uOetiBPwlBX4pIOv4kPX/Gc345WxCOOa1fydukTt1LAhq94Dl3R3AAJ4XlGHqTHO8pL+khmhmYMF+hMKBeePHWckL1SZtIpE8CJT1r45HvKhi0E2widAR2IU/FdvciTNtZnnoz2RFttiTLSqfKOcjnakDZY0nll7+morLNo+cC//Mu/fEkF/bV6sQBETbVzBXUV5LcDTfI9+e5beSqAmkYPjBpIGi49Gg3nKsc98Z3j3ql29HIAgN6T3pi0KIPLf980XRqpusIUAtPOP/3pTxfrQITFB0tX9cRCDKiz5Oll6WVse7Xf62KNarzDf1Jx3uxxPHPv7FWaTWLRokUJpI7sEoH2zsGFI5a9l0rJhwA5+TIxTye0in7kT09JR/SsaLtN1wM6HVgw57LLLntQ+QyG9jhH52RecPeu7V2iPOeZayN+c4/jHufecU9YnIvn2pdn3MMnvEO1deXhGbxB+zh+Ss6DNPFIZOIgcd0z4vKM9Bw/Q086S3678pC/czxD4yQOHQjpkberjys74eks4H2eoa0QztXXhSc/DY0SAvNXvvOd7/yPpYAarEiE/zfthrlRvUbIVdYVIt1XiOAq0NWyOKI6Qrm0DjW9Q8mfhlBvG33ggQe+p80v/6E0OqUCqIx7uLermR44/B6u/yTMHmR88tvddRhONOxU+ZVQ8Oabb/5fMoj+UOpxJnzVW3R3ldjf1fFE8ruDlcvF2V84986lt78w7h1Xwrs4hO0o/MHCwVfqoGOa0bhDguJ/L1q0qMbqcdxIVbhZakmurIbXaNwVoHfoKKPkwvXGfXfKkRyX++TfPV12elPUI41vIlKzblcvervy7CwYaPROh+3puhxi+nHqLI1osNTCb5Rp7TEal5Nmh5hmt6MdCg8cKM6B3u2vsITvTJyOwgF0pLvG+gkNn+7StO7NYJi89g42ZazhEPElUkWPEqA5Ysi+60zG+yv04f4MgqOSSR3aqXnfH2ud7S0y4Bx0/fNAo5sMYG2iwRIJjIBsHlM1U5Hr1MaBVtfeqA88BW+Jrq0SEk/oQMFvaj3C3uHPXkBTGEmSRvnF0stD8uM1FshjwJ3uHrU3CJWqPCA4NMPwJ4PchgcffPB7CxYsuF1W48N2z6DqHpUkeVlCYodAPUPXQiy7HUmgVLXFQEoHqQxfoTlrdqNKUvlXMvD+oxZGbU2u56cAzQsZQ+qffvrpZ9SLLhFThmUoqJBVL9MB20vsZPJ9co/UwUCB1VXnilVJBfrVE0888Q8/+clPnlao/q46f1LRQ7+La6HM2xqCPC9DpQzJLUfKICSFcI9x0vPV/gkLX4E96CMre0SGynu0vPcffvjDH/4arO4b6zOAdgFkpt+oua8lYtJVsvAN0/MxWNoQ90hs3wB7KIVEZkqEsaGWD8a0zPVRrXr6vmYO/kcMvNHR01/3UEBLPXdohder0v7e1hgwT8CukMU9CA09X33CJQ7ISGYWAomnlgiTP1i4cOHPZAT74JOQn77b15L56bftv3Sgfrkm6c/QopCrtUplLsv1MPYg/p2pf78RB/BD6k/nxgIMxsaai3xBywB/p/uX7r777u0DuOopq5rWoA/TcsxTtGDoOvHUabrPYXoSvqKDPBydGyNTf+a3NV/9Z62j+IOk87MaL68/GE06Bej2REJqgFKt7jldq1iuUAMA7EL1tOpE9iyaQGoPVMlNHek1uSJJmM8VgHfImPgn3d8vgi/XeJmjezuaBjpYWxyu7wPaaFAigTFNU6aXaqHFZQL4UN0HoDf8NJAlN/yEB8jUVeskEgJyrfyftSruXo2Xn5OAqBZzdGoZZ1cA7RguoAUDYc0pThThzysrK0NyT9NStFxNT2RRMOccwPsTyCEuzhGaK+WX1EhIRWyW0bCusrJymXrNpwXopwXkSqmRHW0pdKTw105QQBsnMgXsMvHVWeKps8Rbx5eXlw/SrEu2tCE1xSerrxxPuWsnkk97kGSecoVBw9Xy1hYth24STy3X9VmB+THNMa/SAiRW43RJQBwKoF1Z3DXr6quvnqaFA/O0HW6+lqiNlxGtWGtZCzSYt5/IIeC+vS0Nke7GcAR2ktcxDBKBFXMycLWI2PUi8lZt8XtfBF+scfJLGsOsUpW8octxQM9cg1roNHH69OmnCNxzxFdTJTRGSGgUaLxtPw3r2s3xkpPkfYWv4CdXRsqGg69kN4jKMFgvo9Zu8dVabdR4XguPFmnrKlvhujUbkgpA24K2/8vUZo8yrQ3nlMvp2hgxRarTWDUCH28vVq+TK6um/eazq2wy0F2DkJZrFNdYyZkc6J50cclXd09eeBzpkh8ey7R8mwgdEaF3ShLv0oaAj6TyrBTB35Uq/ZquB9xMYRP1/3qMAgL0SKnmJ+g6Xbw1WfPZR0py8zF3Fq0I4zkZGNZcG7s2d21MwZJ5KZm/Olto0nTpJl+T83T5kb74iWWeCWmzTRIMu+V3aXi2QXPIK8Rb72qd9hvaVFOp/FOm4aUa0PvSJk9j7hHa0zpRDTBBVvIyTVWMF7gLBexiGUAGS5XKlZourIftZ2cxNkEgCIb6nkw4d79vJu53coMlE5b7duJibGmW+hwVkRtk0KoWkGtlxd8qQn8kgm+VFF6hTe2rRXAMWwfcQOHy9ddep0BYoB6mVY0TJL2niJ1GSHAcqfltTlctFF+Vwk7irUzxUzZTY0z9OL5yAKTU8FRX+AoeQ03mCl9hvGJnmPipVc9bxVpN4qudAvJubQCp0W6yj+QrJSBWay5+lcbEzBt3+7OxHVG8pwG9v3zZHpSrT6IUS0Uv1bRYnog/SD3tcDXGCAAugufzTO+K1RCFInienuXomiEfEjH1M2jLLqIm9CyuZ23yELVFzxoE4N3yNfpdB3h1Fd0btovI20T0eqk+9ZovrtYEPZ8UgcCdMjrsr0L+WZ+gAMabPO0KK9TpJPBVgXipQCvUhmsxyzAJB3gqX9dB4qki+WL4TL+zxD9heAu+EkCzxT9BhW1q56sYvKVnEV0bxVO14p3d4qk6+AwASyhslWa3jWd61ygVulqfQOJrpE3yvSoU0gHoA7V+pl6yvjxTW8qytO80S71ulhoEiwjP0ZeDaoRPlVtgxXAQ1/OYFsPgW7WbpUUGq2aNTSAonnkQD1oR4TB0gB3+CcvWE9bsTLZU9yytVgvL8zke3gNijsRiG3HuKaecwt5uBr7WA2oJhKi0uRadtNOiVYCMdVGV4auUqcxKyztPAU+BFFLgOKV1agrT69WkemJ7Xq9WwGfmKZBiCqAl4j+lBaY4jx5LzgO6x0jrE04XBaQeB+SxtXTZa8ydkBEtrnPTGFN3NT5x0toRpDXzdDW4z3dgU0Cg4pjhi+Q57QWh5RZnHHTtgDY/HCEbTJamXlfJaObiKQnrwAu+o3TI60nZe9ba0P6fp4CnQPcpIEAfLx+VT8hqzSVlTpbsg6V1lQKkTVDaE0u6T0KfgqdAn6IAsxkRLRAq4CMNmqe2O+Jkue5WIVnlxdHGHNrPeokOXFot3h2WqoPC+seeAv2BAhna+hvndE2OOuZccb7ewsF8p+mkU01L2d9aM26PldbUpj1Kl22Kmia1p3pyHjbAZfUZcekUONCPA/40/2w/DMARxBzcz7HUHLOrqTCOFg5xOouItK+63it0+2QnRa9k5zPxFOh5CugE2+H6YMP1Alc2IObYXa0CtCfAakWgPcddc9FGh1BYoGoRij0yl6N1tebBHrEr1dpeAT9H/rKVEamslYT2CuC19NR+aYV7VqJpeTCVu09rzlfqe+tpAbS3cvc8f/kcepkC2jecQHoK0Pbsa63msh9pkKHLfqBBO+bsWeNIXMDKJ3I4vIPvZ/G9LY2BjTaG2M/wEFequz1cn06AxSfE1yImm74MZ1aqowWwl1srxgByWsAMmT2ge5nZfHY9TwF9J9lKYy2/tCo36621ltp+kI4vjqA+6zRSC0qkLF9TQXKjOiPNUZ/VKdgrkhrpTBoAm3d8jQX1HFVca8jtDiq+BkIakvLMYafNpc0al7Ya+4wHPAUkYWdpieaLWlOdyydpGNtqs42VvEhg1GgtC7bSGHBrG6PdcMGuO6Qw6jngJh7jcCQ27/gEjsbH9lM6pMdHG9AC6CxQxwG9QH2tvvDyB01dpUVKe0APePY+/CooAE5WrX8tz5cHARbzxk4bxQIO32M/4jnvHQ4CWq+drfhBqc9NMoDF+WSvxsgJ7S0IYCXXeJt0iEccvLvXrf39D7oyF+0BDUW88xToLgUESHb0cbClA3Gnk7zxxhtnCNR5Wim2BOktF9J0VVRApgNwnUNH6ZHfdoGZXVbeeQp4CvQBChyvMpzWB8pxSEXocg92SLn4SJ4C/YcCbnNGv8RGvyx0/+ENX1JPgd6lgAd079Lb59a3KcA4GaMZyze573fOWff6XcF9gT0FUkwBsPBVeSzknELCEUK3yvfqEULKzztPAU+BFFHgPKXDofZYs7+eojR9Mp4CngJppMBC5b1Ynr3U/c753Vb9rsn6R4EXPHzT+Lzc3NHxWDzACqr+4IKhYOKFu15b1xJprT7rSyed2B/K7Mq4Z6Va894VMu65v3oKpIQCv1j0z7edMun8r2SFsjP4RkpKEu1CIgyIO5sp32ZwJdSRshjFTHzPSaB7zuzWy86m1YUipjRoTAvWFq1+0B5tmtKEfWKeAlBgUFZh5riSioLsjFxveO0llngl9KQHdC/R+rDLRsf0xeISc6r4QYd12nLIedh295MOxzfLli0zZ511lt0M8bvf/c4eIsDWxoM5Dh5gO6POBLN7nTnMgL3OHTkOK9DXLOwOKjZtnHzyyYavbDinJaB2E4e+zmH0pQ732F7ZsKElnp96dqAf7Ma6//77bXnYqnnmGWea/IL8A0Xp0rvWWKtpi7Z1fa1rl3LxgT0FOkEBHXRv9yWzPZHdToCQwwY4nICxoT5ZbLcusj2R/cmAQwfd222L2lFlt0iy4+mOO+6w2xrZ7sjuKEDHrih9s9sQjt/OsS3ykUceseGuu+46e3CBPkJowwFk8qCDYM80e585vIDjh+h8iPfAAw/Y3Vb68qj9Rjg7r8iDXVyUkd1a+jKLPeGEPPUpKJuXvuxh9NVS88KLL9jycGACJ6YQh45IH3W3u79cObt6PWjv2dUEfXhPga5SgE0QSGQAx3bHG264wfzrv/6rBYq+X2X0QTf7HJAiwQEcANuxYwc7oSzo2ddMh8BzbZ20gHr55ZdtXEDIVshLL73UHmRA+dhCCeDIi1NK9F1qu78ZYH7+85+3WoJOHrEAZf8ze585lWTq1Kl2uySGvqVLl9r35EungcQHlJQZoHMGGcC+6KKLbKeAREcT0bev7KEKlN0djaTP6Fogsz2T/dnXXnut3WvdVVp6QHeVYj58yimAFEYNdY5TQTgBhH3JSDYkGs8AMxIMUH35y1+24OVkEvYz65M2Rh9GtAcUACROIgFcAIV3SGSAh8QFWHg0AfLA0VnQsQBuysPpI+TJgQc8nzVrlj3YABCighOf566DocMoKyvb26EQj7B0Ls6RLmXCcTACHQ5lmzNnjt13TRm+/e1vG+pEBzF06FA7hHDxO3P1gO4MlXyYXqUAkhoAovJyz1Xf5bbgQYIjGWF+xsuo1+Xl5RbAhAPIqOYc9oe6DWAAKe+Qykj14447zoJ57ty5VkoDXCQ74/TKykornfkNaOkEACLA5Iq05+BAd8YYcZHMdAx0AoCReJTBHSoI8QhDGuedd55ZsmSJufvuu225KSMqvT7DbKU6daPM5LVIZ54xriePzjoP6M5SyofrVQoghRlbIwE5fRMgI1FRfxl3MuasqKgwo0aNssAGBIAfIKDSAmDuAT2AwQEypP20adNsWvPnz7fxGTsDUiQvnvQ5Z4xnSF1UbfKjLEhitAnCUR7UfwxpdEBckbwAkN/EoVw46nLBBRfYzuXKK6+0NgLSwtPRcBqKDlGw43A6Gp698MILVjPoCqA7b6azxfL/PAU6R4G7lv7kxxfO+PLXcsMFfUZoICUBCp0DQHcOlR2DFmDkaN++4NBAKC+aRnJZOyobVu47l/7o4FMKHSXgn3sK9DcKIC2Tp6Vc+Rnvoh5j6ELKozKn26Ed4LvqPummuhrTh/cU6CUKoNbqnG073kWaok4fitsXqKjWTDPhUMtRrfcN09V8KBtTapQzHa7PqEPpqLzPs+9TACPWvffea8eyjEkxIjlDEQAEQMlrxQEkY2ee4QnD2BfLN6or41HuiQfoGKeyqITxMI53hMc7R1jyJj3i8w6VGEf6jJcZIzNFxXumoso09p43b55N170nHmkQlg4EbQBH3t3tSGxC+ucB7Sjhr32OAgCJVWOAB+swQGBcyXQP0zo6Ltc+YyoLddqNNbEYv/rqqzYshjOmwDi9kzleLNzMEWO9PvHEE63VmtVonOjp0sbwdskll+xNj07l0UcftWFJm6N7F8kCTfmYKkMiY11nmorpLabaKCMdBqBmQcrKlSvtO/KmwwHEjOexwJMX8+ipcF7lTgUVfRo9QgEAA/CclRepBgCQlqweY8EJjnExxiwkLe+JwyozfRLHTnFhxQYwSEgO32dums4AazhLOqdPn26nxZgyArAAO9khPelUACsH7dM5AGSA/fjjj9vyYJlmPpkOg/Lyjo7hiSeesMCnbEh/pq5OP/10W04MXhji6DBS5TygU0VJn07KKQCAAQKSDis06vaHH35op5UAB1IRqYzkxYCE9RrQEg+gAnpUXxZzMH8McJHkSEyAjyM+cRmnM5eMGuyAy/JPF4Y8mGcmLTxlQd0GlKTJ9BlAZmqMdAhPWqQLYJnmQlsgL1agUTbC0FlQl1S5fnluUqoq79PpOQpceuM5Z08cMWNWZijrkIUGzI4EA0gYr1BR+Q0AAATPARMgBlwAiDEq8QjPSi6kMVKX71EBYiSzWzuNZZs0ARmrspCoLBjhOYBlAQiLTciPJaGEwzGGd9+3Yo4cjQBAkx/3lAWVms4C8FIe1poDfsbTzGPTKfCespMf9emOiyViZvmmpX4/dHeI6ON2TIFUz0MDKCQgIHZGJgABiPHOcc9Ylg0UN910016goDIzdgVAyWACrKSDVCd9pD4qPAYuVG+3wAXgA0zSpxNB8uLoJLgHwKSRLG0JS35cKbMbN/OM4QTPXRiedcf5eejuUM/H7XUKJEswgHcgx3iazQ2o4M456cpvAOncvvPSqME4VnABUBzX5Dg8cyr7vvfJ+fDOOVdmOpWedIesDvVkoXzangKHSgFUbiQh6jMSNdkhDZG0WMuR0lw7csRFiuJxzsKOUQtpS1p90fVsd9EXa+zLNGApgFrNFBRqM+NSxtt8ExoJCyCxarNn+qqrrrJWbcbHjGtxhAGkhEMFxxpO54BxDev14sWL7XvSZEEKqjjjYwAP+J06zm8n2dNBaA/odFDd59kjFEDdBaDsbUbt/vGPf2wNYkjjSu2iYkqJMIyNkeCov8wP8x6gAsQVK1ZYyzqqN+BGVWZ6DBWbtLG28w4jF1eMaHQE3NOR4DHCJQ8ReqSyHSTqAd0BYfzj/kkBQIkFGimKgYrtjKzcckYpQIzkfeyxxwy7nrBKI32ZUkIyA1TAf80111ipi4rNb9R4pswwlmGYw9JNunz4HYcqj3GMcTsdBIccpMP5MXQ6qO7z7FEKoCYDOMDNii2AzdE/PAfYSFOkLcBERWbKinliOgJWjDEVhREMD5AJzwovrqQJ+FlgAtiR3Oeee+7e7Y+nnnrqXgt4j1ayg8Q9oDsgjH/c/yiAlGT+mPPIACDAmz17tpWeDz30kAUzKjGSFjCyrJRVZKw8c+o1v5OnnphOYuwNmFkgggqOBCYdN2/N0k+kM3mjgjPFli6jmVe5+x/f+hJ3QAHU6YsvvtgCEvUZCYxxjLXVgJKpqOuvv97kSOpOmDDBLgDhCmhRlRl7o6IjyZ2FnDQGlwy2zyceNdHOUa/6cJXJDmfb00gxjBEfoCP9keBucUsHxeyZx+0WfQ/oniHvYZ+qzvA10XhMnj3Gh7bdsetE1MqyUSP2RkNKtsaiZuiIoWbYiGGGMo0cM8pKz2IBgPelQ0vtIfqo3rl6Vjy4ROFiiue+URcw5ePLTWsiamoaaqwfPHSwqRhfYTKzw2b0uDGKryks/YEpJWk7g0/i7y1Oj95AZybpPKB7lMyHb+Kbaz42D7zzSwOW06V+por6ACUQCJq4KkNdQtGQeefd5/pUvShjdcM28/8BKOhvDwlXEMQAAAAASUVORK5CYII=)\n",
        "\n",
        "dbr:Apocalypto a dbo:Film . <br>\n",
        "dbr:Apocalypto dbo:language dbr:Yucatec_Maya_language .  <br>\n",
        "dbr:Yucatec_Maya_language dbp:region \"Yucatán, Quintana Roo, Campeche, northern Belize\"@en . )\n",
        "\n",
        "__Réponse : 1__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bOCIScB1Oxs"
      },
      "source": [
        "### Authors\n",
        "- Guilhem Garnier 2230323\n",
        "- Pierre Crochelet 2161844\n",
        "- Vi Retault 2164296\n",
        "- Pierre Gallou-Guyot 2227094"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEMylxPCPFgp"
      },
      "source": [
        "## 2. LIBRARIES PERMISES\n",
        "- Numpy\n",
        "- Pandas\n",
        "- HuggingFace\n",
        "- Keras\n",
        "- NLTK\n",
        "- SPACY\n",
        "- Pytorch\n",
        "- re\n",
        "\n",
        "\n",
        "- Pour toute autre librairie, demandez à votre chargé de laboratoire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFHoV-vcPYWw"
      },
      "source": [
        "## 3. INFRASTRUCTURE\n",
        "\n",
        "- Vous avez accès aux GPU du local L-4818. Dans ce cas, vous devez utiliser le dossier temp (voir le tutoriel VirtualEnv.pdf)\n",
        "- Vous pouvez aussi utiliser l’environnement Google Colab :  https://colab.research.google.com/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZmv6OCzPY8h"
      },
      "source": [
        "## 4. ECHÉANCE\n",
        "\n",
        "- Fin de la session. La date précise sera indiquée sur Moodle.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSlDX8dEPjWE"
      },
      "source": [
        "## 5. KAGGLE\n",
        "\n",
        "Le TP4-projet se fera sous forme d’une compétition Kaggle.  Vous devrez utiliser l’environnement Kaggle pour la soumission et l’évaluation de vos modèles.  \n",
        "Pour tester votre système au fur et à mesure, vous aurez le droit à 4 soumissions par jour sur Kaggle. Vous verrez deux types de résultats sur votre « private leaderboard » et votre « public leaderboard » :\n",
        "- Le « public leaderboard » est calculé sur approximativement 30% des données de test, choisies aléatoirement par Kaggle. Ce score est public et est calculé sur la même tranche de donnée pour tous les participants.\n",
        "- Le « private leaderboard » est calculé sur approximativement 70% des données de test et n’est visible qu’à la fin de la compétition. Le résultat final sera basé sur ce leaderboard. Si aucune soumission n’est choisie, la soumission avec le meilleur score sur le « public leaderboard » sera utilisée pour calculer le score sur le « private leaderboard ».\n",
        "\n",
        "Pour l’évaluation, vous devrez soumettre un fichier de données _tp4_submission.csv_ du même format que le fichier _sample_submission.csv_ (disponible sur le site de la compétition et Moodle). _tp4_submission.csv_ devra contenir pour chaque ligne de votre ensemble de test, la requête retournée par votre approche, selon le format indiqué dans la compétition.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN3Q1FqLQJhX"
      },
      "source": [
        "## 6. DESCRIPTION DES DONNEES ET METRIQUES D’EVALUATION\n",
        "\n",
        "Le corpus est un corpus de 5 000 paires de questions - requêtes sur DBPedia portant sur une grande variété de thèmes plus ou moins spécifiques. Trois documents sont fournis :\n",
        "\n",
        "-\tLes 4000 paires de questions – requêtes d’entrainement dans un fichier train.csv.\n",
        "-\tLes 500 paires de questions – requêtes de validation dans un fichier validation.csv.\n",
        "-\tLes 500 questions de test pour lesquelles vous devez générer des requêtes SPARQL dans un fichier test.csv.\n",
        "\n",
        "La sortie de votre modèle sera comparée à notre ensemble de référence. Vous serez évalués en utilisant la métrique « accuracy » sur les requêtes prédites par vos modèles dans la compétition Kaggle. Cette métrique vérifie pour chaque requête prédite par votre modèle si elle est exactement égale à la requête attendue. Faite donc bien attention aux requêtes générées : un seul caractère non correct fait compter la requête comme fausse.\n",
        "\n",
        "Nous vous demandons également de rapporter, dans votre notebook uniquement, la métrique BLEU de votre modèle sur l’ensemble de validation. Cette métrique est très utilisée dans les tâches de traduction automatique et nous vous fournissons une fonction qui la calcule. Pour plus d’information voir https://en.wikipedia.org/wiki/BLEU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "123Zds9PQMIN"
      },
      "source": [
        "## 7. ETAPES DU TP\n",
        "\n",
        "A partir de ce notebook squelette, vous devez réaliser les étapes suivantes. (Notez que les cellules dans le squelette sont là à titre informatif il est fort probable que vous rajoutiez des sections au fur et à mesure de votre TP).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyOPA9qmQPc8"
      },
      "source": [
        "### 7.1. Etat de l’art (5%)\n",
        "\n",
        "Décrivez en __deux paragraphes__, dans une cellule du notebook, avec les références appropriées, les architectures de l’état de l’art pour la génération de requêtes SPARQL. Utilisez le service Google Scholar. Voici quelques mots-clés : Neural Machine Translation SPARQL, SPARQL Sequence to Sequence Model, etc.\n",
        "\n",
        "En vous basant sur vos recherches et sur cet article, quelles sont les meilleures techniques de l’état de l’art ?  Soyez brefs et clairs. Attention à comparer des approches sur les mêmes jeux de données et en utilisant les mêmes métriques dans votre analyse.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTLHkK0t1Oxw"
      },
      "source": [
        "Dans un article de Yin et al. [1] de 2021, 8 variations au total de 3 architectures de réseaux neuronaux ont été testées pour la génération de requêtes SPARQL. Les tests ont été menés sur 5 datasets en considant comme métrique le score BLEU et l'Accuracy. Parmi ces modèles, le modèle à convolution ConvS2S donnait les meilleurs résultats, suivi par par un modèle Transformer. Il est cependant mentionné que tous ces modèles souffrent du même problème: les mots hors vocabulaire (oov words). En effet, de par leur nature, les requêtes SPARQL contiennent souvent de nouveaux mots. Diomedi et al. [2] proposent une première manière de résoudre ce problème à l'aide de \"entity linking\". Certains mots se voient alors réduits seulement à leur fonction dans la phrase ce qui permet dans certains cas de prendre en compte les mots oov. Par exemple, un mot sera remplacé par la balise <'subj'> puis recopié dans la requête finale.\n",
        "\n",
        "Dans un article de novembre 2022, Hirigoyen et al. [3] mentionnent également les limites de cette approche à vocabulaire fini. Pour palier cela, Hirigoyen et al. proposent d'implémenter le mécanisme de copie, tel qu'introduit dans CopyNet par Gu et al. [4] à une architecture encodeur-decodeur en l'insérant juste après le décodeur. Ce mécanisme de copie utilise les mots clés présent dans la question pour aider à la génération des requêtes. Les auteur·rices comparent leurs résultats à l'approche utilisée par Yin et al. et obtiennent de bien meilleurs résultats en utilisant les métriques BLEU et accuracy. Cette méthode semble être l'état de l'art pour un modèle de génération de requête SPARQL sans pré-entrainement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb8mP4So1Oxw"
      },
      "source": [
        "[1] : Yin, X., Gromann, D., & Rudolph, S. (2021). Neural machine translating from natural language to SPARQL. Future Generation Computer Systems, 117, 510-519. </br>\n",
        "[2] : Diomedi, D., and A. Hogan. 2021. Question Answering over Knowl-edge  Graphs  with  Neural  Machine  Translation  and  Entity  Linking.arXiv:2107.02865 [cs.AI]. </br>\n",
        "[3] : Hirigoyen, R., Zouaq, A., & Reyd, S. (2022). A Copy Mechanism for Handling Knowledge Base Elements in SPARQL Neural Machine Translation. arXiv preprint arXiv:2211.10271. </br>\n",
        "[4] : Gu, J., Lu, Z., Li, H., & Li, V. O. (2016). Incorporating copying mechanism in sequence-to-sequence learning. arXiv preprint arXiv:1603.06393."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3mcb6v3QUVl"
      },
      "source": [
        "### 7.2. Méthodologie\n",
        "#### 7.2.1. Architecture proposée (5%)\n",
        "\n",
        "Proposez une architecture d'encodeur-décodeur non pré-entrainée de type Transformer ou CNN pour la tâche. Décrivez l’architecture et la méthodologie en quelques lignes dans une cellule de texte."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1Z9pVya1Oxx"
      },
      "source": [
        "Pour la tâche, on propose d’utiliser une architecture de type Transformer. Cette architecture combine un encodeur et un décodeur qui sont des piles de même taille (ici, 6) de couches identiques sans partage des poids. Ces couches sont formées de 3 couches d’attention multi-têtes détaillées ci-dessous, d’une couche d’attention croisée (pour le décodeur uniquement) et d’un réseau à propagation avant dense à 1 couche cachée. Aussi, la sortie de chaque couche est normalisée avant d'être passée à la couche suivant. Au sommet de la pile de décodeurs, une tête de classification (classificateur neuronal composé d’une couche linéaire suivie d’un softmax) permet de retourner un mot du vocabulaire de sortie.\n",
        "\n",
        "La pile d’encodeurs reçoit en entrée une représentation de la séquence d'entrée (en anglais dans ce cas) sous forme de plongements lexicaux (embeddings) auxquels on a sommé des « plongements de position » (positional embeddings) permettant de retrouver une notion de distance entre les mots de la séquence. Pour chaque couche d'encodeur, il y a ensuite une couche de self-attention globale avec un masque permettant de différencer les mots du padding et enfin le réseau à propagation avant. La sortie de la pile d’encodeurs est une représentation de toute la séquence d’entrée.\n",
        "\n",
        "La pile de décodeurs reçoit en entrée une représentation de la séquence de sortie (en sparql dans ce cas) sous forme de plongement lexicaux (embeddings) auxquels on a sommé des « plongements de position » (positional embeddings) permettant de retrouver une notion de distance entre les mots de la séquence. Pour chaque couche décodeur, il y a ensuite la couche de self-attention masquée. Le masque ici assure que la sortie pour l'élément d'une séquence ne dépend que des éléments précédents. Puis on retrouve le module d’attention croisée avec la sortie du module d'encodeur avant le réseau à propagation avant. Finalement, une fois ces opérations faites pour chaque couche décodeur, la sortie du dernier décodeur passe dans un réseau linéaire puis un l'application d'un softmax permet de diriger le décodeur vers la génération du « meilleur » token, à partir de début de la phrase et de la représentation de toute la séquence d’entrée de l’encodeur, qui est ce que l’on souhaite traduire avec cette architecture.\n",
        "\n",
        "Au cours de l’entraînement, nous fournissons des paires de requêtes en langue naturelle prétraitées (suppression des espaces/tabulations, ajout de \\<S> au début et de \\</S> à la fin et padding pour atteindre une longueur de 5000 par défaut pour toutes les requêtes d'un même batch) qu’on donne en entrée de l’encodeur, et les requêtes SPARQL correspondantes (qui sont la sortie attendue du décodeur). Nous entraînons le modèle sur 200 epochs avec une taille de batch de 200, en diminuant la cross-entropy loss entre les tokens générés par le décodeur et les tokens attendus dans l’exemple."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOvcuz0A1VhQ"
      },
      "source": [
        "#### 7.2.2. Mise en place (45%)\n",
        "\n",
        "Mettez en place la solution proposée dans la partie précédente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bB43sZwH1Oxy"
      },
      "source": [
        "Le code qui suit est inspiré de [The annotated transformer](https://nlp.seas.harvard.edu/annotated-transformer/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEr2a4Ig1Oxz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import log_softmax\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import copy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from typing import List, Tuple\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    \"\"\"An transformer as encoder decoder pair\"\"\"\n",
        "    def __init__(self, src_vocab, tgt_vocab, N, d_model, d_ff, h, dropout, maxlen=5000):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.src_embeddings = Embeddings(d_model, src_vocab)\n",
        "        self.tgt_embeddings = Embeddings(d_model, tgt_vocab)\n",
        "        self.positionalEncoding = PositionalEncoding(d_model, dropout, maxlen)\n",
        "        self.encoder = Encoder(EncoderLayer(h, d_model, d_ff, dropout), N)\n",
        "        self.decoder = Decoder(DecoderLayer(h, d_model, d_ff, dropout), N)\n",
        "        self.proj = nn.Linear(d_model, tgt_vocab)\n",
        "        self.generator = Generator(d_model, tgt_vocab)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
        "        x = self.encode(src, src_mask)\n",
        "        x = self.decode(x, src_mask, tgt, tgt_mask)\n",
        "        x = self.generator(x)\n",
        "        return x\n",
        "\n",
        "    def encode(self, src, src_mask):\n",
        "        \"\"\"Apply transformer's encoders with source embedding and positional encoding\"\"\"\n",
        "        x = self.src_embeddings(src)\n",
        "        x = self.positionalEncoding(x)\n",
        "        x = self.encoder(x, src_mask)\n",
        "        return x\n",
        "\n",
        "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
        "        \"\"\"Apply transformer's encoders with target embedding and positional encoding\"\"\"\n",
        "        x = self.tgt_embeddings(tgt)\n",
        "        x = self.positionalEncoding(x)\n",
        "        x = self.decoder(x, memory, src_mask, tgt_mask)\n",
        "        return x\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"Simple linear layer with log softmax\"\"\"\n",
        "    def __init__(self, d_model, tgt_vocab):\n",
        "        super(Generator, self).__init__()\n",
        "        self.proj = nn.Linear(d_model, tgt_vocab)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return log_softmax(self.proj(x), dim=-1)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"A encoder is a stack of N identical layers\"\"\"\n",
        "    def __init__(self, layer, N):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([copy.deepcopy(layer) for _ in range(N)])\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, src_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, src_mask)\n",
        "        return self.norm(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"A decoder is a stack of N identical layer with memory of the encoder output\"\"\"\n",
        "    def __init__(self, layer, N):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([copy.deepcopy(layer) for _ in range(N)])\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, memory, src_mask, tgt_mask)\n",
        "        return self.norm(x)\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    \"\"\"Each encoder layer is self attention and feed forward\"\"\"\n",
        "\n",
        "    def __init__(self, h, d_model, d_ff, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attention = MultiHeadedAttention(h, d_model, dropout)\n",
        "        self.feed_forward = FeedForward(d_model, d_ff, dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.norm1 = LayerNorm(d_model)\n",
        "        self.norm2 = LayerNorm(d_model)\n",
        "        self.size = d_model\n",
        "\n",
        "    def forward(self, x, src_mask):\n",
        "        # Add and norm self attention\n",
        "        x = x + self.norm1(self.dropout(self.self_attention(x, x, x, src_mask)))\n",
        "        # Add and norm feed forward\n",
        "        x = x + self.norm2(self.dropout(self.feed_forward(x)))\n",
        "        return x\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    \"\"\"Each decoder layer is self attention, cross attention and feed forward\"\"\"\n",
        "\n",
        "    def __init__(self, h, d_model, d_ff, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attention = MultiHeadedAttention(h, d_model, dropout)\n",
        "        self.cross_attention = MultiHeadedAttention(h, d_model, dropout)\n",
        "        self.feed_forward = FeedForward(d_model, d_ff, dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.norm1 = LayerNorm(d_model)\n",
        "        self.norm2 = LayerNorm(d_model)\n",
        "        self.norm3 = LayerNorm(d_model)\n",
        "        self.size = d_model\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        # Add and norm masked self attention\n",
        "        x = x + self.norm1(self.dropout(self.self_attention(x, x, x, tgt_mask)))\n",
        "        # Add and norm cross attention\n",
        "        x = x + self.norm2(self.dropout(self.cross_attention(x, memory, memory, src_mask)))\n",
        "        # Add and norm feed forward\n",
        "        x = x + self.norm3(self.dropout(self.feed_forward(x)))\n",
        "        return x\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    \"\"\"Fully connected feed forward network\"\"\"\n",
        "\n",
        "    def __init__(self, d_model, d_ff, dropout):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.layer1 = nn.Linear(d_model, d_ff)\n",
        "        self.layer2 = nn.Linear(d_ff, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer2(self.dropout(self.layer1(x).relu()))\n",
        "\n",
        "def attention(query, key, value, mask=None, dropout=None):\n",
        "    \"\"\"Compute attention\"\"\"\n",
        "    d_k = query.size(-1)\n",
        "    scores = torch.matmul(query, key.transpose(-2, -1))/math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)\n",
        "    attn_coeffs = scores.softmax(dim=-1)\n",
        "    if dropout is not None:\n",
        "        attn_coeffs = dropout(attn_coeffs)\n",
        "\n",
        "    return torch.matmul(attn_coeffs, value), attn_coeffs\n",
        "\n",
        "\n",
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, h, d_model, dropout=0.1):\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        assert d_model % h == 0\n",
        "\n",
        "        self.d_k = d_model // h\n",
        "        self.h = h\n",
        "        self.linearV = nn.Linear(d_model, d_model)\n",
        "        self.linearK = nn.Linear(d_model, d_model)\n",
        "        self.linearQ = nn.Linear(d_model, d_model)\n",
        "        self.linearOutput = nn.Linear(d_model, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        if mask is not None:\n",
        "            # Apply mask to all heads\n",
        "            mask = mask.unsqueeze(1)\n",
        "        nbatches = query.size(0)\n",
        "\n",
        "        # Linear projections and split into multiple heads\n",
        "        query = self.linearQ(query).view(nbatches, -1, self.h, self.d_k).transpose(1,2)\n",
        "        key = self.linearK(key).view(nbatches, -1, self.h, self.d_k).transpose(1,2)\n",
        "        value = self.linearV(value).view(nbatches, -1, self.h, self.d_k).transpose(1,2)\n",
        "\n",
        "        # Apply Attention\n",
        "        x, attn_coeffs = attention(query, key, value, mask=mask, dropout=self.dropout)\n",
        "\n",
        "        # Concat back into a single attention matrix\n",
        "        x = x.transpose(1,2).reshape(nbatches, -1, self.h*self.d_k)\n",
        "\n",
        "        # Apply final linear\n",
        "        x = self.linearOutput(x)\n",
        "        return x\n",
        "\n",
        "class Embeddings(nn.Module):\n",
        "    def __init__(self, d_model, vocab):\n",
        "        super(Embeddings, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab, d_model)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.embedding(x) * math.sqrt(self.d_model)\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000)/d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "\n",
        "        # Not a model p/arameter but needs to be on the same device as model parameters\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)].requires_grad_(False)\n",
        "        return self.dropout(x)\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    \"Construct a layernorm module (See citation for details).\"\n",
        "\n",
        "    def __init__(self, features, eps=1e-6):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.a_2 = nn.Parameter(torch.ones(features))\n",
        "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
        "\n",
        "def subsequent_mask(size):\n",
        "    \"\"\"Mask subsequent positions\"\"\"\n",
        "    attn_shape = (1, size, size)\n",
        "    subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(torch.uint8)\n",
        "    return subsequent_mask == 0\n",
        "\n",
        "def make_std_mask(tgt, pad):\n",
        "    \"Create a mask to hide padding and future words.\"\n",
        "    tgt_mask = (tgt != pad).unsqueeze(-2)\n",
        "    tgt_mask = tgt_mask & subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data)\n",
        "    return tgt_mask\n",
        "\n",
        "def rate(step, model_size, factor, warmup):\n",
        "    \"\"\"Learning rate schedule\"\"\"\n",
        "    if step == 0:\n",
        "        step = 1\n",
        "    return factor*(model_size**(-0.5)*min(step**(-0.5), step*warmup**(-1.5)))\n",
        "\n",
        "def make_model(src_vocab, tgt_vocab, N=5, d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
        "    model = Transformer(src_vocab, tgt_vocab, N, d_model, d_ff, h, dropout)\n",
        "    # Initialize model parameters with uniform weights\n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "    return model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4y7AyOYv1Ox1",
        "outputId": "f9327b56-52fb-4848-80cf-f0b7671fb368",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example Untrained Model Prediction: tensor([[ 0, 10,  4, 10,  4,  1,  4, 10,  4, 10]], device='cuda:0')\n",
            "Example Untrained Model Prediction: tensor([[0, 6, 6, 6, 6, 6, 6, 6, 6, 6]], device='cuda:0')\n",
            "Example Untrained Model Prediction: tensor([[0, 9, 9, 4, 9, 9, 9, 9, 9, 9]], device='cuda:0')\n",
            "Example Untrained Model Prediction: tensor([[0, 1, 6, 6, 6, 6, 1, 6, 6, 6]], device='cuda:0')\n",
            "Example Untrained Model Prediction: tensor([[ 0,  0,  0,  0,  0,  0,  0,  0, 10,  0]], device='cuda:0')\n",
            "Example Untrained Model Prediction: tensor([[0, 4, 3, 3, 3, 3, 3, 3, 2, 2]], device='cuda:0')\n",
            "Example Untrained Model Prediction: tensor([[0, 6, 6, 6, 6, 6, 6, 6, 6, 6]], device='cuda:0')\n",
            "Example Untrained Model Prediction: tensor([[0, 1, 6, 9, 9, 9, 9, 9, 9, 9]], device='cuda:0')\n",
            "Example Untrained Model Prediction: tensor([[ 0, 10, 10, 10, 10, 10, 10, 10, 10, 10]], device='cuda:0')\n",
            "Example Untrained Model Prediction: tensor([[ 0,  6,  4,  2, 10,  9,  2,  9,  2,  9]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "def inference_test():\n",
        "    test_model = make_model(11, 11, 2)\n",
        "    test_model.eval()\n",
        "    src = torch.LongTensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]]).to(device)\n",
        "    src_mask = torch.ones(1, 1, 10).to(device)\n",
        "\n",
        "    memory = test_model.encode(src, src_mask)\n",
        "    ys = torch.zeros(1, 1).type_as(src).to(device)\n",
        "\n",
        "    for i in range(9):\n",
        "        out = test_model.decode(\n",
        "            memory, src_mask, ys, subsequent_mask(ys.size(1)).type_as(src.data)\n",
        "        )\n",
        "        prob = test_model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.data[0]\n",
        "        ys = torch.cat(\n",
        "            [ys, torch.empty(1, 1).type_as(src.data).fill_(next_word)], dim=1\n",
        "        )\n",
        "\n",
        "    print(\"Example Untrained Model Prediction:\", ys)\n",
        "\n",
        "\n",
        "for _ in range(10):\n",
        "    inference_test()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEzMaRjA1Ox2"
      },
      "outputs": [],
      "source": [
        "def data_gen(V, batch_size, nbatches):\n",
        "    data_size = batch_size*nbatches\n",
        "    pad = 0\n",
        "    data = torch.randint(1, V, size=(data_size, 10))\n",
        "    data[:, 0] = 1\n",
        "    src = data\n",
        "    src_mask = (src != pad).unsqueeze(-2)\n",
        "    tgt = data[:,:-1]\n",
        "    tgt_y = data[:,1:]\n",
        "    tgt_mask = make_std_mask(tgt, pad)\n",
        "    dataset = TensorDataset(src, tgt, tgt_y, src_mask, tgt_mask)\n",
        "    return DataLoader(dataset, batch_size=batch_size, pin_memory=True)\n",
        "\n",
        "def greedy_decode(model, src, src_mask, max_len, start_symbol, end_symbol=None):\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.zeros(1, 1).fill_(start_symbol).type_as(src.data).to(device)\n",
        "    for _ in range(max_len - 1):\n",
        "        out = model.decode(\n",
        "            memory, src_mask, ys, subsequent_mask(ys.size(1)).type_as(src.data)\n",
        "        )\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.data[0]\n",
        "        ys = torch.cat(\n",
        "            [ys, torch.zeros(1, 1).type_as(src.data).fill_(next_word)], dim=1\n",
        "        )\n",
        "        if next_word==end_symbol:\n",
        "            break\n",
        "    return ys\n",
        "\n",
        "def train_simple_task():\n",
        "    V = 11\n",
        "    train = data_gen(V, 80, 20)\n",
        "    validation = data_gen(V, 80, 5)\n",
        "\n",
        "    model = make_model(V, V, N=2)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.5, betas=(0.9, 0.98), eps=1e-9)\n",
        "    scheduler = LambdaLR(optimizer=optimizer, lr_lambda=lambda step: rate(step, model_size=model.d_model, factor=1.0, warmup=400))\n",
        "    loss_function = nn.CrossEntropyLoss(ignore_index=0, label_smoothing=0)\n",
        "\n",
        "    train_loss = []\n",
        "    validation_loss = []\n",
        "\n",
        "    for epoch in tqdm(range(20), desc=\"epoch\"):\n",
        "        # Run epoch train\n",
        "        model.train()\n",
        "        for i, batch in enumerate(train):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            src, tgt, tgt_y, src_mask, tgt_mask = [a.to(device) for a in batch]\n",
        "            out = model.forward(src, tgt, src_mask, tgt_mask).view(-1,V)\n",
        "            tgt_y = tgt_y.view(-1)\n",
        "            loss = loss_function(out, tgt_y)\n",
        "            train_loss.append(loss.item())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "        # Run epoch eval\n",
        "        model.eval()\n",
        "        for i, batch in enumerate(validation):\n",
        "            src, tgt, tgt_y, src_mask, tgt_mask = [a.to(device) for a in batch]\n",
        "            out = model.forward(src, tgt, src_mask, tgt_mask).view(-1, V)\n",
        "            tgt_y = tgt_y.view(-1)\n",
        "            loss = loss_function(out, tgt_y)\n",
        "            validation_loss.append(loss.item())\n",
        "\n",
        "    model.eval()\n",
        "    src = torch.LongTensor([[0,1,2,3,4,5,6,7,8,9]]).to(device)\n",
        "    max_len = src.shape[1]\n",
        "    src_mask = torch.ones(1, 1, max_len).to(device)\n",
        "    ys = greedy_decode(model, src, src_mask, max_len=max_len, start_symbol=0)\n",
        "    print(ys)\n",
        "    return torch.equal(ys,torch.tensor([[0,1,2,3,4,5,6,7,8,9]]).to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYkxTH8R1Ox3"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
        "from nltk.lm import Vocabulary\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "padding_id = 0\n",
        "tokenizer = RegexpTokenizer('\\s+', gaps=True)\n",
        "\n",
        "class Vocab(Vocabulary):\n",
        "    def __init__(self, tokens, unk_cutoff=1):\n",
        "        super().__init__(np.insert(np.concatenate(tokens.tolist()), 0, [\"<BLANK>\"]), unk_cutoff=unk_cutoff)\n",
        "        self.word_to_id_dict = {word:i for i,word in enumerate(self)}\n",
        "        self.id_to_word_dict = {i:word for i,word in enumerate(self)}\n",
        "\n",
        "    def word_to_id(self, words):\n",
        "        if type(words) is list or type(words) is Tuple or type(words) is np.ndarray:\n",
        "            return [self.word_to_id_dict[a] for a in self.lookup(words)]\n",
        "        return self.word_to_id_dict[self.lookup(words)]\n",
        "\n",
        "    def id_to_word(self, ids):\n",
        "        if type(ids) is list or type(ids) is Tuple or type(words) is np.ndarray:\n",
        "            return [self.id_to_word_dict[a] for a in ids]\n",
        "        return self.id_to_word_dict[ids]\n",
        "\n",
        "def tokenize(df):\n",
        "    tokens = pd.DataFrame()\n",
        "    for column in df.columns:\n",
        "        tokens[column] = df[column].apply(tokenizer.tokenize).apply(np.insert, args=(0, \"<S>\")).apply(np.append, args=[\"</S>\"])\n",
        "    return tokens\n",
        "\n",
        "def vectorize(tokens, vocab):\n",
        "    return tokens.apply(vocab.word_to_id).apply(torch.tensor)\n",
        "\n",
        "train_df = pd.read_csv(\"data/train.csv\", index_col=0)\n",
        "validation_df = pd.read_csv(\"data/validation.csv\", index_col=0)\n",
        "test_df = pd.read_csv(\"data/test.csv\", index_col=0)\n",
        "\n",
        "train_tokens = tokenize(train_df)\n",
        "validation_tokens = tokenize(validation_df)\n",
        "test_tokens = tokenize(test_df)\n",
        "\n",
        "maxlen = max(train_tokens[\"sparql\"].apply(len))+10\n",
        "\n",
        "english_vocab = Vocab(train_tokens[\"english\"])\n",
        "sparql_vocab = Vocab(train_tokens[\"sparql\"])\n",
        "\n",
        "train_english_tensors = vectorize(train_tokens[\"english\"], english_vocab)\n",
        "train_sparql_tensors = vectorize(train_tokens[\"sparql\"], sparql_vocab)\n",
        "validation_english_tensors = vectorize(validation_tokens[\"english\"], english_vocab)\n",
        "validation_sparql_tensors = vectorize(validation_tokens[\"sparql\"], sparql_vocab)\n",
        "test_english_tensors = vectorize(test_tokens[\"english\"], english_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQ9qK1W21Ox4"
      },
      "outputs": [],
      "source": [
        "## Hyper paramètres\n",
        "batch_size = 200\n",
        "validation_batch_size = 200\n",
        "nb_epoch = 200\n",
        "N = 6\n",
        "lr = 0.1\n",
        "betas = (0.9, 0.98)\n",
        "eps = 1e-9\n",
        "factor = 1.0\n",
        "warmup = 400\n",
        "label_smoothing = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMl7UhfL1Ox4"
      },
      "outputs": [],
      "source": [
        "def collate_batch(batch):\n",
        "  \"\"\"Pad batch value with zeros\"\"\"\n",
        "  src = [a[\"src\"] for a in batch]\n",
        "  tgt = [a[\"tgt\"] for a in batch]\n",
        "  src = pad_sequence(src, batch_first=True, padding_value=padding_id)\n",
        "  tgt = pad_sequence(tgt, batch_first=True, padding_value=padding_id)\n",
        "\n",
        "  src_mask = (src != padding_id).unsqueeze(-2)\n",
        "  tgt, tgt_y = tgt[:,:-1], tgt[:,1:]\n",
        "  tgt_mask = make_std_mask(tgt, padding_id)\n",
        "\n",
        "  return src, tgt, tgt_y, src_mask, tgt_mask\n",
        "\n",
        "class TranslateDataset(Dataset):\n",
        "  def __init__(self, src, tgt):\n",
        "    super().__init__()\n",
        "    assert len(src) == len(src)\n",
        "    self.src = src\n",
        "    self.tgt = tgt\n",
        "    self.len = len(src)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.len\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return {\"src\":self.src[idx], \"tgt\": self.tgt[idx]}\n",
        "\n",
        "def prepare_data(src, tgt, batch_size):\n",
        "  dataset = TranslateDataset(src, tgt)\n",
        "  return DataLoader(dataset, collate_fn=collate_batch, batch_size=batch_size, pin_memory=True)\n",
        "\n",
        "train = prepare_data(train_english_tensors, train_sparql_tensors, batch_size)\n",
        "validation = prepare_data(validation_english_tensors, validation_sparql_tensors, validation_batch_size)\n",
        "src_vocab = english_vocab\n",
        "tgt_vocab = sparql_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "335c42c933cb414492d90ca68df647bc",
            "39f93afa6c1b48ed91354ce465864fba",
            "38d530fbc45747f5909c97d9350dc5d3",
            "c3965144772042609340da39f2d7db45",
            "546fe184b05142eb987adce753f7721c",
            "b00ebea5ac3a48d6947ee086d3465563",
            "0dbac25f8b654162a08094973a408ec9",
            "4cdde9d0c52b417bb0426a4561620cb6",
            "86618c371641477a8cf45f8ab014f360",
            "452ecb199a6841a2af9d3093bf7430a7",
            "80e82bdc68a2447f97565413315acd99"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "awSfK9nH1Ox5",
        "outputId": "1563d7ef-49bc-4233-8b22-6de34e190d55"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "335c42c933cb414492d90ca68df647bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 0 train_loss=7.893208575248718 validation_loss=6.854603131612142\n",
            "EPOCH 1 train_loss=6.546305370330811 validation_loss=5.9097358385721845\n",
            "EPOCH 2 train_loss=5.781983661651611 validation_loss=5.085222085316976\n",
            "EPOCH 3 train_loss=4.818444418907165 validation_loss=3.920821189880371\n",
            "EPOCH 4 train_loss=3.8556293129920958 validation_loss=3.458643118540446\n",
            "EPOCH 5 train_loss=3.4083587169647216 validation_loss=3.193674166997274\n",
            "EPOCH 6 train_loss=3.163816225528717 validation_loss=3.0346078077952066\n",
            "EPOCH 7 train_loss=2.985628771781921 validation_loss=2.8895210425059\n",
            "EPOCH 8 train_loss=2.8424524068832397 validation_loss=2.7729955514272056\n",
            "EPOCH 9 train_loss=2.7327893018722533 validation_loss=2.7007784843444824\n",
            "EPOCH 10 train_loss=2.6472271919250487 validation_loss=2.653914133707682\n",
            "EPOCH 11 train_loss=2.5846450567245483 validation_loss=2.614093065261841\n",
            "EPOCH 12 train_loss=2.532915508747101 validation_loss=2.582436720530192\n",
            "EPOCH 13 train_loss=2.487732398509979 validation_loss=2.5615214506785073\n",
            "EPOCH 14 train_loss=2.4498802542686464 validation_loss=2.5442917346954346\n",
            "EPOCH 15 train_loss=2.4227559328079225 validation_loss=2.5576610565185547\n",
            "EPOCH 16 train_loss=2.401592254638672 validation_loss=2.521130402882894\n",
            "EPOCH 17 train_loss=2.3734341979026796 validation_loss=2.508399486541748\n",
            "EPOCH 18 train_loss=2.3368428587913512 validation_loss=2.484034538269043\n",
            "EPOCH 19 train_loss=2.2971367120742796 validation_loss=2.4586238861083984\n",
            "EPOCH 20 train_loss=2.2494245409965514 validation_loss=2.4219199816385903\n",
            "EPOCH 21 train_loss=2.1999393701553345 validation_loss=2.3858701388041177\n",
            "EPOCH 22 train_loss=2.1270884037017823 validation_loss=2.309222857157389\n",
            "EPOCH 23 train_loss=2.040037399530411 validation_loss=2.23624054590861\n",
            "EPOCH 24 train_loss=1.957875508069992 validation_loss=2.1734439531962075\n",
            "EPOCH 25 train_loss=1.8879850089550019 validation_loss=2.116593678792318\n",
            "EPOCH 26 train_loss=1.822354781627655 validation_loss=2.0676423708597818\n",
            "EPOCH 27 train_loss=1.7693761527538299 validation_loss=2.026839335759481\n",
            "EPOCH 28 train_loss=1.7127153337001801 validation_loss=1.9798035621643066\n",
            "EPOCH 29 train_loss=1.669658714532852 validation_loss=1.9490686257680256\n",
            "EPOCH 30 train_loss=1.6231124937534331 validation_loss=1.9163839022318523\n",
            "EPOCH 31 train_loss=1.5791741251945495 validation_loss=1.8925764163335164\n",
            "EPOCH 32 train_loss=1.5434937655925751 validation_loss=1.8586532672246296\n",
            "EPOCH 33 train_loss=1.5108698606491089 validation_loss=1.8377639055252075\n",
            "EPOCH 34 train_loss=1.4831637024879456 validation_loss=1.8305824597676594\n",
            "EPOCH 35 train_loss=1.4573900997638702 validation_loss=1.8185051282246907\n",
            "EPOCH 36 train_loss=1.4336975812911987 validation_loss=1.8037022352218628\n",
            "EPOCH 37 train_loss=1.4111959338188171 validation_loss=1.7904417514801025\n",
            "EPOCH 38 train_loss=1.3933718144893645 validation_loss=1.784602959950765\n",
            "EPOCH 39 train_loss=1.3787891507148742 validation_loss=1.7765097618103027\n",
            "EPOCH 40 train_loss=1.3597489953041078 validation_loss=1.772734522819519\n",
            "EPOCH 41 train_loss=1.344462478160858 validation_loss=1.7615493138631184\n",
            "EPOCH 42 train_loss=1.3286357343196868 validation_loss=1.7647476991017659\n",
            "EPOCH 43 train_loss=1.317292147874832 validation_loss=1.7474474509557087\n",
            "EPOCH 44 train_loss=1.3004179894924164 validation_loss=1.7398464679718018\n",
            "EPOCH 45 train_loss=1.2865932822227477 validation_loss=1.7371878226598103\n",
            "EPOCH 46 train_loss=1.2765854597091675 validation_loss=1.7327098449071248\n",
            "EPOCH 47 train_loss=1.2665907263755798 validation_loss=1.7277183135350545\n",
            "EPOCH 48 train_loss=1.2586692094802856 validation_loss=1.7298280795415242\n",
            "EPOCH 49 train_loss=1.2559264421463012 validation_loss=1.7212937275568645\n",
            "EPOCH 50 train_loss=1.2441646695137023 validation_loss=1.7208885351816814\n",
            "EPOCH 51 train_loss=1.2359042644500733 validation_loss=1.7142722209294636\n",
            "EPOCH 52 train_loss=1.2278134405612946 validation_loss=1.7100196679433186\n",
            "EPOCH 53 train_loss=1.2223974585533142 validation_loss=1.7124555905659993\n",
            "EPOCH 54 train_loss=1.217868447303772 validation_loss=1.7095364729563396\n",
            "EPOCH 55 train_loss=1.2130588591098785 validation_loss=1.7085326115290325\n",
            "EPOCH 56 train_loss=1.2090113282203674 validation_loss=1.7024115721384685\n",
            "EPOCH 57 train_loss=1.2055277168750762 validation_loss=1.7007815837860107\n",
            "EPOCH 58 train_loss=1.203754061460495 validation_loss=1.7018477121988933\n",
            "EPOCH 59 train_loss=1.2023867905139922 validation_loss=1.6959335803985596\n",
            "EPOCH 60 train_loss=1.1997299790382385 validation_loss=1.6935047308603923\n",
            "EPOCH 61 train_loss=1.1964388132095336 validation_loss=1.6918374300003052\n",
            "EPOCH 62 train_loss=1.194205492734909 validation_loss=1.6875568628311157\n",
            "EPOCH 63 train_loss=1.1930201172828674 validation_loss=1.6924277941385906\n",
            "EPOCH 64 train_loss=1.1908841967582702 validation_loss=1.6847118536631267\n",
            "EPOCH 65 train_loss=1.1910695016384125 validation_loss=1.683246652285258\n",
            "EPOCH 66 train_loss=1.190140688419342 validation_loss=1.6844967206319172\n",
            "EPOCH 67 train_loss=1.190484195947647 validation_loss=1.6811986764272053\n",
            "EPOCH 68 train_loss=1.1891278684139253 validation_loss=1.6758478085199993\n",
            "EPOCH 69 train_loss=1.1869647681713105 validation_loss=1.673749844233195\n",
            "EPOCH 70 train_loss=1.1854130268096923 validation_loss=1.6704270839691162\n",
            "EPOCH 71 train_loss=1.1842583119869232 validation_loss=1.671800971031189\n",
            "EPOCH 72 train_loss=1.1829425752162934 validation_loss=1.6699440081914265\n",
            "EPOCH 73 train_loss=1.1820256054401397 validation_loss=1.6666857798894246\n",
            "EPOCH 74 train_loss=1.182373481988907 validation_loss=1.6712815761566162\n",
            "EPOCH 75 train_loss=1.1826429307460784 validation_loss=1.6715500354766846\n",
            "EPOCH 76 train_loss=1.1815394639968873 validation_loss=1.663166880607605\n",
            "EPOCH 77 train_loss=1.1811019361019135 validation_loss=1.6600778102874756\n",
            "EPOCH 78 train_loss=1.1811439752578736 validation_loss=1.6561581293741863\n",
            "EPOCH 79 train_loss=1.1800255298614502 validation_loss=1.6583826541900635\n",
            "EPOCH 80 train_loss=1.1789706230163575 validation_loss=1.6529743274052937\n",
            "EPOCH 81 train_loss=1.1782120168209076 validation_loss=1.6538902918497722\n",
            "EPOCH 82 train_loss=1.1780969977378846 validation_loss=1.6505409081776936\n",
            "EPOCH 83 train_loss=1.1782709777355194 validation_loss=1.647099534670512\n",
            "EPOCH 84 train_loss=1.1786159932613374 validation_loss=1.6473198731740315\n",
            "EPOCH 85 train_loss=1.1778543710708618 validation_loss=1.6412537495295207\n",
            "EPOCH 86 train_loss=1.1782364010810853 validation_loss=1.6453240315119426\n",
            "EPOCH 87 train_loss=1.1793424427509307 validation_loss=1.6474326054255168\n",
            "EPOCH 88 train_loss=1.177721530199051 validation_loss=1.6392282644907634\n",
            "EPOCH 89 train_loss=1.176290225982666 validation_loss=1.647015889485677\n",
            "EPOCH 90 train_loss=1.175714486837387 validation_loss=1.6402929226557414\n",
            "EPOCH 91 train_loss=1.1754558682441711 validation_loss=1.6422317028045654\n",
            "EPOCH 92 train_loss=1.1758496701717376 validation_loss=1.6416127284367878\n",
            "EPOCH 93 train_loss=1.1757368683815002 validation_loss=1.6349182923634846\n",
            "EPOCH 94 train_loss=1.1756556987762452 validation_loss=1.638224681218465\n",
            "EPOCH 95 train_loss=1.1755933821201325 validation_loss=1.6423489650090535\n",
            "EPOCH 96 train_loss=1.1751138329505921 validation_loss=1.6385596990585327\n",
            "EPOCH 97 train_loss=1.1748968243598938 validation_loss=1.6349252065022786\n",
            "EPOCH 98 train_loss=1.1748316943645478 validation_loss=1.635137637456258\n",
            "EPOCH 99 train_loss=1.1742137253284455 validation_loss=1.6338186264038086\n",
            "EPOCH 100 train_loss=1.1743299186229705 validation_loss=1.6364099582036336\n",
            "EPOCH 101 train_loss=1.1741260528564452 validation_loss=1.6335644324620564\n",
            "EPOCH 102 train_loss=1.1746300399303435 validation_loss=1.6336290041605632\n",
            "EPOCH 103 train_loss=1.1737774312496185 validation_loss=1.6320710976918538\n",
            "EPOCH 104 train_loss=1.1731492042541505 validation_loss=1.629858374595642\n",
            "EPOCH 105 train_loss=1.1729874193668366 validation_loss=1.629872441291809\n",
            "EPOCH 106 train_loss=1.1726127982139587 validation_loss=1.628549337387085\n",
            "EPOCH 107 train_loss=1.1736100971698762 validation_loss=1.6303143898646038\n",
            "EPOCH 108 train_loss=1.173075407743454 validation_loss=1.633072813351949\n",
            "EPOCH 109 train_loss=1.172760969400406 validation_loss=1.6327486038208008\n",
            "EPOCH 110 train_loss=1.1722885489463806 validation_loss=1.6367841561635335\n",
            "EPOCH 111 train_loss=1.1719419479370117 validation_loss=1.6339961687723796\n",
            "EPOCH 112 train_loss=1.1721612870693208 validation_loss=1.631723960240682\n",
            "EPOCH 113 train_loss=1.1724044680595398 validation_loss=1.6246150334676106\n",
            "EPOCH 114 train_loss=1.172645378112793 validation_loss=1.6275661786397297\n",
            "EPOCH 115 train_loss=1.1721065580844878 validation_loss=1.6263797283172607\n",
            "EPOCH 116 train_loss=1.172278392314911 validation_loss=1.628894329071045\n",
            "EPOCH 117 train_loss=1.1715357601642609 validation_loss=1.630060076713562\n",
            "EPOCH 118 train_loss=1.1710827827453614 validation_loss=1.6285855770111084\n",
            "EPOCH 119 train_loss=1.170980590581894 validation_loss=1.6230687697728474\n",
            "EPOCH 120 train_loss=1.1716144979000092 validation_loss=1.6250367959340413\n",
            "EPOCH 121 train_loss=1.1712945580482483 validation_loss=1.6379967133204143\n",
            "EPOCH 122 train_loss=1.1710152208805085 validation_loss=1.6271957953770955\n",
            "EPOCH 123 train_loss=1.1705059647560119 validation_loss=1.6222457091013591\n",
            "EPOCH 124 train_loss=1.170912605524063 validation_loss=1.6218922138214111\n",
            "EPOCH 125 train_loss=1.1717808842658997 validation_loss=1.6327814658482869\n",
            "EPOCH 126 train_loss=1.170869106054306 validation_loss=1.6262375116348267\n",
            "EPOCH 127 train_loss=1.1706866085529328 validation_loss=1.6272671222686768\n",
            "EPOCH 128 train_loss=1.170727950334549 validation_loss=1.6257139444351196\n",
            "EPOCH 129 train_loss=1.1702259361743927 validation_loss=1.6245777606964111\n",
            "EPOCH 130 train_loss=1.1698467254638671 validation_loss=1.623790701230367\n",
            "EPOCH 131 train_loss=1.1696576058864594 validation_loss=1.622193694114685\n",
            "EPOCH 132 train_loss=1.1695394337177276 validation_loss=1.6220380862553914\n",
            "EPOCH 133 train_loss=1.1697501599788667 validation_loss=1.6230167547861736\n",
            "EPOCH 134 train_loss=1.1697058260440827 validation_loss=1.6234513918558757\n",
            "EPOCH 135 train_loss=1.1699564695358275 validation_loss=1.627556602160136\n",
            "EPOCH 136 train_loss=1.1698784589767457 validation_loss=1.6385869979858398\n",
            "EPOCH 137 train_loss=1.1712343096733093 validation_loss=1.6421963373819988\n",
            "EPOCH 138 train_loss=1.1705243825912475 validation_loss=1.6207276582717896\n",
            "EPOCH 139 train_loss=1.169997900724411 validation_loss=1.6343292792638142\n",
            "EPOCH 140 train_loss=1.1696561872959137 validation_loss=1.622200568517049\n",
            "EPOCH 141 train_loss=1.169204342365265 validation_loss=1.6205267906188965\n",
            "EPOCH 142 train_loss=1.169167685508728 validation_loss=1.621437668800354\n",
            "EPOCH 143 train_loss=1.1687375664711 validation_loss=1.6178230047225952\n",
            "EPOCH 144 train_loss=1.168619728088379 validation_loss=1.6178821325302124\n",
            "EPOCH 145 train_loss=1.1685273766517639 validation_loss=1.6171963612238567\n",
            "EPOCH 146 train_loss=1.1684312403202057 validation_loss=1.6154197057088215\n",
            "EPOCH 147 train_loss=1.1683616578578948 validation_loss=1.6379321416219075\n",
            "EPOCH 148 train_loss=1.1682693302631377 validation_loss=1.6256770292917888\n",
            "EPOCH 149 train_loss=1.1682693600654601 validation_loss=1.62044362227122\n",
            "EPOCH 150 train_loss=1.1684274315834045 validation_loss=1.618498682975769\n",
            "EPOCH 151 train_loss=1.1687851071357727 validation_loss=1.6231296459833782\n",
            "EPOCH 152 train_loss=1.1686500251293181 validation_loss=1.6207961241404216\n",
            "EPOCH 153 train_loss=1.168498545885086 validation_loss=1.625048319498698\n",
            "EPOCH 154 train_loss=1.1684759616851808 validation_loss=1.624379555384318\n",
            "EPOCH 155 train_loss=1.1688148021697997 validation_loss=1.6553171873092651\n",
            "EPOCH 156 train_loss=1.1688535690307618 validation_loss=1.6257915894190471\n",
            "EPOCH 157 train_loss=1.168635082244873 validation_loss=1.6196386019388835\n",
            "EPOCH 158 train_loss=1.1679777681827546 validation_loss=1.6180113554000854\n",
            "EPOCH 159 train_loss=1.167996448278427 validation_loss=1.6611441373825073\n",
            "EPOCH 160 train_loss=1.1678273916244506 validation_loss=1.6193619171778362\n",
            "EPOCH 161 train_loss=1.1685615241527558 validation_loss=1.6147241592407227\n",
            "EPOCH 162 train_loss=1.1684898436069489 validation_loss=1.624616026878357\n",
            "EPOCH 163 train_loss=1.168167781829834 validation_loss=1.6199595928192139\n",
            "EPOCH 164 train_loss=1.167757523059845 validation_loss=1.6142661571502686\n",
            "EPOCH 165 train_loss=1.167563658952713 validation_loss=1.614810307820638\n",
            "EPOCH 166 train_loss=1.1674663186073304 validation_loss=1.617351730664571\n",
            "EPOCH 167 train_loss=1.1673354625701904 validation_loss=1.6161405642827351\n",
            "EPOCH 168 train_loss=1.16721630692482 validation_loss=1.6159372329711914\n",
            "EPOCH 169 train_loss=1.1678537547588348 validation_loss=1.6175046761830647\n",
            "EPOCH 170 train_loss=1.167527711391449 validation_loss=1.6198241313298543\n",
            "EPOCH 171 train_loss=1.1673279047012328 validation_loss=1.6144415537516277\n",
            "EPOCH 172 train_loss=1.1671149790287019 validation_loss=1.6164839267730713\n",
            "EPOCH 173 train_loss=1.1671043395996095 validation_loss=1.6212478081385295\n",
            "EPOCH 174 train_loss=1.1670225977897644 validation_loss=1.617614507675171\n",
            "EPOCH 175 train_loss=1.1673460602760315 validation_loss=1.6150234937667847\n",
            "EPOCH 176 train_loss=1.1669901728630065 validation_loss=1.6163562933603923\n",
            "EPOCH 177 train_loss=1.1671099543571473 validation_loss=1.6216772397359211\n",
            "EPOCH 178 train_loss=1.1669545888900756 validation_loss=1.6231655677159627\n",
            "EPOCH 179 train_loss=1.1668145477771759 validation_loss=1.6136572360992432\n",
            "EPOCH 180 train_loss=1.1667986750602721 validation_loss=1.6365673144658406\n",
            "EPOCH 181 train_loss=1.1668269395828248 validation_loss=1.6213701963424683\n",
            "EPOCH 182 train_loss=1.1667534172534944 validation_loss=1.617730736732483\n",
            "EPOCH 183 train_loss=1.1671132445335388 validation_loss=1.6319170395533245\n",
            "EPOCH 184 train_loss=1.1668192863464355 validation_loss=1.6196751594543457\n",
            "EPOCH 185 train_loss=1.166920793056488 validation_loss=1.6163022915522258\n",
            "EPOCH 186 train_loss=1.167065405845642 validation_loss=1.6234888235727947\n",
            "EPOCH 187 train_loss=1.1666985273361206 validation_loss=1.6161282459894817\n",
            "EPOCH 188 train_loss=1.1667345941066742 validation_loss=1.6260606447855632\n",
            "EPOCH 189 train_loss=1.1664835274219514 validation_loss=1.6157389481862385\n",
            "EPOCH 190 train_loss=1.1664513111114503 validation_loss=1.6143837372461955\n",
            "EPOCH 191 train_loss=1.1663375198841095 validation_loss=1.6148258050282795\n",
            "EPOCH 192 train_loss=1.166622567176819 validation_loss=1.6128462950388591\n",
            "EPOCH 193 train_loss=1.1663511514663696 validation_loss=1.6150914033253987\n",
            "EPOCH 194 train_loss=1.166284829378128 validation_loss=1.6222173770268757\n",
            "EPOCH 195 train_loss=1.1661086857318879 validation_loss=1.6185965538024902\n",
            "EPOCH 196 train_loss=1.1662240743637085 validation_loss=1.6143343846003215\n",
            "EPOCH 197 train_loss=1.166140753030777 validation_loss=1.6450487772623699\n",
            "EPOCH 198 train_loss=1.166183340549469 validation_loss=1.6308876276016235\n",
            "EPOCH 199 train_loss=1.1664977848529816 validation_loss=1.6234300533930461\n"
          ]
        }
      ],
      "source": [
        "model = make_model(len(src_vocab), len(tgt_vocab), N=N)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=betas, eps=eps)\n",
        "scheduler = LambdaLR(optimizer=optimizer, lr_lambda=lambda step: rate(step, model_size=model.d_model, factor=factor, warmup=warmup))\n",
        "loss_function = nn.CrossEntropyLoss(ignore_index=padding_id, label_smoothing=label_smoothing)\n",
        "\n",
        "train_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "best_model = copy.deepcopy(model)\n",
        "best_validation_loss = None\n",
        "\n",
        "for epoch in tqdm(range(nb_epoch)):\n",
        "    # Run epoch train\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    for i, batch in enumerate(train):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        src, tgt, tgt_y, src_mask, tgt_mask = [a.to(device) for a in batch]\n",
        "        out = model.forward(src, tgt, src_mask, tgt_mask)\n",
        "        tgt_y = tgt_y.view(-1)\n",
        "        loss = loss_function(out.view(-1, out.size(-1)), tgt_y.view(-1))\n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "    train_loss.append(np.mean(loss_list))\n",
        "    # Run epoch eval\n",
        "    model.eval()\n",
        "    loss_list = []\n",
        "    for i, batch in enumerate(validation):\n",
        "        src, tgt, tgt_y, src_mask, tgt_mask = [a.to(device) for a in batch]\n",
        "        out = model.forward(src, tgt, src_mask, tgt_mask)\n",
        "        loss = loss_function(out.view(-1, out.size(-1)), tgt_y.view(-1))\n",
        "        loss_list.append(loss.item())\n",
        "    validation_loss.append(np.mean(loss_list))\n",
        "    if best_validation_loss is None or validation_loss[-1] < best_validation_loss:\n",
        "        best_validation_loss = validation_loss[-1]\n",
        "        best_model = copy.deepcopy(model)\n",
        "    print(f\"EPOCH {epoch} train_loss={train_loss[-1]} validation_loss={validation_loss[-1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scj_uryX1Ox5",
        "outputId": "9239f8d3-ba28-437a-cb4b-898c5aaf54c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhcZdn48e89k5nsSZs0lG50YS3dS4Syr0LZ19IKKKhQ5cUXeF9Fcfkp8KKiIiKKIAiIsolFdlS2tqBAbQptKd2gtKV70yVp9m3u3x/PSTJNs0yWk0lm7s91nWtmzvKc+5xJ7vOc55x5jqgqxhhjEk8g3gEYY4zxhyV4Y4xJUJbgjTEmQVmCN8aYBGUJ3hhjEpQleGOMSVCW4I2JIiLzROTqLiw3SkRURFL8iKs7ROR4EVkV7zhM77ME30+IyDoROS3ecZjYeAeKk3qgnFtE5LHulKGqb6vqod2NpTf15QNmf2IJ3iSUZEsI4tj/sWmV/WH0cyKSKiJ3i8hmb7hbRFK9aYNE5CURKRGRXSLydmMyEJHviMgmESkTkVUicmob5Z8tIh+IyB4R2SAit0RNO0lENraYv80zDRFJF5Ffish6ESkVkX+JSLo37TwR+ciLdZ6IjI1aTkXkoKjPfxSR26Nj8LZnK/BIe9vdSkyfF5GVXjy/BaTF9K+IyAoR2S0i/xSRke18Ha0SkYCI3Cwia0Rkp4g8LSJ53rTGmuqVIvKZiOwQke9706YD3wNmiki5iCzxxs8TkR+LyL+BSmCMiHzZi7NMRD4Vka9FrX+v78n7jr4lIku97f6LiKRFTT9HRBZ7++8dEZnYYtmbvGUrROQhERksIn/31v26iAyMmn+aV0aJiCyJPqvxtuP/ROTf3rKvisggb/Jb3muJt+1Hd3a/G0BVbegHA7AOOK2V8bcB7wH7AQXAO8D/edN+CtwPhLzheFwCOxTYAAz15hsFHNjGek8CJuAqAxOBbcAFUdM2xhKnN+1eYB4wDAgCxwCpwCFABfB5L85vA58AYW85BQ6KKuePwO1RMdQDP/PKSm9ru1uJZxBQBlzizfc/XllXe9PP9+IYC6QAPwDeaWPbRnlxprQy7QbvOxruxfh74MkWyz3oxT4JqAHGetNvAR5rUd484DNgnBdXCDgbOND7fk/EJf6prX1P3nf0H2AokAesAL7uTZsCbAeO8r6jK735U6OWfQ8Y7H2P24H3veXSgDeBH3nzDgN2Amfh/n4+730uiNqONd73n+59vqOj/WlD7IPV4Pu/y4HbVHW7qhYDtwJf9KbVAUOAkapap64tVoEGXKI5XERCqrpOVde0VriqzlPVD1U1oqpLgSdxCaRTvBr0V4AbVHWTqjao6juqWgPMBF5W1ddUtQ64E/cPf0yMxUdwSaVGVava2e6WzgI+UtU53nrvBrZGTf868FNVXaGq9cBPgMldqMV/Hfi+qm70tvcW4BLZuznpVlWtUtUlwBJcom/PH1X1I1Wt97bxZVVdo8584FXcga0t96jqZlXdBbwITPbGzwZ+r6oLvO/oUdwBZ1rUsr9R1W2qugl4G1igqh+oajXwLC7ZA1wBvKKqr3h/P68BRbj93ugRVV3tfW9PR8VheoAl+P5vKLA+6vN6bxzAL3A10Fe90/abAVT1E+BGXKLZLiJPichQWiEiR4nIXBEpFpFSXLIa1Nq8HRiEq+G1diDZaxtUNYI7wxgWY9nFXnJp1Op2t7HeDVHr1ejPwEjg117zQgmwC1dDjjWu6HKejSpnBe4gOzhqnugDSyWQ1UGZ0XEiImeKyHtek1QJLom29z21tb6RwDcbY/XKGkHz3xS4s7hGVa18ji5rRouyjsMdfDuKw/QAS/D932bcP1KjA7xxqGqZqn5TVccA5wH/K15bu6o+oarHecsqromjNU8ALwAjVDUX1/TR2E5dAWQ0zigiQVwzUWt2ANW4ZoR2t0FEBJdUNnmjKqPXA+zfYvm9auftbXcLW7z1tFxvow3A11R1QNSQrqrvtLGNbdkAnNminDSvBtyRtrp7bRov7prLM7gzn8GqOgB4hRbXEzoR649bxJqhqk92saw/tygrU1XviGFZ6+a2B1iC719CIpIWNaTgmkx+ICIF3gWqHwKPQdPFsoO8xFWKqzVGRORQETnFSwzVuFpXpI11ZgO7VLVaRI4ELouathpIE3chNoRro05trRCvVv4wcJeIDBWRoIgc7cXwNHC2iJzqlfNNXLNAYyJdDFzmLTOdDpqI2truVmZ9GRgnIhd5+/J69j543A98V0TGeeXmisiM9tbdhvuBHzc27Xjf1fkxLrsNGCXt3ykTxu33YqBeRM4ETu9CnOCuBXzdO3MTEcn0vt/sLpT1GHCuiJzhfXdp3gXf4TEsW4z7zsZ0Yb3GYwm+f3kFl4wbh1uA23HtmkuBD3EXvG735j8YeB0oB94Ffqeqc3HJ4A5crXor7gLtd9tY538Bt4lIGe7g8XTjBFUt9ab/AVfbrgA2tlaI51tejAtxzR0/AwKqugrXXvsbL6ZzgXNVtdZb7gZvXAnumsNz7ayjve3ei6ruAGbg9sVOb7l/R01/1ovxKRHZAywDzuxg3a35Ne4s6FVvP76Hu4gZi796rztF5P3WZlDVMtzB6WlgN+4g/EIX4kRVi4BrgN96ZX0CXNXFsjbgLlR/D5ewNwA3EUPeUdVK4MfAv73mnWkdLWP2Ja1fezLGGNPfWQ3eGGMSlCV4Y4xJUJbgjTEmQVmCN8aYBNWnOmYaNGiQjho1Kt5hGGNMv7Fo0aIdqtrq70/6VIIfNWoURUVF8Q7DGGP6DRFZ39Y0a6IxxpgEZQneGGMSlK8JXkT+R1wf38tE5MnoPqeNMcb4y7c2eBEZhvv59OGqWiUiTwOzcH15G2MSXF1dHRs3bqS6urrjmU2H0tLSGD58OKFQKOZl/L7ImgKki0gdrjfAzT6vzxjTR2zcuJHs7GxGjRqF6/fNdJWqsnPnTjZu3Mjo0aNjXs63JhqvK9Q7cU+e2QKUquqrLecTkdkiUiQiRcXFxX6FY4zpZdXV1eTn51ty7wEiQn5+fqfPhnxL8N5zGc8HRuMeFpApIle0nE9VH1DVQlUtLChoqytxY0x/ZMm953RlX/p5kfU0YK2qFnuPQ/sbsT+CrVPueeNj5q+22r8xxkTzM8F/BkwTkQzvwQun4h5V1uN+P38Nb1uCN8ZEKSkp4Xe/+12nlzvrrLMoKSnxIaLe52cb/AJgDu4BFB9663rAj3Wlh4NU1TX4UbQxpp9qK8HX19e3u9wrr7zCgAED/AqrV/l6F42q/gj4kZ/rAEgLWYI3xuzt5ptvZs2aNUyePJlQKERaWhoDBw5k5cqVrF69mgsuuIANGzZQXV3NDTfcwOzZs4HmLlPKy8s588wzOe6443jnnXcYNmwYzz//POnp6XHestj1qb5ouio9FKSmrq1Hihpj4u3WFz9i+eY9PVrm4UNz+NG549qcfscdd7Bs2TIWL17MvHnzOPvss1m2bFnTbYYPP/wweXl5VFVV8bnPfY6LL76Y/Pz8vcr4+OOPefLJJ3nwwQe59NJLeeaZZ7jiin3uFemzEiPBWxONMaYDRx555F73kN9zzz08++yzAGzYsIGPP/54nwQ/evRoJk+eDMARRxzBunXrei3enpAQCT4tFKSq1hK8MX1VezXt3pKZmdn0ft68ebz++uu8++67ZGRkcNJJJ7V6j3lqamrT+2AwSFVVVa/E2lMSorMxa4M3xrSUnZ1NWVlZq9NKS0sZOHAgGRkZrFy5kvfee6+Xo+sdCVGDTw8F2L7HErwxpll+fj7HHnss48ePJz09ncGDBzdNmz59Ovfffz9jx47l0EMPZdq0aXGM1D8JkuCtBm+M2dcTTzzR6vjU1FT+/ve/tzqtsZ190KBBLFu2rGn8t771rR6Pz28J0USTHrY2eGOMaSkhEry1wRtjzL4SIsGnh4JUW4I3xpi9JEyCr2tQ6hvsx07GGNMoMRJ8OAhAdb0leGOMaZQQCT4t5BK8XWg1xphmCZXgrR3eGNNVWVlZAGzevJlLLrmk1XlOOukkioqK2i3n7rvvprKysulzPLsfTogEn95Yg7cEb4zppqFDhzJnzpwuL98ywcez++HESPBhtxnWRGOMaXTzzTdz7733Nn2+5ZZbuP322zn11FOZOnUqEyZM4Pnnn99nuXXr1jF+/HgAqqqqmDVrFmPHjuXCCy/cqy+aa6+9lsLCQsaNG8ePfuR6Rb/nnnvYvHkzJ598MieffDLguh/esWMHAHfddRfjx49n/Pjx3H333U3rGzt2LNdccw3jxo3j9NNP77E+bxLil6xpVoM3pm/7+82w9cOeLXP/CXDmHW1OnjlzJjfeeCPXXXcdAE8//TT//Oc/uf7668nJyWHHjh1MmzaN8847r83nnd53331kZGSwYsUKli5dytSpU5um/fjHPyYvL4+GhgZOPfVUli5dyvXXX89dd93F3LlzGTRo0F5lLVq0iEceeYQFCxagqhx11FGceOKJDBw40LduiROjBm8J3hjTwpQpU9i+fTubN29myZIlDBw4kP3335/vfe97TJw4kdNOO41Nmzaxbdu2Nst46623mhLtxIkTmThxYtO0p59+mqlTpzJlyhQ++ugjli9f3m48//rXv7jwwgvJzMwkKyuLiy66iLfffhvwr1vihKjBN90maU00xvRN7dS0/TRjxgzmzJnD1q1bmTlzJo8//jjFxcUsWrSIUCjEqFGjWu0muCNr167lzjvvZOHChQwcOJCrrrqqS+U08qtbYqvBG2MS1syZM3nqqaeYM2cOM2bMoLS0lP32249QKMTcuXNZv359u8ufcMIJTR2WLVu2jKVLlwKwZ88eMjMzyc3NZdu2bXt1XNZWN8XHH388zz33HJWVlVRUVPDss89y/PHH9+DW7isxavCW4I0xrRg3bhxlZWUMGzaMIUOGcPnll3PuuecyYcIECgsLOeyww9pd/tprr+XLX/4yY8eOZezYsRxxxBEATJo0iSlTpnDYYYcxYsQIjj322KZlZs+ezfTp0xk6dChz585tGj916lSuuuoqjjzySACuvvpqpkyZ4utTokRV/SlY5FDgL1GjxgA/VNW721qmsLBQO7rHtDV7quuYeMur/L9zDuerx43ueAFjjO9WrFjB2LFj4x1GQmltn4rIIlUtbG1+32rwqroKmOwFEAQ2Ac/6sa60FPuhkzHGtNRbbfCnAmtUtf0Gry4KBYVgQOw+eGOMidJbCX4W8GRrE0RktogUiUhRcXFxlwoXEXuqkzF9kF9NwMmoK/vS9wQvImHgPOCvrU1X1QdUtVBVCwsKCrq8HnvohzF9S1paGjt37rQk3wNUlZ07d5KWltap5XrjLpozgfdVte1fE/SA9HDA7oM3pg8ZPnw4GzdupKtn5mZvaWlpDB8+vFPL9EaC/wJtNM/0pIwUsRq8MX1IKBRi9Gi7qy2efG2iEZFM4PPA3/xcDz8ZzjV1j1uCN8aYKL7W4FW1Asj3cx0ApITJpsruojHGmCgJ0VUBqdlkS5U9ss8YY6IkTILPpMoushpjTJQESfA5ZGiltcEbY0yUBEnw2ZbgjTGmhYRJ8OmRCmuiMcaYKAmT4FMbrAZvjDHREiTB55DaUEF9RKlrsDtpjDEGEibBZ5OitYSpo9KaaYwxBkiYBJ8DQCZVlNfUxzkYY4zpGxIkwWcDkCVVlFTWxjkYY4zpGxIqwWdTRWlVXZyDMcaYviGhEnwWVZRWWoI3xhhItAQvVoM3xphGCZLg3UXWLKoosQRvjDFAwiR4V4MfGLQavDHGNEqoBD8oVEOJtcEbYwyQKAk+lA4SJC+lhj1WgzfGGKB3nsnqPxFIy2EgNdZEY4wxnsSowQOkZpMbqKakyn7oZIwxkFAJPodsu03SGGOaJFCCz/a6KrAEb4wx4HOCF5EBIjJHRFaKyAoROdq3lXlPdSqrrqchor6txhhj+gu/a/C/Bv6hqocBk4AVvq0pNZv0SCWA3UljjDF0MsGLyEARmRjjvLnACcBDAKpaq6olnQ8xRqnZhBsqAKwd3hhjiCHBi8g8EckRkTzgfeBBEbkrhrJHA8XAIyLygYj8QUQyWyl/togUiUhRcXFxpzegSWo24fpyAOuuwBhjiK0Gn6uqe4CLgD+p6lHAaTEslwJMBe5T1SlABXBzy5lU9QFVLVTVwoKCgk6E3kJqDsGGalKotxq8McYQW4JPEZEhwKXAS50oeyOwUVUXeJ/n4BK+P6K6DLaHfhhjTGwJ/jbgn8AnqrpQRMYAH3e0kKpuBTaIyKHeqFOB5V2OtCNpuQBkS6VdZDXGGGLoqkBV/wr8Nerzp8DFMZb/38DjIhIGPgW+3JUgY5I2AIAcKq2JxhhjiO0i68+9i6whEXlDRIpF5IpYClfVxV77+kRVvUBVd3c/5DZ4NfiClGr7sZMxxhBbE83p3kXWc4B1wEHATX4G1SVegh+SWm01eGOMIcaLrN7r2cBfVbXUx3i6zkvw+SlVVNTWxzkYY4yJv1gS/EsishI4AnhDRAqAan/D6gIvwecFqymrtgRvjDEdJnhVvRk4BihU1Trc/ezn+x1Yp4WzQALkBSopr7EEb4wxHd5FIyIh4ArgBBEBmA/c73NcnRcIQGoOuVJJudXgjTEmpic63QeEgN95n7/ojbvar6C6LH0AOZFKKizBG2NMTAn+c6o6KerzmyKyxK+AuiUtl+yKcsqsicYYY2K6yNogIgc2fvB+ydrgX0jdkJZLplZQXlOPqvUJb4xJbrHU4G8C5orIp4AAI/HzF6ndkZZLemQTqlBZ20BmamI8U9wYY7oilq4K3hCRg4HGPmVWqWqNv2F1UVouqfVlAJTX1FuCN8YktTYzoIhc1Makg0QEVf2bTzF1XdqApgRfVl3P4Jw4x2OMMXHUXhX33HamKdAHE3wuKQ1VpFBPhV1oNcYkuTYTvKr2zXb29kT1KGk/djLGJDu/H7rdu7zuCnKkwrorMMYkvcRM8FaDN8aYBE3wUkl5tXUZbIxJbrE88GORiFwnIgN7I6BuaarBV1gN3hiT9GKpwc8EhgILReQpETlDvF7H+pzGPuEDlZTX9M0f2xpjTG+JpbvgT1T1+8AhwBPAw8B6EblVRPL8DrBTvAQ/KFRNeY010RhjkltMbfAiMhH4JfAL4BlgBrAHeNO/0LognAkSJC9YZV0GG2OSXiz9wS8CSoCHgJujuilYICLHdrDsOqAM1zlZvaoWdi/cDohA+gDy6u0uGmOMiaWzlhmq+mlrE1S1re4Mop2sqjs6F1Y3hDPJ1hq7D94Yk/RiaaIpFZF7ROR9746aX4tIvu+RdVU4i0yptRq8MSbpxZLgnwKKgYuBS7z3f4mxfAVe9Q4Ms1ubQURmi0iRiBQVFxfHWGw7QhlkUm190Rhjkl4sCX6Iqv6fqq71htuBwTGWf5yqTgXOBK4TkRNazqCqD6hqoaoWFhQUdCL0NoQzSafGavDGmKQXS4J/VURmiUjAGy4F/hlL4aq6yXvdDjwLHNn1UGMUziSNamuDN8YkvVgS/DW4+99rveEp4GsiUiYie9paSEQyRSS78T1wOrCs+yF3IJxJaqSKmvoItfUR31dnjDF9VSxPdMruYtmDgWe9H72mAE+o6j+6WFbsQhmEI9UAVNTUE04J+75KY4zpi2J6pp2InAc0tp/PU9WXOlrGu7VyUjdi65pwJqGGSsA9tm9gpiV4Y0xyiqWzsTuAG4Dl3nCDiPzU78C6LJxJSkMVoNYOb4xJarHU4M8CJqtqBEBEHgU+AL7rZ2BdFspAUNKopaLWErwxJnnF2h/8gKj3uX4E0mPCWQBkUGP90RhjklosNfifAB+IyFxAcG3xN/saVXeEMwDIkGrK7F54Y0wSazfBi0gAiADTgM95o7+jqlv9DqzLwpmA1eCNMabdBK+qERH5tqo+DbzQSzF1TygqwVuf8MaYJBZLG/zrIvItERkhInmNg++RdVVjDV6qrQZvjElqsbTBz/Rer4sap8CYng+nB3ht8HmhentsnzEmqcWS4MeqanX0CBFJ8yme7vPuoslLqbUmGmNMUoulieadGMf1DSFXgx8QqrMeJY0xSa3NGryI7A8MA9JFZAruFkmAHCCjF2LrGq+JJjdYa79kNcYktfaaaM4ArgKGA3dFjS8DvudjTN3j3UWTG7SnOhljklubCV5VHwUeFZGLVfWZXoype1LCEAiRFai1u2iMMUktlousL4nIZcCo6PlV9Ta/guq2cCZZgRoqqizBG2OSVywJ/nmgFFgE1PgbTg8JZ5IpNdZVgTEmqcWS4Ier6nTfI+lJ4UwytJrymnpUFe+hI8YYk1Riuk1SRCb4HklPCmWQpjWoQmWt/djJGJOcYqnBHwdcJSJrcU00AqiqTvQ1su4IZ5FWXQW4pzplpsb04CpjjEkosWS+M32PoqeFM0jV3QCUVdczOCfO8RhjTBx02ESjquuBEcAp3vvKWJaLq1AGoQZXg6+wC63GmCQVyzNZfwR8h+ZH9IWAx2JdgYgEReQDEenwQd09JpzlPZcV+7GTMSZpxVITvxA4D6gAUNXNQHYn1nEDsKLzoXVDOINgQyWAdVdgjElasST4WlVVXBfBiEhmrIWLyHDgbOAPXQuvi8KZBOtcgrcavDEmWcWS4J8Wkd8DA0TkGuB14MEYy78b+DbusX+9J5SJROoIUU95tXUZbIxJTh3eRaOqd4rI54E9wKHAD1X1tY6WE5FzgO2qukhETmpnvtnAbIADDjgg1rjb5z3VKZ1qq8EbY5JWTHfDqOprqnoTMC+W5O45FjhPRNYBTwGniMg+F2dV9QFVLVTVwoKCgljjbp/XZfCAlFp7qpMxJml19nbHmDsYU9XvqupwVR0FzALeVNUrOrm+rsnIB2B4uNKe6mSMSVqdTfD9o1OXnGEAjErZbXfRGGOSVmcT/Ne6shJVnaeq53Rl2S7xEvzocAnFZf2jA0xjjOlpsfzQaYaINN73foaI/E1EpvocV/dkFkAgxMhQCVtKqzue3xhjElAsNfj/p6plInIccArwEHCfv2F1UyAAOUMZGtjJppIq3G38xhiTXGJJ8I23oZwNPKiqLwNh/0LqIbnDGdSwg9r6CDsrauMdjTHG9LpYEvwm74dOM4FXRCQ1xuXiK2cYubXbANhcUhXnYIwxpvfFkqgvBf4JnKGqJUAecJOvUfWEnKGkVm9HiLC5xNrhjTHJJ5b+4IcAL6tqjfeL1InAn3yNqifkDicQqWMQpVaDN8YkpVhq8M8ADSJyEPAArm/4J3yNqid4t0qODJVYgjfGJKVYEnxEVeuBi4DfeF0WDPE3rB6Q6xL8uMwyNpdagjfGJJ9YEnydiHwB+BLQ+NCOkH8h9ZCc4QAclFZqbfDGmKQUS4L/MnA08GNVXSsio4E/+xtWD8jIg5Q0DgjusiYaY0xSiuWZrMuBbwEfish4YKOq/sz3yLpLBHKHM5TtbC+roabeepU0xiSXWLoqOAn4GLgX+B2wWkRO8DmunrHf4exf9QkA20qtTxpjTHKJpYnml8Dpqnqiqp4AnAH8yt+wesjQyWRXbiCHClZtK4t3NMYY06tiSfAhVV3V+EFVV9MfLrICDJkEwITgehZv2B3nYIwxpnfF8kOnRSLyB6DxaUyXA0X+hdSDhkwG4OSczczbUBrnYIwxpnfFUoP/OrAcuN4blgPX+hlUj8kcBDnDKUzdwJINJUQi1qukMSZ5tFuDF5EgsERVDwPu6p2QetiQSYzZuJyymno+3VHOQftld7yMMcYkgHZr8KraAKwSkQN6KZ6eN2QS2RXryKSKxdZMY4xJIrE00QwEPhKRN0TkhcbB78B6zLAjEJTjUz+xC63GmKQSy0XW/+d7FH4afTyEs5kV+oDbPz063tEYY0yvaTPBe71HDlbV+S3GHwds8TuwHpOSCodOZ9rK11hbdjkbdlUyIi8j3lEZY4zv2muiuRvY08r4Um9au0QkTUT+IyJLROQjEbm1q0F22+Hnk1ZXwlGBFcxdtT1uYRhjTG9qL8EPVtUPW470xo2Koewa4BRVnQRMBqaLyLQuRdldB50GoUxmZSzizZWW4I0xyaG9BD+gnWnpHRWsTrn3MeQN8bkRPZQOh07nNH2PhWu2UVVrHY8ZYxJfewm+SESuaTlSRK4GFsVSuIgERWQxsB14TVUXtDLPbBEpEpGi4uLiWOPuvIkzyWgo5ajIYuav9nE9xhjTR7SX4G8Eviwi80Tkl94wH/gqcEMshatqg6pOBoYDR3rdDbec5wFVLVTVwoKCgq5sQ2wOPAXNyGdW6rs898Em/9ZjjDF9RJsJXlW3qeoxwK3AOm+4VVWPVtWtnVmJqpYAc4HpXQ+1m4IhZPzFnMxCFqxcS0llbdxCMcaY3hDLAz/mqupvvOHNWAsWkQIRGeC9Twc+D6zseqg9YOIsQlrLObzNS0v7z52exhjTFbH8krWrhgBzRWQpsBDXBv9SB8v4a/gR6PDP8fXUfzBn4TpUrfMxY0zi8i3Bq+pSVZ2iqhNVdbyq3ubXujpDjv4GwyJb2W/LXN5dszPe4RhjjG/8rMH3TYedQyT3AP43/Bz3z10R72iMMcY3yZfggykEpv+Ew1jL0et/z6L1u+IdkTHG+CL5EjzA2HOpm3wlX0t5iTf/ei8N9iAQY0wCSs4ED4TOuoNdgwq5qfxOPnjqNrALrsaYBJO0CZ5wBvlfe5EF6SdQuPouSv90GVRZf/HGmMSRvAkekFA6Y679K78NfonMtf+g4TeFUPQI1JTFOzRjjOm2pE7wAAU5aZz81duZGfkpK6vz4aUb4c5D4Jlr4N/3wDNXw4dz4h2mMcZ0mvSlH/sUFhZqUVFRXNZdtG4XVz68gBMz1nHHgR+Rs+YFqC6FtFz3euhZMPZcOGQ6ZOTFJUZjjGlJRBapamGr0yzBN/vgs9189dEiVJV7Z47jmKEpkJEP//4VvHuva6MPZcLnvgJHfwOy949brMYYA5bgO2X9zgq++mgRa4rLmX38GL5xykFkp4UgEoGtS+Dd38GyORAIwdHXwUnfhZRwXGM2xiQvS/CdVFlbz20vLuephRsYkBHii9NGMuvIAxg2wHvOya5PYd7PYHQDcnQAABQJSURBVOlTsP9EuOhB2O+w+AZtjElKluC76MONpfz6jdW8sXI7QREuP+oAbjjtEPIyvRr7ypfhhf+G2go477cwcUZ8AzbGJB1L8N20YVcl981fw18WbmBQVpi7Z07h6APz3cTy7fD0lbD5ffjaW1BwaHyDNcYklfYSfNLfJhmLEXkZ/OTCCbzwjWPJTE3hsj+8x12vrqK+IQJZ+8GMRyCUAX+7BurtQSLGmL7BEnwnjBuay4vfOI6Lpw7nnjc/4SuPFlFZW+/upjn317BlCbz183iHaYwxgCX4TstMTeHOGZP46UUT+NfHxXzpof9QWlUHh58Hky+Ht38Jn+3zbHFjjOl1luC76AtHHsBvL5vKko0lzHrgPYrLamD6HZA7HOZ8xbXNG2NMHFmC74azJgzhD1d+jnU7Krj60YXUhbLg0j9D5U546nKoq453iMaYJGYJvptOPKSAX146iSUbS/nVa6th6GS48H7Y+B/429UQaYh3iMaYJGUJvgecNWEIlxYO5775a1i0fjeMuwDO+CmseBFevN6SvDEmLnxL8CIyQkTmishyEflIRG7wa119wQ/PHcfg7DR+8Nwyd/vk0f8FJ34HPnjMbp80xsSFnzX4euCbqno4MA24TkQO93F9cZWVmsIt5x3Oii17+OM769zIk78Hp90Ky56BR8+BPVviGqMxJrn4luBVdYuqvu+9LwNWAMP8Wl9fcMa4/TnlsP341Wur2VJa5UYedyNc8ghsXQYPngzbPopvkMaYpNErbfAiMgqYAuxzg7iIzBaRIhEpKi4u7o1wfCMi3HreOBpUue3F5c0Txl8EV78GCDx8pqvR96EuIowxicn3BC8iWcAzwI2quqfldFV9QFULVbWwoKDA73B8NyIvg/8+5WD+vmwrLy3d3Dxh8Dj46quQN8rdJ//nC2HHJ3GL0xiT+HxN8CISwiX3x1X1b36uqy+55vgxTD1gAN+Zs5Q1xeXNEwaMgKvfhDN/DpsWwX1Hw8vfhF1r4xesMSZh+XkXjQAPAStU9S6/1tMXhVMC/PayqaSGglz72CLXX02jYAoc9TX4xkKYNAve/xPceyTM/wXU18QvaGNMwvGzBn8s8EXgFBFZ7A1n+bi+PmXogHR+PWsyH28v5wfPLmOfbpmz94fzfgM3LIXDzoG5t8Ndh8MrN8HCP8Cm9+3+eWNMt6T4VbCq/gsQv8rvD44/uIAbTz2EX72+moMGZ/FfJx2070w5Q1x3w0dcCf950NXo670uDlJzYdRxMPp4GHkMDBzlHgJujDEx8C3BG+e/TzmIT3eU8/N/rCIrNYUvHT2q9RnHnOSGSAT2bIINC2DtfFj7Fqx6uXm+cDbkDoOcYTDoENh/PETqIXM/OPAUCKX5vk3GmP7BErzPAgHhzhmTqKxt4IfPf0RGOIVLjhje3gLuYuyAETDhEjeuZANsXAilG13yb3x9/1Goq2xeNpTpnig1YASkDYD0gZCR7x5KEmmAYAjyD3JnASmp7qBgDww3JmFZgu8FoWCA33xhClc/WsS35yyhtj7CZUcdEHsBjQm/pYZ6KFkPKWmwYxWs+gfsWA3bV0BVCVTthkhd+2VnFkB6HtRXQSAFUrMhNccbst0QDIFG3EEjIx8y8tz7tBwIZ7r1aATyxriDSkq6O1AZY+LKnsnaiypr67n2sfeZv7qYL04byQ/PPZxQ0MdEqAo1ZVBRDIGg675458dQV+Vq/mVbYc9ml6BDGa6pp6YMava41+o9UFPqmo1E3PhYhTIglO7OKsIZ7nM4s/nsAQEJuCallHSo2gW1lS7OvNEw4ADvLGQABMPuDqP0gW75SIMrs/FAZAeT/qdqNwRT3fcYbdtHrqJhzzaOmT10uw9piCg//8dKfv/Wpxw5Oo/7Lp9KflZqvMOKTUO9+8es3OmSffUeqC1vvvC7e60bV1cJtRXeayXUVbiDSk05VJdCQy2g7gDUeLDJyHMHg4Zad1bSEGvnbOKSfJqX7Btqmw9Q6QMhazCUbgAJQs5Qd6CKNLjX7KHuIFS12zsLaXDLpA+EcJabp/FA1PTe+xwIuTObYNgNKd6rqjtraqh1+2uv9/Xu4JaR7w5gkXq37ZEG744pbd6mlFR3p5UEoWyze0pYKB2GTHLbEc5yZ11blkBDnbsmEwy52MAdKCXglpeA9znobYd630sllG2BzYvdqwRgwgxXTvEqt64BI73t9LY1kNK8zY3jP1sAy+a4GIZMdGeE6QPdtIodzbFU7nLbvKkI3r3X/d2c8G0YOsV9/2vfcneRSQDOvtPdXVZb7s5KU3Pc/sga7GLQiNvXGnEDUe8bx8O+44Jhd1BpqIPqEvdgnrpKF0vWYFjyFJRvgzEnu5saqnbBZ+9CznC3P9IHuApTdSnkjoCK7a6itN9YyB7iYgukePsZ972WbXX7N5zpvvvacnjjNtj5CYw6HgaPd2e/B0xrXq4TLMH3Qc99sInvPLOUQVmpPPClIxg31O6OadJQ7w4i1SWuqamh1jVDNR5YAkGXoGr2uH+06lJ3YKkudUmlMdlX7IDyrV4yjbhEibjlNQKlm1ySbExIgWBz01ZtudedhEYljKj3kQYvcXfw24VAincwCLszjfqava+bxCoj3/VIWlvWhR3agYGjXCKv2AHbvb6SAikuGccqLdcdwDXGW3snXOoO5Bta9F4y5mRXxtq3Yl93Twumdvy9diSQ4g5UbVVUQhkwdKq7ttZQ45pKb+raL9vbS/DWBh8nF0wZxpiCTGb/aREX3/cOd86YxDkTh8Y7rL4hmALZg93Q16m6RNhQ65K3iJfMvdptazWymjJ3oTwYdv/ogWBzra+xwlVX5Q5Oiqs15o1x00o/g7Jt7iARSHFdYIQyXA2x8SygsdYaaXDJMtLgHZgams9ewpluuQzv4Na4LVuXurjyD4biFa4221DnDbXN2xo9LncYHHaue7/rU+/AvNtNz8h3MUUa3IG08QA8cJRbX/FK2L3eHZxTUl2tHWDVK24fpYShYKw7Iyzf6uJRZa+zqabXAHudcTWNo3lcfa3bd8FQc609lAGVO2D3Ojj4dMg70D2wp2ybi2nkMe6mhu0rXaUiI88tW7LBvc8eAtuXe9vsnbVF6t02h9Ihc5A7A6ircGcxdZUw/mL3eM+GOij5zFVefGA1+DjbXlbNtY+9z6L1u7li2gF8e/ph5KSF4h2WMaafaK8Gb1en4my/7DSeuOYovnLsaJ5Y8Bmn3DmfP/57LTX19itWY0z3WILvA1JTgvzw3MN57rpjObAgk1teXM5Jv5jH4wvWU11nid4Y0zXWRNPHqCr//mQnv3xtFR98VkJ+Zpgrpo3ki0ePZFB/udvGGNNr7C6afkhVeXfNTh7611reWLmdUFA47qBBnDlhCKcfPpgBGfYLVGOMJfh+b01xOX9ZuIFXPtzCxt1VpASEow/M5/Rx+3PSIQWMyMvouBBjTEKyBJ8gVJVlm/bw8odb+PuyLazf6e6nHlOQyYmHFHDiIQVMG5NPWigY50iNMb3FEnwCUlU+3VHB/FXFzF9dzHuf7qSmPkJqSoCjxuRzwsGDmDxiAIfun0223XZpTMKyBJ8EqusaWLB2l5fwt7OmuKJp2rAB6Ywdks3oQZlkp4UYNSiTcUNzGJ2fSSCQ1F32G9Pv2S9Zk0BaKNjUTAOHs6W0ihVb9rBiSxkrt5axause3v54BzX1kaZlMsNBRg3K5IC8DEbkZbBfdir5WWEGZoTJz0wlLytMXkaY9LA1+RjTH1mCT1BDctMZkpvOKYft/XP/mvoGPtlezkeb97B88x7W7axg1bYy3li5ndqo5B8tJSCEUwKkpgS812CLzwHCKcG9Pqe2nC8YIDXU+BokFAwQDEBABBEhICC410BACIoQDHqvASHgvQYDEAwECIoQCHjLBJqXdT0DNL5vLlcaf9kugtDcg0DTtMaNlX3HRS8jSPN83jziFRY9T3QPBS3HSVSZTdO70MmUMR2xBJ9kUlOCjBuau0/nZqrKnqp6dlbUsKuitmnYWVFLRU09tfURauoj3msDtQ0RauoiTa+lVXXU1LUc732uj9CHWgL7tNYOAtEHI4S9xjWNb2X55nH7HjxaPZxIx/O0WlYrM8ay7N4xtj5l7+1sff7Wtn/f+Vs/gLY8EHe1zDbCj1leRpg51x7T+QU7YAneAO6PNTcjRG5GiDEFPVu2qlIf0b0OErX1ESKq3uDmiajrTrlxfEMkalAlEoEGVRoiERoibl5Q19+XgtJcFkBEo6Z579WbH1w/Xo3jaHrv3mhT7N6y0GK55mXcOG1avuU4Wszf2jwaVVh0XK3GGnWwjD5utoyp5fTm+VoZ12LOWA/IrV3Di2Wd0etrK969l2lj/r2W7VyZ2saObG2ftl9O6/N3hl83QliCN74TEUJBIRQMkGk/xjWm1/jWF42IPCwi20VkmV/rMMYY0zY/Oxv7IzDdx/KNMca0w7cEr6pvAbv8Kt8YY0z74t5dsIjMFpEiESkqLi6OdzjGGJMw4p7gVfUBVS1U1cKCgh6+fcMYY5JY3BO8McYYf1iCN8aYBOXnbZJPAu8Ch4rIRhH5ql/rMsYYs68+1ZukiBQD67u4+CBgRw+G01Msrs7rq7FZXJ1jcXVeV2IbqaqtXsDsUwm+O0SkqK0uM+PJ4uq8vhqbxdU5Flfn9XRs1gZvjDEJyhK8McYkqERK8A/EO4A2WFyd11djs7g6x+LqvB6NLWHa4I0xxuwtkWrwxhhjoliCN8aYBNXvE7yITBeRVSLyiYjcHMc4RojIXBFZLiIficgN3vhbRGSTiCz2hrPiFN86EfnQi6HIG5cnIq+JyMfe68BejunQqP2yWET2iMiN8dhnrT2/oK39I8493t/cUhGZGofYfiEiK731PysiA7zxo0SkKmrf3d/LcbX53YnId719tkpEzujluP4SFdM6EVnsje/N/dVWjvDv78w9yqx/DkAQWAOMAcLAEuDwOMUyBJjqvc8GVgOHA7cA3+oD+2odMKjFuJ8DN3vvbwZ+FufvciswMh77DDgBmAos62j/AGcBf8c9fXMasCAOsZ0OpHjvfxYV26jo+eIQV6vfnfe/sARIBUZ7/7fB3oqrxfRfAj+Mw/5qK0f49nfW32vwRwKfqOqnqloLPAWcH49AVHWLqr7vvS8DVgDD4hFLJ5wPPOq9fxS4II6xnAqsUdWu/pK5W7T15xe0tX/OB/6kznvAABEZ0puxqeqrqlrvfXwPGO7X+jsTVzvOB55S1RpVXQt8gvv/7dW4RESAS4En/Vh3e9rJEb79nfX3BD8M2BD1eSN9IKmKyChgCrDAG/UN7xTr4d5uBomiwKsiskhEZnvjBqvqFu/9VmBwfEIDYBZ7/9P1hX3W1v7pa393X8HV9BqNFpEPRGS+iBwfh3ha++76yj47Htimqh9Hjev1/dUiR/j2d9bfE3yfIyJZwDPAjaq6B7gPOBCYDGzBnR7Gw3GqOhU4E7hORE6InqjunDAu98yKSBg4D/irN6qv7LMm8dw/7RGR7wP1wOPeqC3AAao6Bfhf4AkRyenFkPrcd9fCF9i7ItHr+6uVHNGkp//O+nuC3wSMiPo83BsXFyISwn1xj6vq3wBUdZuqNqhqBHgQn05LO6Kqm7zX7cCzXhzbGk/5vNft8YgNd9B5X1W3eTH2iX1G2/unT/zdichVwDnA5V5iwGsC2em9X4Rr6z6kt2Jq57uL+z4TkRTgIuAvjeN6e3+1liPw8e+svyf4hcDBIjLaqwXOAl6IRyBe295DwApVvStqfHSb2YXAspbL9kJsmSKS3fged4FuGW5fXenNdiXwfG/H5tmrVtUX9pmnrf3zAvAl7y6HaUBp1Cl2rxCR6cC3gfNUtTJqfIGIBL33Y4CDgU97Ma62vrsXgFkikioio724/tNbcXlOA1aq6sbGEb25v9rKEfj5d9YbV4/9HHBXmlfjjrzfj2Mcx+FOrZYCi73hLODPwIfe+BeAIXGIbQzuDoYlwEeN+wnIB94APgZeB/LiEFsmsBPIjRrX6/sMd4DZAtTh2jq/2tb+wd3VcK/3N/chUBiH2D7Btc82/q3d7817sfcdLwbeB87t5bja/O6A73v7bBVwZm/G5Y3/I/D1FvP25v5qK0f49ndmXRUYY0yC6u9NNMYYY9pgCd4YYxKUJXhjjElQluCNMSZBWYI3xpgEZQnemG4QkZNE5KV4x2FMayzBG2NMgrIEb5KCiFwhIv/x+vz+vYgERaRcRH7l9c39hogUePNOFpH3pLmv9cb+uQ8SkddFZImIvC8iB3rFZ4nIHHH9sz/u/WIREbnD6/t7qYjcGadNN0nMErxJeCIyFpgJHKuqk4EG4HLcr2iLVHUcMB/4kbfIn4DvqOpE3C8IG8c/DtyrqpOAY3C/lgTXK+CNuL69xwDHikg+7qf647xybvd3K43ZlyV4kwxOBY4AFop7ks+puEQcobnjqceA40QkFxigqvO98Y8CJ3h9+QxT1WcBVLVam/uA+Y+qblTXwdZi3EMkSoFq4CERuQho6i/GmN5iCd4kAwEeVdXJ3nCoqt7Synxd7bejJup9A+5JS/W4nhTn4Hp8/EcXyzamyyzBm2TwBnCJiOwHTc/AHIn7+7/Em+cy4F+qWgrsjnrwwxeB+eqewLNRRC7wykgVkYy2Vuj1+Z2rqq8A/wNM8mPDjGlPSrwDMMZvqrpcRH6Ae6JVANfL4HVABXCkN207rp0eXJet93sJ/FPgy974LwK/F5HbvDJmtLPabOB5EUnDnUH8bw9vljEdst4kTdISkXJVzYp3HMb4xZpojDEmQVkN3hhjEpTV4I0xJkFZgjfGmARlCd4YYxKUJXhjjElQluCNMSZB/X+7eUOAf3Le2AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plot validation and training loss\n",
        "ep = np.arange(0, nb_epoch)\n",
        "plt.plot(ep, train_loss, '-', label='train')\n",
        "plt.plot(ep, validation_loss, '-', label='validation')\n",
        "plt.legend()\n",
        "plt.title(\"Loss au cours de l'entrainement\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Cross-entropy loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "aXdzfz3u1Ox6",
        "outputId": "2cf708cc-844f-4645-c46b-d10f5547662d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test input is:\n",
            "['<S>', 'what', 'is', 'the', 'dbo:routeEnd', 'of', 'dbr:Birmingham_and_Oxford_Junction_Railway', '?', '</S>']\n",
            "Expected output of length 11 is:\n",
            "<S> select distinct ?uri where { dbr:Birmingham_and_Oxford_Junction_Railway dbo:routeEnd ?uri } </S>\n",
            "Actual output of length 11 is: \n",
            "tensor([   1,    2,    3,    6,    8,    9, 3950,  181,    6,   13,   14],\n",
            "       device='cuda:0')\n",
            "<S> select distinct ?uri where { dbr:Birmingham_and_Oxford_Junction_Railway dbo:routeEnd ?uri } </S>\n"
          ]
        }
      ],
      "source": [
        "chosen_example = 11\n",
        "model.eval()\n",
        "print(f\"Test input is:\")\n",
        "src = validation_english_tensors[chosen_example].unsqueeze(0)\n",
        "print(english_vocab.id_to_word(src.squeeze().tolist()))\n",
        "src_mask = (src!=0).unsqueeze(-2)\n",
        "tgt = validation_tokens[\"sparql\"][chosen_example]\n",
        "print(f\"Expected output of length {tgt.size} is:\")\n",
        "print(\" \".join(tgt.tolist()))\n",
        "src = src.requires_grad_(False).clone().detach().to(device=device)\n",
        "src_mask = src_mask.requires_grad_(False).clone().detach().to(device=device)\n",
        "output = greedy_decode(model, src, src_mask, max_len=50, start_symbol=sparql_vocab.word_to_id(\"<S>\"), end_symbol=sparql_vocab.word_to_id(\"</S>\")).squeeze()\n",
        "print(f\"Actual output of length {output.shape[0]} is: \")\n",
        "print(output)\n",
        "print(\" \".join(sparql_vocab.id_to_word(output.tolist())))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqdoJzdB1Ox7",
        "outputId": "fe221556-2d0d-42b7-a02a-fdaddbcafd3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max performance without dealing with <UNK> 0.41600000000000004\n"
          ]
        }
      ],
      "source": [
        "count_unknown=0\n",
        "for tensor in validation_english_tensors:\n",
        "    if \"<UNK>\" in english_vocab.id_to_word(tensor.tolist()):\n",
        "        count_unknown+=1\n",
        "print(\"Max performance without dealing with <UNK>\", 1-count_unknown/len(validation_english_tensors))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4efVu3eTTnqd"
      },
      "source": [
        "#### 7.4.3. Évaluation (10%)\n",
        "\n",
        "Afficher les résultats de votre modèle sur l’ensemble de validation au moyen de la métrique de précision globale et de la métrique BLEU,.\n",
        "\n",
        "Générez, le fichier _tp4_submission.csv_ qui contient les questions de test et leurs requêtes SPARQL.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kr6yIZiL1Ox7"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "def compute_bleu(predictions: List[List[str]], targets: List[List[str]]) -> float:\n",
        "    \"\"\"\n",
        "    entrées:\n",
        "       - predictions: Liste des prédicitons du modèle pour l'ensemble de validation. Chaque prédiction est une liste de jetons textuels.\n",
        "       - targets: Liste des requêtes attendues de l'ensemble de validation. Chaque requête est une liste de jetons textuels.\n",
        "    sortie:\n",
        "       Le score bleu moyen de vos prédictions comparées aux requêtes attendues.\n",
        "    \"\"\"\n",
        "    return bleu_score(predictions, [[tokens] for tokens in targets])\n",
        "\n",
        "def compute_accuracy(predictions, targets):\n",
        "   return (sum(np.array(predictions, dtype=object)==np.array(targets, dtype=object)))/len(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "bcb6175f3e1f46838368bc905e8ee3e6",
            "dfe0e4b6ded74c42b0fe5973f5c8bea6",
            "a33cbe53c5a14317928cfd40205788d4",
            "3eb1863d965c46a98f19c748c21ba7ba",
            "278aae03b6594ed4bf79ce6db5b788dd",
            "532e43e92cf948cb889f8d1378540770",
            "4e867142f0e44b79bb71e6c7c131afe6",
            "98f3d15fd75a4027a9b45ad20963c0ee",
            "210ee14fac5942b0afaec44f371cbede",
            "4f47ea9c7db14b318a9a4f2d17450b55",
            "dcc862acdcbd4d6d830dd7f493f1beb0"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "id": "0mb9HqRn1Ox8",
        "outputId": "8b238147-9347-4a10-c3d4-bcded5bf7278"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bcb6175f3e1f46838368bc905e8ee3e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score 0.8434478030976812\n",
            "Accuracy 0.294\n"
          ]
        }
      ],
      "source": [
        "maxlen = max(train_sparql_tensors.apply(len))+10\n",
        "predictions = []\n",
        "targets = []\n",
        "for i in tqdm(range(0, len(validation_english_tensors))):\n",
        "    src = validation_english_tensors[i].unsqueeze(0)\n",
        "    src_mask = (src!=0).unsqueeze(-2)\n",
        "    src = src.requires_grad_(False).clone().detach().to(device)\n",
        "    src_mask = src_mask.requires_grad_(False).clone().detach().to(device)\n",
        "    output = greedy_decode(model, src, src_mask, max_len=maxlen, start_symbol=sparql_vocab.word_to_id(\"<S>\"), end_symbol=sparql_vocab.word_to_id(\"</S>\")).squeeze()\n",
        "    predictions.append(sparql_vocab.id_to_word(output.tolist()))\n",
        "    targets.append(validation_tokens[\"sparql\"][i].tolist())\n",
        "print(\"BLEU score\", compute_bleu(predictions, targets))\n",
        "print(\"Accuracy\", compute_accuracy(predictions, targets))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTmKvWFL2hqA"
      },
      "source": [
        "### 7.3. Approche(s) avancée(s) (30%)\n",
        "Reprenez les étapes de la partie précédente avec une ou plusieurs nouvelle(s) architecture(s) plus complexe(s), ou améliorant votre précédente architecture, afin d’obtenir un score plus élevé sur l’ensemble de validation et dans la compétition Kaggle. Démontrez bien cette amélioration dans votre notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le modèle précédent, bien qu'il ait un score pour la métrique BLEU élevé sur notre ensemble de validation, perd en efficacité lorsqu'il doit utiliser des mots hors vocabulaires (OOV), ce qui arrive lorsque le modèle doit utiliser des éléments qui n'ont pas été rencontrés dans l'ensemble d'entraînement. Le greedy decoding va à la place remplacer les jetons inconnus par des jetons du vocabulaire d'entraînement les plus probables étant données le contexte. </br>\n",
        "De plus, la métrique BLEU utilisée nous indique juste que les requêtes générées par le modèle ont une forme correcte, sans inspecter son sens. Il est donc possible d'obtenir une valeur BLEU élevée même si aucune phrase n'est correcte: cela explique pourquoi l'accuracy est plus faible. Nous pouvons également remarquer ceci sur le chosen_example quelques cellules plus haut : la syntaxe de la requête générée est correcte (selection d'un attribut du RDF satisfaisant 2 contraintes), mais les contraintes ne correspondent pas à ce qui est attendu (dbr:Bordesley_railway_station dbp:borough vs dbr:Birmingham_and_Oxford_Junction_Railway dbo:routeEnd normalement), sûrement car le gold standard dbr:Birmingham_and_Oxford_Junction_Railway dbo:routeEnd n'a pas été rencontré dans l'ensemble d'entraînement et donc n'appartient pas au vocabulaire. </br>\n",
        "Pour résoudre ce problème, Hirigoyen et al. [3] proposent d'utiliser le mécanisme de copie : l'idée est de masquer les tokens inconnus de la requête avant de la passer en entrée de l'encodeur, ceci afin de produire en sortie une requête SPARQL \"générique\" syntaxiquement correcte, et de copier directement les tokens à partir de la requête initiale en langue naturelle dans la requête SPARQL. Ceci permet de contourner le problème des OOV et ainsi de ne pas avoir à augmenter inutilement la taille du vocabulaire utilisé dans l'entraînement. </br>\n",
        "Pour ce faire, on modifie légèrement la manière dont les vocabulaires sont construits. On va dans un premier temps construire les vocabulaires en enlevant tous les mots spécifiques à sparql. Ces mots sont tous ceux qui commencent par l'un de ces préfixes: *dbo:, dbr:, dbc:, dbp:, dct:, geo:, georss:*. Ensuite, on va compléter avec des mots aléatoires vocabulaire le plus petit et rajouter tous les mots spécifiques à sparql à la fin des vocabulaires. Comme on veut juste copier les jetons, ils est important que la correspondance id-jeton soit la même dans les deux vocabulaires pour les mots spécifiques à sparql, c'est pourquoi on remplit l'un d'eux avec des mots aléatoires."
      ],
      "metadata": {
        "id": "erI_juvhj_zE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B35JZ6A31Ox9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import log_softmax\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import copy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import math\n",
        "from typing import List, Tuple\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    \"\"\"An transformer as encoder decoder pair\"\"\"\n",
        "    def __init__(self, src_vocab, tgt_vocab, N, d_model, d_ff, h, dropout, maxlen=5000):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.src_embeddings = Embeddings(d_model, src_vocab)\n",
        "        self.tgt_embeddings = Embeddings(d_model, tgt_vocab)\n",
        "        self.positionalEncoding = PositionalEncoding(d_model, dropout, maxlen)\n",
        "        self.encoder = Encoder(EncoderLayer(h, d_model, d_ff, dropout), N)\n",
        "        self.decoder = Decoder(DecoderLayer(h, d_model, d_ff, dropout), N)\n",
        "        self.proj = nn.Linear(tgt_vocab, 1)\n",
        "        self.generator = Generator(d_model, tgt_vocab)\n",
        "        self.d_model = d_model\n",
        "        self.input_vocab_size = src_vocab\n",
        "        self.output_vocab_size = tgt_vocab\n",
        "\n",
        "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
        "        x = self.encode(src.masked_fill(src >= self.input_vocab_size, 0), src_mask)\n",
        "        x, attention = self.decode(x, src_mask, tgt.masked_fill(tgt >= self.output_vocab_size, 0), tgt_mask)\n",
        "        x = self.generator(x)\n",
        "\n",
        "        # Calculate alpha bal with formula from Hirigoyen et al.\n",
        "        alpha_bal = torch.sigmoid(self.proj(x))\n",
        "        # To calculate p_gen, we need to extand the vector x to contain the KB words present in the query\n",
        "        max_oov_word = torch.max(src) + 1\n",
        "        # Those KB words originaly have a probability of 0\n",
        "        new_x = torch.autograd.Variable(torch.zeros((x.shape[0], x.shape[1], max_oov_word))).to(device=device)\n",
        "        # Simply recopy x into this new vector\n",
        "        new_x[0:x.shape[0], 0:x.shape[1], 0:x.shape[2]] = x\n",
        "        x = new_x\n",
        "        # p_gen is the softmax of probability vector, balanced by alpha_bal\n",
        "        p_gen = (1-alpha_bal) * torch.nn.functional.softmax(x, dim=2)\n",
        "        # p_copy is just the attention scores, balanced by alpha_bal\n",
        "        p_copy = alpha_bal * attention[:, 3]\n",
        "\n",
        "        # Compute indexes of where p_copy needs to be added to p_gen\n",
        "        index = torch.zeros(src.shape[0], x.shape[1], src.shape[1], dtype=torch.int64).to(device)\n",
        "        for i in range(src.shape[0]):\n",
        "          index[i] = src[i].repeat(index.shape[1], 1)\n",
        "\n",
        "        # In the end the probability vector is just the sum of p_gen and p_copy at the needed indexes\n",
        "        x = p_gen.scatter_add(2, index, p_copy)\n",
        "        return torch.log(x)\n",
        "\n",
        "    def encode(self, src, src_mask):\n",
        "        \"\"\"Apply transformer's encoders with source embedding and positional encoding\"\"\"\n",
        "        x = self.src_embeddings(src)\n",
        "        x = self.positionalEncoding(x)\n",
        "        x = self.encoder(x, src_mask)\n",
        "        return x\n",
        "\n",
        "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
        "        \"\"\"Apply transformer's encoders with target embedding and positional encoding\"\"\"\n",
        "        x = self.tgt_embeddings(tgt)\n",
        "        x = self.positionalEncoding(x)\n",
        "        x, attention = self.decoder(x, memory, src_mask, tgt_mask)\n",
        "        return x, attention\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"Simple linear layer with log softmax\"\"\"\n",
        "    def __init__(self, d_model, tgt_vocab):\n",
        "        super(Generator, self).__init__()\n",
        "        self.proj = nn.Linear(d_model, tgt_vocab)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # return log_softmax(self.proj(x), dim=-1)\n",
        "        return self.proj(x)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"A encoder is a stack of N identical layers\"\"\"\n",
        "    def __init__(self, layer, N):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([copy.deepcopy(layer) for _ in range(N)])\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, src_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, src_mask)\n",
        "        return self.norm(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"A decoder is a stack of N identical layer with memory of the encoder output\"\"\"\n",
        "    def __init__(self, layer, N):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([copy.deepcopy(layer) for _ in range(N)])\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        for layer in self.layers:\n",
        "            x, attention = layer(x, memory, src_mask, tgt_mask)\n",
        "        return self.norm(x), attention\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    \"\"\"Each encoder layer is self attention and feed forward\"\"\"\n",
        "\n",
        "    def __init__(self, h, d_model, d_ff, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attention = MultiHeadedAttention(h, d_model, dropout)\n",
        "        self.feed_forward = FeedForward(d_model, d_ff, dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.norm1 = LayerNorm(d_model)\n",
        "        self.norm2 = LayerNorm(d_model)\n",
        "        self.size = d_model\n",
        "\n",
        "    def forward(self, x, src_mask):\n",
        "        # Add and norm self attention\n",
        "        x = x + self.norm1(self.dropout(self.self_attention(x, x, x, src_mask)))\n",
        "        # Add and norm feed forward\n",
        "        x = x + self.norm2(self.dropout(self.feed_forward(x)))\n",
        "        return x\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    \"\"\"Each decoder layer is self attention, cross attention and feed forward\"\"\"\n",
        "\n",
        "    def __init__(self, h, d_model, d_ff, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attention = MultiHeadedAttention(h, d_model, dropout)\n",
        "        self.cross_attention = MultiHeadedAttention(h, d_model, dropout)\n",
        "        self.feed_forward = FeedForward(d_model, d_ff, dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.norm1 = LayerNorm(d_model)\n",
        "        self.norm2 = LayerNorm(d_model)\n",
        "        self.norm3 = LayerNorm(d_model)\n",
        "        self.size = d_model\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        # Add and norm masked self attention\n",
        "        x = x + self.norm1(self.dropout(self.self_attention(x, x, x, tgt_mask)))\n",
        "        # Add and norm cross attention\n",
        "        t, attention = self.cross_attention(x, memory, memory, src_mask, return_attention=True)\n",
        "        x = x + self.norm2(self.dropout(t))\n",
        "        # Add and norm feed forward\n",
        "        x = x + self.norm3(self.dropout(self.feed_forward(x)))\n",
        "        return x, attention\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    \"\"\"Fully connected feed forward network\"\"\"\n",
        "\n",
        "    def __init__(self, d_model, d_ff, dropout):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.layer1 = nn.Linear(d_model, d_ff)\n",
        "        self.layer2 = nn.Linear(d_ff, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer2(self.dropout(self.layer1(x).relu()))\n",
        "\n",
        "def attention(query, key, value, mask=None, dropout=None):\n",
        "    \"\"\"Compute attention\"\"\"\n",
        "    d_k = query.size(-1)\n",
        "    scores = torch.matmul(query, key.transpose(-2, -1))/math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)\n",
        "    attn_coeffs = scores.softmax(dim=-1)\n",
        "    if dropout is not None:\n",
        "        attn_coeffs = dropout(attn_coeffs)\n",
        "\n",
        "    return torch.matmul(attn_coeffs, value), attn_coeffs\n",
        "\n",
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, h, d_model, dropout=0.1):\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        assert d_model % h == 0\n",
        "\n",
        "        self.d_k = d_model // h\n",
        "        self.h = h\n",
        "        self.linearV = nn.Linear(d_model, d_model)\n",
        "        self.linearK = nn.Linear(d_model, d_model)\n",
        "        self.linearQ = nn.Linear(d_model, d_model)\n",
        "        self.linearOutput = nn.Linear(d_model, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None, return_attention = False):\n",
        "        if mask is not None:\n",
        "            # Apply mask to all heads\n",
        "            mask = mask.unsqueeze(1)\n",
        "        nbatches = query.size(0)\n",
        "\n",
        "        # Linear projections and split into multiple heads\n",
        "        query = self.linearQ(query).view(nbatches, -1, self.h, self.d_k).transpose(1,2)\n",
        "        key = self.linearK(key).view(nbatches, -1, self.h, self.d_k).transpose(1,2)\n",
        "        value = self.linearV(value).view(nbatches, -1, self.h, self.d_k).transpose(1,2)\n",
        "\n",
        "        # Apply Attention\n",
        "        x, attn_coeffs = attention(query, key, value, mask=mask, dropout=self.dropout)\n",
        "\n",
        "        # Concat back into a single attention matrix\n",
        "        x = x.transpose(1,2).reshape(nbatches, -1, self.h*self.d_k)\n",
        "\n",
        "        # Apply final linear\n",
        "        x = self.linearOutput(x)\n",
        "        if return_attention:\n",
        "            return x, attn_coeffs\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "class Embeddings(nn.Module):\n",
        "    def __init__(self, d_model, vocab):\n",
        "        super(Embeddings, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab, d_model)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.embedding(x) * math.sqrt(self.d_model)\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000)/d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "\n",
        "        # Not a model p/arameter but needs to be on the same device as model parameters\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)].requires_grad_(False)\n",
        "        return self.dropout(x)\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    \"Construct a layernorm module (See citation for details).\"\n",
        "\n",
        "    def __init__(self, features, eps=1e-6):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.a_2 = nn.Parameter(torch.ones(features))\n",
        "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
        "\n",
        "def subsequent_mask(size):\n",
        "    \"\"\"Mask subsequent positions\"\"\"\n",
        "    attn_shape = (1, size, size)\n",
        "    subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(torch.uint8)\n",
        "    return subsequent_mask == 0\n",
        "\n",
        "def make_std_mask(tgt, pad):\n",
        "    \"Create a mask to hide padding and future words.\"\n",
        "    tgt_mask = (tgt != pad).unsqueeze(-2)\n",
        "    tgt_mask = tgt_mask & subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data)\n",
        "    return tgt_mask\n",
        "\n",
        "def rate(step, model_size, factor, warmup):\n",
        "    \"\"\"Learning rate schedule\"\"\"\n",
        "    if step == 0:\n",
        "        step = 1\n",
        "    return factor*(model_size**(-0.5)*min(step**(-0.5), step*warmup**(-1.5)))\n",
        "\n",
        "def make_model(src_vocab, tgt_vocab, N=5, d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
        "    model = Transformer(src_vocab, tgt_vocab, N, d_model, d_ff, h, dropout)\n",
        "    # Initialize model parameters with uniform weights\n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "    return model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R32KyqPP1Ox-"
      },
      "outputs": [],
      "source": [
        "def data_gen(V, batch_size, nbatches):\n",
        "    data_size = batch_size*nbatches\n",
        "    pad = 0\n",
        "    data = torch.randint(1, V, size=(data_size, 10))\n",
        "    data[:, 0] = 1\n",
        "    src = data\n",
        "    src_mask = (src != pad).unsqueeze(-2)\n",
        "    tgt = data[:,:-1]\n",
        "    tgt_y = data[:,1:]\n",
        "    tgt_mask = make_std_mask(tgt, pad)\n",
        "    dataset = TensorDataset(src, tgt, tgt_y, src_mask, tgt_mask)\n",
        "    return DataLoader(dataset, batch_size=batch_size, pin_memory=True)\n",
        "\n",
        "def greedy_decode(model, src, src_mask, max_len, start_symbol, end_symbol=None):\n",
        "    memory = model.encode(src.masked_fill(src>=model.input_vocab_size, 0), src_mask)\n",
        "    ys = torch.zeros(1, 1).fill_(start_symbol).type_as(src.data).to(device)\n",
        "    for _ in range(max_len - 1):\n",
        "        out, attention = model.decode(\n",
        "            memory, src_mask, ys.masked_fill(ys>=model.output_vocab_size, 0), subsequent_mask(ys.size(1)).type_as(src.data)\n",
        "        )\n",
        "        out = model.generator(out)\n",
        "        # Calculate alpha bal with formula from Hirigoyen et al.\n",
        "        alpha_bal = torch.sigmoid(model.proj(out))\n",
        "        # To calculate p_gen, we need to extand the vector out to contain the KB words present in the query\n",
        "        max_oov_word = torch.max(src) + 1\n",
        "        # Those KB words originaly have a probability of 0\n",
        "        new_out = torch.autograd.Variable(torch.zeros((out.shape[0], out.shape[1], max_oov_word))).to(device=device)\n",
        "        # Simply recopy out into this new vector\n",
        "        new_out[0:out.shape[0], 0:out.shape[1], 0:out.shape[2]] = out\n",
        "        out = new_out\n",
        "        # p_gen is the softmax of probability vector, balanced by alpha_bal\n",
        "        p_gen = (1-alpha_bal) * torch.nn.functional.softmax(out, dim=2)\n",
        "        # p_copy is just the attention scores, balanced by alpha_bal\n",
        "        p_copy = alpha_bal * attention[:, 3]\n",
        "\n",
        "        # Compute indexes of where p_copy needs to be added to p_gen\n",
        "        index = torch.zeros(src.shape[0], out.shape[1], src.shape[1], dtype=torch.int64).to(device)\n",
        "        for i in range(src.shape[0]):\n",
        "          index[i] = src[i].repeat(index.shape[1], 1)\n",
        "\n",
        "        # In the end the probability vector is just the sum of p_gen and p_copy\n",
        "        prob = p_gen.scatter_add(2, index, p_copy)\n",
        "\n",
        "        prob = torch.log(prob)\n",
        "        prob = prob[:, -1]\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.data[0]\n",
        "        ys = torch.cat(\n",
        "            [ys, torch.zeros(1, 1).type_as(src.data).fill_(next_word)], dim=1\n",
        "        )\n",
        "        if next_word==end_symbol:\n",
        "            break\n",
        "    return ys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Chv-9V61Ox_",
        "outputId": "69063e84-2d16-48fd-b41f-7564f5351fc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything went ok building the vocabs\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
        "from nltk.lm import Vocabulary\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from copy import deepcopy\n",
        "import string\n",
        "import random\n",
        "\n",
        "padding_id = 0\n",
        "tokenizer = RegexpTokenizer('\\s+', gaps=True)\n",
        "word_generator = list(string.ascii_letters)\n",
        "\n",
        "class Vocab(Vocabulary):\n",
        "    def __init__(self, tokens, unk_cutoff=1):\n",
        "        super().__init__(np.insert(np.concatenate(tokens), 0, [\"<BLANK>\"]), unk_cutoff=unk_cutoff)\n",
        "        self.word_to_id_dict = {}\n",
        "        self.id_to_word_dict = {}\n",
        "        self.length = 0\n",
        "        # Don't count sparql specific words when first building vocabulary\n",
        "        for word in self:\n",
        "            if word[0:4]!=\"dbo:\" and word[0:4]!=\"dbr:\" and word[0:4]!=\"dbc:\" and word[0:4]!=\"dbp:\" and word[0:4]!=\"dct:\" and word[0:4]!=\"geo:\" and word[0:4]!=\"georss:\":\n",
        "                self.word_to_id_dict[word] = self.length\n",
        "                self.id_to_word_dict[self.length] = word\n",
        "                self.length += 1\n",
        "\n",
        "    def word_to_id(self, words):\n",
        "        if type(words) is list or type(words) is Tuple or type(words) is np.ndarray:\n",
        "            return [self.word_to_id_dict[a] for a in self.lookup(words)]\n",
        "        return self.word_to_id_dict[self.lookup(words)]\n",
        "\n",
        "    def id_to_word(self, ids):\n",
        "        if type(ids) is list or type(ids) is Tuple or type(ids) is np.ndarray:\n",
        "            return [self.id_to_word_dict[a] for a in ids]\n",
        "        return self.id_to_word_dict[ids]\n",
        "\n",
        "    def fill_vocab(self, limit):\n",
        "        # fill a vocabulary so that both vocabularies have the same size\n",
        "        while self.length<limit:\n",
        "            # This can generate more than 1e10 different words which is far more than any vocabulary\n",
        "            filler_word = \"\".join(random.choices(word_generator, k=random.randint(1, 10)))\n",
        "            if filler_word not in self.word_to_id_dict:\n",
        "                self.word_to_id_dict[filler_word] = self.length\n",
        "                self.id_to_word_dict[self.length] = filler_word\n",
        "                self.length += 1\n",
        "\n",
        "    def expand(self, tokens, unk_cutoff=1):\n",
        "        super().__init__(np.concatenate(tokens), unk_cutoff=unk_cutoff)\n",
        "        # Expand the vocabulary with all the sparql specific words\n",
        "        for word in self:\n",
        "            if word[0:4]==\"dbo:\" or word[0:4]==\"dbr:\" or word[0:4]==\"dbc:\" or word[0:4]==\"dbp:\" or word[0:4]==\"dct:\" or word[0:4]==\"geo:\" or word[0:7]==\"georss:\":\n",
        "                self.word_to_id_dict[word] = self.length\n",
        "                self.id_to_word_dict[self.length] = word\n",
        "                self.length += 1\n",
        "\n",
        "def tokenize(df):\n",
        "    tokens = pd.DataFrame()\n",
        "    for column in df.columns:\n",
        "        tokens[column] = df[column].apply(tokenizer.tokenize).apply(np.insert, args=(0, \"<S>\")).apply(np.append, args=[\"</S>\"])\n",
        "    return tokens\n",
        "\n",
        "def vectorize(tokens, vocab):\n",
        "    return tokens.apply(vocab.word_to_id).apply(torch.tensor)\n",
        "\n",
        "train_df = pd.read_csv(\"data/train.csv\", index_col=0)\n",
        "validation_df = pd.read_csv(\"data/validation.csv\", index_col=0)\n",
        "test_df = pd.read_csv(\"data/test.csv\", index_col=0)\n",
        "\n",
        "train_tokens = tokenize(train_df)\n",
        "validation_tokens = tokenize(validation_df)\n",
        "test_tokens = tokenize(test_df)\n",
        "\n",
        "maxlen = max(max(train_tokens[\"sparql\"].apply(len))+10, max(validation_tokens[\"sparql\"].apply(len))+10)\n",
        "\n",
        "# First calculate base vocabularies\n",
        "english_vocab = Vocab(train_tokens[\"english\"].tolist() + validation_tokens[\"english\"].tolist() + test_tokens[\"english\"].tolist())\n",
        "sparql_vocab = Vocab(train_tokens[\"sparql\"].tolist() + validation_tokens[\"sparql\"].tolist())\n",
        "\n",
        "english_vocab_size = english_vocab.length\n",
        "sparql_vocab_size = sparql_vocab.length\n",
        "base_english_vocab = deepcopy(english_vocab)\n",
        "base_sparql_vocab = deepcopy(sparql_vocab)\n",
        "# Fill the smallest vocabulary, in general it would be the sparql one\n",
        "if sparql_vocab_size<english_vocab_size:\n",
        "    sparql_vocab.fill_vocab(english_vocab_size)\n",
        "if english_vocab_size<sparql_vocab_size: # I doubt this would happen but we never know\n",
        "    english_vocab.fill_vocab(sparql_vocab_size)\n",
        "# Expand the two vocabularies with KB words, i.e. the words specific to sparql\n",
        "full_list_containing_KB_words = train_tokens[\"english\"].tolist() + train_tokens[\"sparql\"].tolist() + validation_tokens[\"english\"].tolist() + validation_tokens[\"sparql\"].tolist() + test_tokens[\"english\"].tolist()\n",
        "english_vocab.expand(full_list_containing_KB_words)\n",
        "sparql_vocab.expand(full_list_containing_KB_words)\n",
        "\n",
        "full_english_vocab_length = english_vocab.length\n",
        "full_sparql_vocab_length = sparql_vocab.length\n",
        "# If both vocabularies don't have the same length there was a problem somewhere\n",
        "if full_english_vocab_length!=full_sparql_vocab_length:\n",
        "    print(\"Problem!\")\n",
        "else:\n",
        "    print(\"Everything went ok building the vocabs\")\n",
        "train_english_tensors = vectorize(train_tokens[\"english\"], english_vocab)\n",
        "train_sparql_tensors = vectorize(train_tokens[\"sparql\"], sparql_vocab)\n",
        "validation_english_tensors = vectorize(validation_tokens[\"english\"], english_vocab)\n",
        "validation_sparql_tensors = vectorize(validation_tokens[\"sparql\"], sparql_vocab)\n",
        "test_english_tensors = vectorize(test_tokens[\"english\"], english_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRXrr9MM1OyA"
      },
      "outputs": [],
      "source": [
        "## Hyper paramètres\n",
        "batch_size = 200\n",
        "validation_batch_size = 200\n",
        "nb_epoch = 200\n",
        "N = 6\n",
        "lr = 0.1\n",
        "betas = (0.9, 0.98)\n",
        "eps = 1e-9\n",
        "factor = 1.0\n",
        "warmup = 400\n",
        "label_smoothing = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u57-Wuix1OyA"
      },
      "outputs": [],
      "source": [
        "def collate_batch(batch):\n",
        "    \"\"\"Pad batch value with zeros\"\"\"\n",
        "    src = [a[\"src\"] for a in batch]\n",
        "    tgt = [a[\"tgt\"] for a in batch]\n",
        "    src = pad_sequence(src, batch_first=True, padding_value=padding_id)\n",
        "    tgt = pad_sequence(tgt, batch_first=True, padding_value=padding_id)\n",
        "\n",
        "    src_mask = (src != padding_id).unsqueeze(-2)\n",
        "    tgt, tgt_y = tgt[:,:-1], tgt[:,1:]\n",
        "    tgt_mask = make_std_mask(tgt, padding_id)\n",
        "\n",
        "    return src, tgt, tgt_y, src_mask, tgt_mask\n",
        "\n",
        "class TranslateDataset(Dataset):\n",
        "    def __init__(self, src, tgt):\n",
        "        super().__init__()\n",
        "        assert len(src) == len(src)\n",
        "        self.src = src\n",
        "        self.tgt = tgt\n",
        "        self.len = len(src)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\"src\":self.src[idx], \"tgt\": self.tgt[idx]}\n",
        "\n",
        "def prepare_data(src, tgt, batch_size):\n",
        "    dataset = TranslateDataset(src, tgt)\n",
        "    return DataLoader(dataset, collate_fn=collate_batch, batch_size=batch_size, pin_memory=True)\n",
        "\n",
        "train = prepare_data(train_english_tensors, train_sparql_tensors, batch_size)\n",
        "validation = prepare_data(validation_english_tensors, validation_sparql_tensors, validation_batch_size)\n",
        "src_vocab = english_vocab\n",
        "tgt_vocab = sparql_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f1016a75f00948698248afb45f06c664",
            "78a2dab685fb462f93ff594dddbd22be",
            "d4be906fc9e74b75a491dfcde18f4a0a",
            "4051e8bcae134f8b96b914fe8589e532",
            "1a1e850abdbe4230ab06496cd3e1a067",
            "b28ebbcddda34f99a37784c67c7174e0",
            "6f79a50190194de6822d5156c1f5d2eb",
            "7b234a42203041998a2fa6e12197a135",
            "da09521e0a5546beba909b93583b871c",
            "779c8f71eee14e02b14a1726403b1821",
            "a198bbd6132143c3aa6dfd5e2cafc7c9"
          ]
        },
        "id": "cPqC_yAn1OyB",
        "outputId": "d2590194-94f7-4047-cd0a-e1b29e98d4ca"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1016a75f00948698248afb45f06c664"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 0 train_loss=6.377351307868958 validation_loss=4.156095663706462\n",
            "EPOCH 1 train_loss=3.8224149107933045 validation_loss=2.6234018007914224\n",
            "EPOCH 2 train_loss=2.802377438545227 validation_loss=2.182556947072347\n",
            "EPOCH 3 train_loss=2.41605030298233 validation_loss=1.9790377616882324\n",
            "EPOCH 4 train_loss=2.1679607152938845 validation_loss=1.8731404145558674\n",
            "EPOCH 5 train_loss=2.01400220990181 validation_loss=1.7418659528096516\n",
            "EPOCH 6 train_loss=1.8699477910995483 validation_loss=1.6218576828638713\n",
            "EPOCH 7 train_loss=1.7362371861934662 validation_loss=1.4915039539337158\n",
            "EPOCH 8 train_loss=1.6288180947303772 validation_loss=1.4231137832005818\n",
            "EPOCH 9 train_loss=1.5395581483840943 validation_loss=1.39353080590566\n",
            "EPOCH 10 train_loss=1.4747218132019042 validation_loss=1.3439675172170003\n",
            "EPOCH 11 train_loss=1.4334188759326936 validation_loss=1.315557638804118\n",
            "EPOCH 12 train_loss=1.4120315194129944 validation_loss=1.2869340181350708\n",
            "EPOCH 13 train_loss=1.3894105434417725 validation_loss=1.2594208319981892\n",
            "EPOCH 14 train_loss=1.3753089606761932 validation_loss=1.2414449453353882\n",
            "EPOCH 15 train_loss=1.3504624724388123 validation_loss=1.2377360661824544\n",
            "EPOCH 16 train_loss=1.3379953801631927 validation_loss=1.2311472495396931\n",
            "EPOCH 17 train_loss=1.3302503168582915 validation_loss=1.2320193847020466\n",
            "EPOCH 18 train_loss=1.3372555196285247 validation_loss=1.2328240871429443\n",
            "EPOCH 19 train_loss=1.3410689115524292 validation_loss=1.2179382642110188\n",
            "EPOCH 20 train_loss=1.3217475175857545 validation_loss=1.2086146275202434\n",
            "EPOCH 21 train_loss=1.3205336093902589 validation_loss=1.211463491121928\n",
            "EPOCH 22 train_loss=1.3163738429546357 validation_loss=1.2041908105214436\n",
            "EPOCH 23 train_loss=1.311399406194687 validation_loss=1.200452208518982\n",
            "EPOCH 24 train_loss=1.31293585896492 validation_loss=1.1959670384724934\n",
            "EPOCH 25 train_loss=1.3109582543373108 validation_loss=1.1958858172098796\n",
            "EPOCH 26 train_loss=1.3010820031166077 validation_loss=1.1979880730311077\n",
            "EPOCH 27 train_loss=1.3161771059036256 validation_loss=1.1924033959706624\n",
            "EPOCH 28 train_loss=1.3108594715595245 validation_loss=1.1904201904932659\n",
            "EPOCH 29 train_loss=1.3055713534355164 validation_loss=1.1906575361887615\n",
            "EPOCH 30 train_loss=1.2976205229759217 validation_loss=1.190421183904012\n",
            "EPOCH 31 train_loss=1.3087218403816223 validation_loss=1.1927140951156616\n",
            "EPOCH 32 train_loss=1.3074026823043823 validation_loss=1.1882837216059368\n",
            "EPOCH 33 train_loss=1.2993651926517487 validation_loss=1.187132994333903\n",
            "EPOCH 34 train_loss=1.294375967979431 validation_loss=1.1862001816431682\n",
            "EPOCH 35 train_loss=1.3004327893257142 validation_loss=1.1842655738194783\n",
            "EPOCH 36 train_loss=1.2942129790782928 validation_loss=1.1853653192520142\n",
            "EPOCH 37 train_loss=1.2944252490997314 validation_loss=1.1840979655583699\n",
            "EPOCH 38 train_loss=1.2915869057178497 validation_loss=1.1840848525365193\n",
            "EPOCH 39 train_loss=1.2944022595882416 validation_loss=1.1866240501403809\n",
            "EPOCH 40 train_loss=1.2902530074119567 validation_loss=1.1860123078028362\n",
            "EPOCH 41 train_loss=1.3069158971309662 validation_loss=1.1893024047215779\n",
            "EPOCH 42 train_loss=1.2843426585197448 validation_loss=1.1857821941375732\n",
            "EPOCH 43 train_loss=1.3018983602523804 validation_loss=1.1875720024108887\n",
            "EPOCH 44 train_loss=1.293092006444931 validation_loss=1.1860685745875041\n",
            "EPOCH 45 train_loss=1.2925398230552674 validation_loss=1.1874802907307942\n",
            "EPOCH 46 train_loss=1.2922833502292632 validation_loss=1.1843272844950359\n",
            "EPOCH 47 train_loss=1.2901977241039275 validation_loss=1.1848464409510295\n",
            "EPOCH 48 train_loss=1.293481034040451 validation_loss=1.18513019879659\n",
            "EPOCH 49 train_loss=1.2927075564861297 validation_loss=1.1872356335322063\n",
            "EPOCH 50 train_loss=1.2928324282169341 validation_loss=1.1850197315216064\n",
            "EPOCH 51 train_loss=1.3063614249229432 validation_loss=1.1858179569244385\n",
            "EPOCH 52 train_loss=1.2900717794895171 validation_loss=1.186319907506307\n",
            "EPOCH 53 train_loss=1.2934505939483643 validation_loss=1.1863913536071777\n",
            "EPOCH 54 train_loss=1.294724065065384 validation_loss=1.1868499517440796\n",
            "EPOCH 55 train_loss=1.294443666934967 validation_loss=1.1930869817733765\n",
            "EPOCH 56 train_loss=1.297617244720459 validation_loss=1.1935127973556519\n",
            "EPOCH 57 train_loss=1.2940931022167206 validation_loss=1.190377950668335\n",
            "EPOCH 58 train_loss=1.2890503346920013 validation_loss=1.1883732477823894\n",
            "EPOCH 59 train_loss=1.2907544195652008 validation_loss=1.1903786261876423\n",
            "EPOCH 60 train_loss=1.2995768129825591 validation_loss=1.1894824504852295\n",
            "EPOCH 61 train_loss=1.300229549407959 validation_loss=1.1891072193781536\n",
            "EPOCH 62 train_loss=1.2967981100082397 validation_loss=1.1882668336232503\n",
            "EPOCH 63 train_loss=1.2917038738727569 validation_loss=1.187126874923706\n",
            "EPOCH 64 train_loss=1.2979630172252654 validation_loss=1.1875459750493367\n",
            "EPOCH 65 train_loss=1.2955452620983123 validation_loss=1.186820348103841\n",
            "EPOCH 66 train_loss=1.2942537188529968 validation_loss=1.1882045269012451\n",
            "EPOCH 67 train_loss=1.2942973732948304 validation_loss=1.1883151133855183\n",
            "EPOCH 68 train_loss=1.2941736221313476 validation_loss=1.188349763552348\n",
            "EPOCH 69 train_loss=1.2845056772232055 validation_loss=1.1887248357137044\n",
            "EPOCH 70 train_loss=1.2889795064926148 validation_loss=1.188311258951823\n",
            "EPOCH 71 train_loss=1.289520615339279 validation_loss=1.1875240405400593\n",
            "EPOCH 72 train_loss=1.2948363184928895 validation_loss=1.1857680877049763\n",
            "EPOCH 73 train_loss=1.2901665210723876 validation_loss=1.1859505573908489\n",
            "EPOCH 74 train_loss=1.297586065530777 validation_loss=1.1865626176198323\n",
            "EPOCH 75 train_loss=1.291291558742523 validation_loss=1.186495264371236\n",
            "EPOCH 76 train_loss=1.2905247986316681 validation_loss=1.1864311297734578\n",
            "EPOCH 77 train_loss=1.2904726207256316 validation_loss=1.1854522625605266\n",
            "EPOCH 78 train_loss=1.2825222134590148 validation_loss=1.1856023867925007\n",
            "EPOCH 79 train_loss=1.2904678404331207 validation_loss=1.1858970324198406\n",
            "EPOCH 80 train_loss=1.2877958118915558 validation_loss=1.18630051612854\n",
            "EPOCH 81 train_loss=1.2943241238594054 validation_loss=1.1858043670654297\n",
            "EPOCH 82 train_loss=1.2888656735420227 validation_loss=1.1851029793421428\n",
            "EPOCH 83 train_loss=1.2899857759475708 validation_loss=1.1859614451726277\n",
            "EPOCH 84 train_loss=1.2923940241336822 validation_loss=1.1855960289637248\n",
            "EPOCH 85 train_loss=1.2856258690357207 validation_loss=1.186795433362325\n",
            "EPOCH 86 train_loss=1.2919729232788086 validation_loss=1.1860905090967815\n",
            "EPOCH 87 train_loss=1.2919383764266967 validation_loss=1.1853000322977703\n",
            "EPOCH 88 train_loss=1.2849521219730378 validation_loss=1.18454110622406\n",
            "EPOCH 89 train_loss=1.2925235629081726 validation_loss=1.1857207616170247\n",
            "EPOCH 90 train_loss=1.2922435641288756 validation_loss=1.1841964721679688\n",
            "EPOCH 91 train_loss=1.297151780128479 validation_loss=1.1850031614303589\n",
            "EPOCH 92 train_loss=1.2938779175281525 validation_loss=1.1848701635996501\n",
            "EPOCH 93 train_loss=1.2870312333106995 validation_loss=1.1844155391057332\n",
            "EPOCH 94 train_loss=1.278113842010498 validation_loss=1.1832918326059978\n",
            "EPOCH 95 train_loss=1.2831602573394776 validation_loss=1.1836684147516887\n",
            "EPOCH 96 train_loss=1.2969101011753081 validation_loss=1.1839566628138225\n",
            "EPOCH 97 train_loss=1.2905704498291015 validation_loss=1.1837705771128337\n",
            "EPOCH 98 train_loss=1.281177806854248 validation_loss=1.1839519739151\n",
            "EPOCH 99 train_loss=1.2951857686042785 validation_loss=1.182850956916809\n",
            "EPOCH 100 train_loss=1.2860750198364257 validation_loss=1.1839154958724976\n",
            "EPOCH 101 train_loss=1.2861126124858857 validation_loss=1.183090329170227\n",
            "EPOCH 102 train_loss=1.2933465719223023 validation_loss=1.1837548812230427\n",
            "EPOCH 103 train_loss=1.288264548778534 validation_loss=1.1837960879007976\n",
            "EPOCH 104 train_loss=1.2941475808620453 validation_loss=1.184808373451233\n",
            "EPOCH 105 train_loss=1.2898418486118317 validation_loss=1.184138337771098\n",
            "EPOCH 106 train_loss=1.2858701765537262 validation_loss=1.1838820377985637\n",
            "EPOCH 107 train_loss=1.290042018890381 validation_loss=1.1840721766153972\n",
            "EPOCH 108 train_loss=1.2856660068035126 validation_loss=1.185470978418986\n",
            "EPOCH 109 train_loss=1.2933485567569734 validation_loss=1.1826200882593791\n",
            "EPOCH 110 train_loss=1.2847513735294342 validation_loss=1.1834307511647542\n",
            "EPOCH 111 train_loss=1.2849655389785766 validation_loss=1.1816935936609905\n",
            "EPOCH 112 train_loss=1.2819447219371796 validation_loss=1.1832669973373413\n",
            "EPOCH 113 train_loss=1.283574140071869 validation_loss=1.1822905540466309\n",
            "EPOCH 114 train_loss=1.2803597748279572 validation_loss=1.1825650533040364\n",
            "EPOCH 115 train_loss=1.2877164781093597 validation_loss=1.181623379389445\n",
            "EPOCH 116 train_loss=1.2957985162734986 validation_loss=1.181838830312093\n",
            "EPOCH 117 train_loss=1.2861422002315521 validation_loss=1.1829069058100383\n",
            "EPOCH 118 train_loss=1.2900126218795775 validation_loss=1.1837399403254192\n",
            "EPOCH 119 train_loss=1.2832232415676117 validation_loss=1.1827851136525471\n",
            "EPOCH 120 train_loss=1.2812341809272767 validation_loss=1.183152715365092\n",
            "EPOCH 121 train_loss=1.2806809008121491 validation_loss=1.1836250225702922\n",
            "EPOCH 122 train_loss=1.2862520337104797 validation_loss=1.1828035910924275\n",
            "EPOCH 123 train_loss=1.290460032224655 validation_loss=1.1819957097371419\n",
            "EPOCH 124 train_loss=1.2785195469856263 validation_loss=1.1834193865458171\n",
            "EPOCH 125 train_loss=1.2829555451869965 validation_loss=1.183660586675008\n",
            "EPOCH 126 train_loss=1.2854023277759552 validation_loss=1.182306448618571\n",
            "EPOCH 127 train_loss=1.2906584084033965 validation_loss=1.1834649244944255\n",
            "EPOCH 128 train_loss=1.290492630004883 validation_loss=1.183866262435913\n",
            "EPOCH 129 train_loss=1.2851748287677764 validation_loss=1.1831610600153606\n",
            "EPOCH 130 train_loss=1.29025958776474 validation_loss=1.182854175567627\n",
            "EPOCH 131 train_loss=1.2818917751312255 validation_loss=1.1831423838933308\n",
            "EPOCH 132 train_loss=1.2859413623809814 validation_loss=1.18352476755778\n",
            "EPOCH 133 train_loss=1.2845589816570282 validation_loss=1.183852235476176\n",
            "EPOCH 134 train_loss=1.2862381041049957 validation_loss=1.1837507883707683\n",
            "EPOCH 135 train_loss=1.2860843122005463 validation_loss=1.1832162141799927\n",
            "EPOCH 136 train_loss=1.2920525014400481 validation_loss=1.1823302110036213\n",
            "EPOCH 137 train_loss=1.2889666140079499 validation_loss=1.1839558283487956\n",
            "EPOCH 138 train_loss=1.2868840396404266 validation_loss=1.182470401128133\n",
            "EPOCH 139 train_loss=1.2799117922782899 validation_loss=1.183210810025533\n",
            "EPOCH 140 train_loss=1.286281055212021 validation_loss=1.183743158976237\n",
            "EPOCH 141 train_loss=1.2864588737487792 validation_loss=1.1829075813293457\n",
            "EPOCH 142 train_loss=1.2856836318969727 validation_loss=1.1845533450444539\n",
            "EPOCH 143 train_loss=1.2757999122142791 validation_loss=1.184707800547282\n",
            "EPOCH 144 train_loss=1.2789173483848573 validation_loss=1.1865814526875813\n",
            "EPOCH 145 train_loss=1.2834295749664306 validation_loss=1.184016267458598\n",
            "EPOCH 146 train_loss=1.2774802267551422 validation_loss=1.1855907837549846\n",
            "EPOCH 147 train_loss=1.290459007024765 validation_loss=1.1854519446690877\n",
            "EPOCH 148 train_loss=1.2886276066303253 validation_loss=1.185189962387085\n",
            "EPOCH 149 train_loss=1.290522313117981 validation_loss=1.1857789357503254\n",
            "EPOCH 150 train_loss=1.291364312171936 validation_loss=1.1862128973007202\n",
            "EPOCH 151 train_loss=1.281188678741455 validation_loss=1.1855687697728474\n",
            "EPOCH 152 train_loss=1.2786117970943451 validation_loss=1.1845478614171345\n",
            "EPOCH 153 train_loss=1.283424735069275 validation_loss=1.1839478413263957\n",
            "EPOCH 154 train_loss=1.2892478108406067 validation_loss=1.1850976546605427\n",
            "EPOCH 155 train_loss=1.2873227000236511 validation_loss=1.1864107847213745\n",
            "EPOCH 156 train_loss=1.2859337627887726 validation_loss=1.185409704844157\n",
            "EPOCH 157 train_loss=1.2844334423542023 validation_loss=1.1853078206380208\n",
            "EPOCH 158 train_loss=1.2822972416877747 validation_loss=1.1854204336802165\n",
            "EPOCH 159 train_loss=1.2882488191127777 validation_loss=1.1849681536356609\n",
            "EPOCH 160 train_loss=1.2810062348842621 validation_loss=1.1856760183970134\n",
            "EPOCH 161 train_loss=1.2807076573371887 validation_loss=1.1847444772720337\n",
            "EPOCH 162 train_loss=1.280547672510147 validation_loss=1.1841507752736409\n",
            "EPOCH 163 train_loss=1.2826741755008697 validation_loss=1.1842206319173176\n",
            "EPOCH 164 train_loss=1.2878436505794526 validation_loss=1.1842364867528279\n",
            "EPOCH 165 train_loss=1.2794612169265747 validation_loss=1.1840053796768188\n",
            "EPOCH 166 train_loss=1.2793496429920197 validation_loss=1.184296727180481\n",
            "EPOCH 167 train_loss=1.2781096875667572 validation_loss=1.1851147413253784\n",
            "EPOCH 168 train_loss=1.2747517645359039 validation_loss=1.1849117279052734\n",
            "EPOCH 169 train_loss=1.2845060288906098 validation_loss=1.185279409090678\n",
            "EPOCH 170 train_loss=1.2864815652370454 validation_loss=1.1849659283955891\n",
            "EPOCH 171 train_loss=1.28709716796875 validation_loss=1.184811274210612\n",
            "EPOCH 172 train_loss=1.2756804287433625 validation_loss=1.1850464741388957\n",
            "EPOCH 173 train_loss=1.2893677413463593 validation_loss=1.184887210528056\n",
            "EPOCH 174 train_loss=1.281954437494278 validation_loss=1.1844123999277751\n",
            "EPOCH 175 train_loss=1.2875818014144897 validation_loss=1.1847782929738362\n",
            "EPOCH 176 train_loss=1.2769301235675812 validation_loss=1.183594783147176\n",
            "EPOCH 177 train_loss=1.2893693923950196 validation_loss=1.184171438217163\n",
            "EPOCH 178 train_loss=1.2853528797626494 validation_loss=1.1842377185821533\n",
            "EPOCH 179 train_loss=1.2730794370174408 validation_loss=1.1850603818893433\n",
            "EPOCH 180 train_loss=1.2833184003829956 validation_loss=1.1831831137339275\n",
            "EPOCH 181 train_loss=1.2913761913776398 validation_loss=1.1840074857076008\n",
            "EPOCH 182 train_loss=1.281366729736328 validation_loss=1.1846192280451457\n",
            "EPOCH 183 train_loss=1.282665067911148 validation_loss=1.1842563947041829\n",
            "EPOCH 184 train_loss=1.2777971863746642 validation_loss=1.1839965184529622\n",
            "EPOCH 185 train_loss=1.2867430210113526 validation_loss=1.1841062307357788\n",
            "EPOCH 186 train_loss=1.278254246711731 validation_loss=1.1835389137268066\n",
            "EPOCH 187 train_loss=1.2800760865211487 validation_loss=1.1835027138392131\n",
            "EPOCH 188 train_loss=1.2817688941955567 validation_loss=1.1838454405466716\n",
            "EPOCH 189 train_loss=1.2863216400146484 validation_loss=1.184536616007487\n",
            "EPOCH 190 train_loss=1.287919706106186 validation_loss=1.1848998467127483\n",
            "EPOCH 191 train_loss=1.2823131740093232 validation_loss=1.1845058997472127\n",
            "EPOCH 192 train_loss=1.2781927168369294 validation_loss=1.1848013003667195\n",
            "EPOCH 193 train_loss=1.2843960344791412 validation_loss=1.1849359273910522\n",
            "EPOCH 194 train_loss=1.2828363478183746 validation_loss=1.1850227912267048\n",
            "EPOCH 195 train_loss=1.2839126586914062 validation_loss=1.1841092109680176\n",
            "EPOCH 196 train_loss=1.2828210830688476 validation_loss=1.1841284036636353\n",
            "EPOCH 197 train_loss=1.2875600099563598 validation_loss=1.183775544166565\n",
            "EPOCH 198 train_loss=1.2835907816886902 validation_loss=1.1837069988250732\n",
            "EPOCH 199 train_loss=1.2838065564632415 validation_loss=1.1833902994791667\n"
          ]
        }
      ],
      "source": [
        "model = make_model(base_english_vocab.length, base_sparql_vocab.length, N=N)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=betas, eps=eps)\n",
        "scheduler = LambdaLR(optimizer=optimizer, lr_lambda=lambda step: rate(step, model_size=model.d_model, factor=factor, warmup=warmup))\n",
        "loss_function = nn.CrossEntropyLoss(ignore_index=padding_id, label_smoothing=0.1)\n",
        "train_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "best_model = copy.deepcopy(model)\n",
        "best_validation_loss = None\n",
        "\n",
        "for epoch in tqdm(range(nb_epoch)):\n",
        "    # Run epoch train\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    for i, batch in enumerate(train):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        src, tgt, tgt_y, src_mask, tgt_mask = [a.to(device) for a in batch]\n",
        "\n",
        "        # Sparql sometimes adds KB words in the query that are not found in the english question.\n",
        "        # In those situations it breaks the loss for some reason\n",
        "        # This replaces them with padding instead\n",
        "        for i in range(0, len(tgt)):\n",
        "            for j in range(0, len(tgt[i])):\n",
        "                if tgt[i][j] >= base_sparql_vocab.length and tgt[i][j] not in src[i]:\n",
        "                    tgt[i][j] = padding_id\n",
        "        for i in range(0, len(tgt_y)):\n",
        "            for j in range(0, len(tgt_y[i])):\n",
        "                if tgt_y[i][j]>=base_sparql_vocab.length and tgt_y[i][j] not in src[i]:\n",
        "                    tgt_y[i][j] = padding_id\n",
        "\n",
        "        out = model.forward(src, tgt, src_mask, tgt_mask)\n",
        "        out = out.contiguous().view(-1, out.shape[-1])\n",
        "        tgt_y = tgt_y.contiguous().view(-1)\n",
        "        loss = loss_function(out, tgt_y)\n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "    train_loss.append(np.mean(loss_list))\n",
        "    # Run epoch eval\n",
        "    model.eval()\n",
        "    loss_list = []\n",
        "    for i, batch in enumerate(validation):\n",
        "        src, tgt, tgt_y, src_mask, tgt_mask = [a.to(device) for a in batch]\n",
        "\n",
        "        # Sparql sometimes adds KB words in the query that are not found in the english question.\n",
        "        # In those situations it breaks the loss for some reason\n",
        "        # This replaces them with padding instead\n",
        "        for i in range(0, len(tgt)):\n",
        "            for j in range(0, len(tgt[i])):\n",
        "                if tgt[i][j] >= base_sparql_vocab.length and tgt[i][j] not in src[i]:\n",
        "                    tgt[i][j] = 0\n",
        "        for i in range(0, len(tgt_y)):\n",
        "            for j in range(0, len(tgt_y[i])):\n",
        "                if tgt_y[i][j]>=base_sparql_vocab.length and tgt_y[i][j] not in src[i]:\n",
        "                    tgt_y[i][j] = 0\n",
        "\n",
        "        out = model.forward(src, tgt, src_mask, tgt_mask)\n",
        "        out = out.contiguous().view(-1, out.shape[-1])\n",
        "        tgt_y = tgt_y.contiguous().view(-1)\n",
        "        loss = loss_function(out, tgt_y)\n",
        "        loss_list.append(loss.item())\n",
        "    validation_loss.append(np.mean(loss_list))\n",
        "    if best_validation_loss is None or validation_loss[-1] < best_validation_loss:\n",
        "        best_validation_loss = validation_loss[-1]\n",
        "        best_model = copy.deepcopy(model)\n",
        "    print(f\"EPOCH {epoch} train_loss={train_loss[-1]} validation_loss={validation_loss[-1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlLhje-W1OyC",
        "outputId": "b33eafe0-d3c0-4fa4-9f68-ed63dd005d1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot validation and training loss\n",
        "ep = np.arange(0, nb_epoch)\n",
        "plt.plot(ep, train_loss, '-', label='train')\n",
        "plt.plot(ep, validation_loss, '-', label='validation')\n",
        "plt.legend()\n",
        "plt.title(\"Loss au cours de l'entrainement\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Cross-entropy loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoqPeJ3D1OyC",
        "outputId": "651b048e-217c-4130-bf75-d129c1e61ebe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test input is:\n",
            "['<S>', 'what', 'is', 'the', 'dbo:municipality', 'of', 'dbr:Homestead_Grays_Bridge', '?', '</S>']\n",
            "Expected output of length 11 is:\n",
            "<S> select distinct ?uri where { dbr:Homestead_Grays_Bridge dbo:municipality ?uri } </S>\n",
            "Actual output of length 11 is: \n",
            "tensor([   1,    2,    3,    6,    8,    9, 2549, 2101,    6,   11,   12],\n",
            "       device='cuda:0')\n",
            "<S> select distinct ?uri where { dbr:Homestead_Grays_Bridge dbo:municipality ?uri } </S>\n"
          ]
        }
      ],
      "source": [
        "chosen_example = 100\n",
        "best_model.eval()\n",
        "print(f\"Test input is:\")\n",
        "src = validation_english_tensors[chosen_example].unsqueeze(0)\n",
        "print(english_vocab.id_to_word(src.squeeze().tolist()))\n",
        "src_mask = (src!=0).unsqueeze(-2)\n",
        "tgt = validation_tokens[\"sparql\"][chosen_example]\n",
        "print(f\"Expected output of length {tgt.size} is:\")\n",
        "print(\" \".join(tgt.tolist()))\n",
        "src = src.requires_grad_(False).clone().detach().to(device=device)\n",
        "src_mask = src_mask.requires_grad_(False).clone().detach().to(device=device)\n",
        "output = greedy_decode(best_model, src, src_mask, max_len=50, start_symbol=sparql_vocab.word_to_id(\"<S>\"), end_symbol=sparql_vocab.word_to_id(\"</S>\")).squeeze()\n",
        "print(f\"Actual output of length {output.shape[0]} is: \")\n",
        "print(output)\n",
        "print(\" \".join(sparql_vocab.id_to_word(output.tolist())))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "ffaa99b57a224128b03972a75e7751b9",
            "61823f4eb57244f7ae1bed67542027c6",
            "1654935e30a845e1ae03d7fa468938b3",
            "4dc58137024c46369e3608859218fba7",
            "5dd300032311497aa51bf3435efc396f",
            "6aafbabd3d824af29c2baed5b9c7fbd8",
            "c6f5506044064ed7848fa182ecc561b2",
            "62537e4e5039423f942eb5d4eb37e30a",
            "bf8544341a0746b4a9e04c06e92f99f6",
            "52d3855a5630442cb79e6d3f252420e3",
            "89f13a22c2fb4cccb984bf8d5de7df2b"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "id": "5IGId9kw1OyD",
        "outputId": "b1f069f3-2611-4eee-98e4-0ebb63dd1d51"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ffaa99b57a224128b03972a75e7751b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score 0.9880239995462768\n",
            "Accuracy 0.942\n"
          ]
        }
      ],
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "def compute_bleu(predictions: List[List[str]], targets: List[List[str]]) -> float:\n",
        "    \"\"\"\n",
        "    entrées:\n",
        "       - predictions: Liste des prédicitons du modèle pour l'ensemble de validation. Chaque prédiction est une liste de jetons textuels.\n",
        "       - targets: Liste des requêtes attendues de l'ensemble de validation. Chaque requête est une liste de jetons textuels.\n",
        "    sortie:\n",
        "       Le score bleu moyen de vos prédictions comparées aux requêtes attendues.\n",
        "    \"\"\"\n",
        "    return bleu_score(predictions, [[tokens] for tokens in targets])\n",
        "\n",
        "def compute_accuracy(predictions, targets):\n",
        "    return (sum(np.array(predictions, dtype=object)==np.array(targets, dtype=object)))/len(predictions)\n",
        "\n",
        "maxlen = max(train_sparql_tensors.apply(len))+10\n",
        "predictions = []\n",
        "targets = []\n",
        "for i in tqdm(range(0, len(validation_english_tensors))):\n",
        "    src = validation_english_tensors[i].unsqueeze(0)\n",
        "    src_mask = (src!=0).unsqueeze(-2)\n",
        "    src = src.requires_grad_(False).clone().detach().to(device)\n",
        "    src_mask = src_mask.requires_grad_(False).clone().detach().to(device)\n",
        "    output = greedy_decode(best_model, src, src_mask, max_len=maxlen, start_symbol=sparql_vocab.word_to_id(\"<S>\"), end_symbol=sparql_vocab.word_to_id(\"</S>\")).squeeze()\n",
        "    predictions.append(sparql_vocab.id_to_word(output.tolist()))\n",
        "    targets.append(validation_tokens[\"sparql\"][i].tolist())\n",
        "\n",
        "print(\"BLEU score\", compute_bleu(predictions, targets))\n",
        "print(\"Accuracy\", compute_accuracy(predictions, targets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "87be49e04edc49db84de41eba442b710",
            "d0010c61dc774f48a043cb7e18f1119f",
            "b9c5a6c8c59a4424bcdefcfc622b3301",
            "be8679aa996c4e5aa70e00d9ab9ffb66",
            "7978afdd593a4122a4c9dfc32d679945",
            "4682a5f4b1a94b61928ab06cd945bb31",
            "a8639321241b40a4a5c29d8a3c5adb38",
            "c3f121eac0de4bc5aee617704feefb75",
            "a172420c6e474c1ab43aad3ebb7f2f1c",
            "dfdb2376327c42358d6f66a3b53f4c44",
            "96f60f062c4640f5835087ff1f2bac49"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "sZjB5g611OyD",
        "outputId": "6140ca35-09fc-4ec1-9ca2-3101e75efd36"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87be49e04edc49db84de41eba442b710"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Soumission Kaggle\n",
        "\n",
        "predictions = []\n",
        "for i in tqdm(range(0, len(test_english_tensors))):\n",
        "  src = test_english_tensors[i].unsqueeze(0)\n",
        "  src_mask = (src!=padding_id).unsqueeze(-2)\n",
        "  src = src.requires_grad_(False).clone().detach().to(device)\n",
        "  src_mask = src_mask.requires_grad_(False).clone().detach().to(device)\n",
        "  output = greedy_decode(best_model, src, src_mask, max_len=maxlen, start_symbol=sparql_vocab.word_to_id(\"<S>\"), end_symbol=sparql_vocab.word_to_id(\"</S>\")).squeeze()\n",
        "  predictions.append(\" \".join(sparql_vocab.id_to_word(output.tolist()[1:-1])))\n",
        "submission = test_df.drop('english', axis=1)\n",
        "submission['translation'] = predictions\n",
        "submission.to_csv(\"tp4_submission.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPnY61np1OyE"
      },
      "source": [
        "### 7.4. Conclusion (5%)\n",
        "En quelques phrases précises, discutez des avantages et limites de vos architectures. Analysez les cas d’erreur. Indiquez des pistes d’amélioration futures potentielles."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Au final, on voit une nette amélioration de l'algorithme lorsque le mécanisme de copie est introduit. Il serait intéressant de comparer ces resultats avec ceux obtenus en utilisant un ensemble d'entraînement plus grand ou un modèle pré-entrainé. Cela montrerait jusqu'à quel point le mécanisme de copie permet de se passer d'un ensemble d'entraînement vaste (contenant la majorité des mots de l'ensemble test). Il serait également intéressant de l'ajouter à un modèle pré-entrainé comme BART ou T5 afin de voir à quel point il peut améliorer les résultats dans ce cas là."
      ],
      "metadata": {
        "id": "Mt8_3coqrwH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to html \"equipe_7_inf8460_TP4 (2).ipynb\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Es88-Hq9wMc3",
        "outputId": "270a5ad4-f68c-4c42-e3c2-6abccba8aad1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook equipe_7_inf8460_TP4 (2).ipynb to html\n",
            "[NbConvertApp] Writing 728384 bytes to equipe_7_inf8460_TP4 (2).html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-P0PPOAT21n"
      },
      "source": [
        "## 8. LIVRABLES\n",
        "Vous devez remettre sur Moodle:\n",
        "\n",
        "1) Le code : Un Jupyter notebook en Python qui contient le code tel que soumis dans l’environnement Kaggle implanté avec les librairies disponibles pour ce cours (Python, Keras, NLTK, scikitLearn, etc.) ainsi que votre fichier de soumission de données de test. Le code doit être exécutable sans erreur et accompagné des commentaires appropriés dans le notebook de manière à expliquer les différentes fonctions et étapes dans votre projet. Nous nous réservons le droit de demander une démonstration ou la preuve que vous avez effectué vous-mêmes les expériences décrites. *Attention, en aucun cas votre code ne doit avoir été copié de projets potentiellement existants.*\n",
        "\n",
        "2) Un fichier `requirements.txt` doit indiquer toutes les librairies / données nécessaires. Les critères de qualité tels que la lisibilité du code et des commentaires sont importants.\n",
        "\n",
        "3) Un lien *GoogleDrive* vers les modèles nécessaires pour exécuter votre notebook si approprié.\n",
        "\n",
        "4) Le fichier `tp3_submission.csv`.\n",
        "\n",
        "5) Un document `contributions.txt` : Décrivez brièvement la contribution de chaque membre de l’équipe. Tous les membres sont censés contribuer au développement. Bien que chaque membre puisse effectuer différentes tâches, vous devez vous efforcer d’obtenir une répartition égale du travail. En particulier, tous les membres du projet devraient participer à la conception du projet et participer activement à la réflexion et à l’implémentation du code.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezXfrDdLUqcI"
      },
      "source": [
        "__EVALUATION__ <br>\n",
        "Votre TP sera évalué sur les points suivants :\n",
        "\n",
        "__Critères :__\n",
        "1. Implantation correcte et efficace\n",
        "2. Exécution correcte du code\n",
        "3. Qualité du code\n",
        "4. Commentaires clairs et informatifs\n",
        "5. Aspect novateur : autres métriques ou modèles qui dépassent ce qui est demandé\n",
        "\n",
        "__CODE D’HONNEUR__\n",
        "- __Règle 1__:  Le plagiat de code est bien évidemment interdit. Toute utilisation de code doit être référencée adéquatement. L’utilisation de code ne peut concerner que les architectures de base (par exemple le Transformer). Vous __ne pouvez pas__ soumettre un code, écrit par quelqu’un d’autre, faisant de la traduction de la langue naturelle vers SPARQL. Dans le cas contraire, cela sera considéré comme du plagiat.\n",
        "- __Règle 2__: Vous êtes libres de discuter des idées et des détails de mise en œuvre avec d'autres équipes. Cependant, vous ne pouvez en aucun cas consulter le code d'une autre équipe INF8460, ou incorporer leur code dans votre TP.\n",
        "- __Règle 3__:  Vous ne pouvez pas partager votre code publiquement (par exemple, dans un dépôt GitHub public) tant que le cours n'est pas fini."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeGeNf9P1OyF"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "335c42c933cb414492d90ca68df647bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39f93afa6c1b48ed91354ce465864fba",
              "IPY_MODEL_38d530fbc45747f5909c97d9350dc5d3",
              "IPY_MODEL_c3965144772042609340da39f2d7db45"
            ],
            "layout": "IPY_MODEL_546fe184b05142eb987adce753f7721c"
          }
        },
        "39f93afa6c1b48ed91354ce465864fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b00ebea5ac3a48d6947ee086d3465563",
            "placeholder": "​",
            "style": "IPY_MODEL_0dbac25f8b654162a08094973a408ec9",
            "value": "100%"
          }
        },
        "38d530fbc45747f5909c97d9350dc5d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cdde9d0c52b417bb0426a4561620cb6",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86618c371641477a8cf45f8ab014f360",
            "value": 200
          }
        },
        "c3965144772042609340da39f2d7db45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_452ecb199a6841a2af9d3093bf7430a7",
            "placeholder": "​",
            "style": "IPY_MODEL_80e82bdc68a2447f97565413315acd99",
            "value": " 200/200 [28:12&lt;00:00,  8.44s/it]"
          }
        },
        "546fe184b05142eb987adce753f7721c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b00ebea5ac3a48d6947ee086d3465563": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dbac25f8b654162a08094973a408ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cdde9d0c52b417bb0426a4561620cb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86618c371641477a8cf45f8ab014f360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "452ecb199a6841a2af9d3093bf7430a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80e82bdc68a2447f97565413315acd99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcb6175f3e1f46838368bc905e8ee3e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dfe0e4b6ded74c42b0fe5973f5c8bea6",
              "IPY_MODEL_a33cbe53c5a14317928cfd40205788d4",
              "IPY_MODEL_3eb1863d965c46a98f19c748c21ba7ba"
            ],
            "layout": "IPY_MODEL_278aae03b6594ed4bf79ce6db5b788dd"
          }
        },
        "dfe0e4b6ded74c42b0fe5973f5c8bea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_532e43e92cf948cb889f8d1378540770",
            "placeholder": "​",
            "style": "IPY_MODEL_4e867142f0e44b79bb71e6c7c131afe6",
            "value": "100%"
          }
        },
        "a33cbe53c5a14317928cfd40205788d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98f3d15fd75a4027a9b45ad20963c0ee",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_210ee14fac5942b0afaec44f371cbede",
            "value": 500
          }
        },
        "3eb1863d965c46a98f19c748c21ba7ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f47ea9c7db14b318a9a4f2d17450b55",
            "placeholder": "​",
            "style": "IPY_MODEL_dcc862acdcbd4d6d830dd7f493f1beb0",
            "value": " 500/500 [01:20&lt;00:00,  6.67it/s]"
          }
        },
        "278aae03b6594ed4bf79ce6db5b788dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "532e43e92cf948cb889f8d1378540770": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e867142f0e44b79bb71e6c7c131afe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98f3d15fd75a4027a9b45ad20963c0ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "210ee14fac5942b0afaec44f371cbede": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f47ea9c7db14b318a9a4f2d17450b55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcc862acdcbd4d6d830dd7f493f1beb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1016a75f00948698248afb45f06c664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78a2dab685fb462f93ff594dddbd22be",
              "IPY_MODEL_d4be906fc9e74b75a491dfcde18f4a0a",
              "IPY_MODEL_4051e8bcae134f8b96b914fe8589e532"
            ],
            "layout": "IPY_MODEL_1a1e850abdbe4230ab06496cd3e1a067"
          }
        },
        "78a2dab685fb462f93ff594dddbd22be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b28ebbcddda34f99a37784c67c7174e0",
            "placeholder": "​",
            "style": "IPY_MODEL_6f79a50190194de6822d5156c1f5d2eb",
            "value": "100%"
          }
        },
        "d4be906fc9e74b75a491dfcde18f4a0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b234a42203041998a2fa6e12197a135",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da09521e0a5546beba909b93583b871c",
            "value": 200
          }
        },
        "4051e8bcae134f8b96b914fe8589e532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_779c8f71eee14e02b14a1726403b1821",
            "placeholder": "​",
            "style": "IPY_MODEL_a198bbd6132143c3aa6dfd5e2cafc7c9",
            "value": " 200/200 [47:42&lt;00:00, 14.26s/it]"
          }
        },
        "1a1e850abdbe4230ab06496cd3e1a067": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b28ebbcddda34f99a37784c67c7174e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f79a50190194de6822d5156c1f5d2eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b234a42203041998a2fa6e12197a135": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da09521e0a5546beba909b93583b871c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "779c8f71eee14e02b14a1726403b1821": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a198bbd6132143c3aa6dfd5e2cafc7c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffaa99b57a224128b03972a75e7751b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_61823f4eb57244f7ae1bed67542027c6",
              "IPY_MODEL_1654935e30a845e1ae03d7fa468938b3",
              "IPY_MODEL_4dc58137024c46369e3608859218fba7"
            ],
            "layout": "IPY_MODEL_5dd300032311497aa51bf3435efc396f"
          }
        },
        "61823f4eb57244f7ae1bed67542027c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6aafbabd3d824af29c2baed5b9c7fbd8",
            "placeholder": "​",
            "style": "IPY_MODEL_c6f5506044064ed7848fa182ecc561b2",
            "value": "100%"
          }
        },
        "1654935e30a845e1ae03d7fa468938b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62537e4e5039423f942eb5d4eb37e30a",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf8544341a0746b4a9e04c06e92f99f6",
            "value": 500
          }
        },
        "4dc58137024c46369e3608859218fba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52d3855a5630442cb79e6d3f252420e3",
            "placeholder": "​",
            "style": "IPY_MODEL_89f13a22c2fb4cccb984bf8d5de7df2b",
            "value": " 500/500 [01:26&lt;00:00,  6.16it/s]"
          }
        },
        "5dd300032311497aa51bf3435efc396f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aafbabd3d824af29c2baed5b9c7fbd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6f5506044064ed7848fa182ecc561b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62537e4e5039423f942eb5d4eb37e30a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf8544341a0746b4a9e04c06e92f99f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52d3855a5630442cb79e6d3f252420e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89f13a22c2fb4cccb984bf8d5de7df2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87be49e04edc49db84de41eba442b710": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0010c61dc774f48a043cb7e18f1119f",
              "IPY_MODEL_b9c5a6c8c59a4424bcdefcfc622b3301",
              "IPY_MODEL_be8679aa996c4e5aa70e00d9ab9ffb66"
            ],
            "layout": "IPY_MODEL_7978afdd593a4122a4c9dfc32d679945"
          }
        },
        "d0010c61dc774f48a043cb7e18f1119f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4682a5f4b1a94b61928ab06cd945bb31",
            "placeholder": "​",
            "style": "IPY_MODEL_a8639321241b40a4a5c29d8a3c5adb38",
            "value": "100%"
          }
        },
        "b9c5a6c8c59a4424bcdefcfc622b3301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3f121eac0de4bc5aee617704feefb75",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a172420c6e474c1ab43aad3ebb7f2f1c",
            "value": 500
          }
        },
        "be8679aa996c4e5aa70e00d9ab9ffb66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfdb2376327c42358d6f66a3b53f4c44",
            "placeholder": "​",
            "style": "IPY_MODEL_96f60f062c4640f5835087ff1f2bac49",
            "value": " 500/500 [01:21&lt;00:00,  6.62it/s]"
          }
        },
        "7978afdd593a4122a4c9dfc32d679945": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4682a5f4b1a94b61928ab06cd945bb31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8639321241b40a4a5c29d8a3c5adb38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3f121eac0de4bc5aee617704feefb75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a172420c6e474c1ab43aad3ebb7f2f1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfdb2376327c42358d6f66a3b53f4c44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96f60f062c4640f5835087ff1f2bac49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}